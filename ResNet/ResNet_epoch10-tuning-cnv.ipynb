{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4999177982297457661\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/data/yingfei/cancer_data/train_data_cnv.csv')\n",
    "test_data = pd.read_csv('/data/yingfei/cancer_data/test_data_cnv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (203918, 2652)\n",
      "Test Shape: (22878, 2652)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Shape: {train_data.shape}')\n",
    "print(f'Test Shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.loc[train_data['auc'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACVR1B</th>\n",
       "      <th>AKT1</th>\n",
       "      <th>AKT2</th>\n",
       "      <th>AKT3</th>\n",
       "      <th>ALK</th>\n",
       "      <th>ALOX12B</th>\n",
       "      <th>FAM123B</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.891908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203913</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>KIN001-236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203914</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203915</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203916</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203917</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203918 rows × 2652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ARXSPAN_ID   DRUG_NAME  ABL1  ACVR1B  AKT1  AKT2  AKT3  ALK  ALOX12B  \\\n",
       "0       ACH-000001   JW-7-24-1     1       1     1     1     1    0       -1   \n",
       "1       ACH-000001  KIN001-260     1       1     1     1     1    0       -1   \n",
       "2       ACH-000001   NSC-87877     1       1     1     1     1    0       -1   \n",
       "3       ACH-000001    PLX-4720     1       1     1     1     1    0       -1   \n",
       "4       ACH-000001   ERK5-IN-1     1       1     1     1     1    0       -1   \n",
       "...            ...         ...   ...     ...   ...   ...   ...  ...      ...   \n",
       "203913  ACH-001716  KIN001-236     0       0     0     0     0    1        0   \n",
       "203914  ACH-001716  LUMINESPIB     0       0     0     0     0    1        0   \n",
       "203915  ACH-001716   NUTLIN-3A     0       0     0     0     0    1        0   \n",
       "203916  ACH-001716     SGC0946     0       0     0     0     0    1        0   \n",
       "203917  ACH-001716   SL 0101-1     0       0     0     0     0    1        0   \n",
       "\n",
       "        FAM123B  ...  PubchemFP872  PubchemFP873  PubchemFP874  PubchemFP875  \\\n",
       "0             0  ...             0             0             0             0   \n",
       "1             0  ...             0             0             0             0   \n",
       "2             0  ...             0             0             0             0   \n",
       "3             0  ...             0             0             0             0   \n",
       "4             0  ...             0             0             0             0   \n",
       "...         ...  ...           ...           ...           ...           ...   \n",
       "203913        0  ...             0             0             0             0   \n",
       "203914        0  ...             0             0             0             0   \n",
       "203915        0  ...             0             0             0             0   \n",
       "203916        0  ...             0             0             0             0   \n",
       "203917        0  ...             0             0             0             0   \n",
       "\n",
       "        PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  PubchemFP880  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "203913             0             0             0             0             0   \n",
       "203914             0             0             0             0             0   \n",
       "203915             0             0             0             0             0   \n",
       "203916             0             0             0             0             0   \n",
       "203917             0             0             0             0             0   \n",
       "\n",
       "             auc  \n",
       "0       0.778432  \n",
       "1       0.951321  \n",
       "2       0.840287  \n",
       "3       0.936410  \n",
       "4       0.891908  \n",
       "...          ...  \n",
       "203913  0.956865  \n",
       "203914  0.975168  \n",
       "203915  0.871995  \n",
       "203916  0.975417  \n",
       "203917  0.942321  \n",
       "\n",
       "[203918 rows x 2652 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reset_index(drop = True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.loc[test_data['auc'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACVR1B</th>\n",
       "      <th>AKT1</th>\n",
       "      <th>AKT2</th>\n",
       "      <th>AKT3</th>\n",
       "      <th>ALK</th>\n",
       "      <th>ALOX12B</th>\n",
       "      <th>FAM123B</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>KIN001-266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARXSPAN_ID   DRUG_NAME  ABL1  ACVR1B  AKT1  AKT2  AKT3  ALK  ALOX12B  \\\n",
       "0      ACH-000802   JW-7-24-1     1       0     1    -1     1    1       -1   \n",
       "1      ACH-000802  KIN001-260     1       0     1    -1     1    1       -1   \n",
       "2      ACH-000802   NSC-87877     1       0     1    -1     1    1       -1   \n",
       "3      ACH-000802    PLX-4720     1       0     1    -1     1    1       -1   \n",
       "4      ACH-000802   ERK5-IN-1     1       0     1    -1     1    1       -1   \n",
       "...           ...         ...   ...     ...   ...   ...   ...  ...      ...   \n",
       "22873  ACH-000438  KIN001-266     0       0     0     1     0    0        0   \n",
       "22874  ACH-000438  LUMINESPIB     0       0     0     1     0    0        0   \n",
       "22875  ACH-000438   NUTLIN-3A     0       0     0     1     0    0        0   \n",
       "22876  ACH-000438     SGC0946     0       0     0     1     0    0        0   \n",
       "22877  ACH-000438   SL 0101-1     0       0     0     1     0    0        0   \n",
       "\n",
       "       FAM123B  ...  PubchemFP872  PubchemFP873  PubchemFP874  PubchemFP875  \\\n",
       "0            0  ...             0             0             0             0   \n",
       "1            0  ...             0             0             0             0   \n",
       "2            0  ...             0             0             0             0   \n",
       "3            0  ...             0             0             0             0   \n",
       "4            0  ...             0             0             0             0   \n",
       "...        ...  ...           ...           ...           ...           ...   \n",
       "22873        0  ...             0             0             0             0   \n",
       "22874        0  ...             0             0             0             0   \n",
       "22875        0  ...             0             0             0             0   \n",
       "22876        0  ...             0             0             0             0   \n",
       "22877        0  ...             0             0             0             0   \n",
       "\n",
       "       PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  PubchemFP880  \\\n",
       "0                 0             0             0             0             0   \n",
       "1                 0             0             0             0             0   \n",
       "2                 0             0             0             0             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "22873             0             0             0             0             0   \n",
       "22874             0             0             0             0             0   \n",
       "22875             0             0             0             0             0   \n",
       "22876             0             0             0             0             0   \n",
       "22877             0             0             0             0             0   \n",
       "\n",
       "            auc  \n",
       "0      0.528562  \n",
       "1      0.930958  \n",
       "2      0.759249  \n",
       "3      0.936510  \n",
       "4      0.823453  \n",
       "...         ...  \n",
       "22873  0.975578  \n",
       "22874  0.980529  \n",
       "22875  0.960501  \n",
       "22876  0.970524  \n",
       "22877  0.706073  \n",
       "\n",
       "[22878 rows x 2652 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.reset_index(drop = True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "padel_features = train_data[train_data.columns[-2326:-1]]\n",
    "padel_features = scaler.fit_transform(padel_features)\n",
    "padel_features = pd.DataFrame(padel_features)\n",
    "#train_features = train_data.drop(columns = ['ARXSPAN_ID', 'DRUG_NAME','auc'])\n",
    "#train_features = scaler.fit_transform(train_features)\n",
    "train_features = train_data[train_data.columns[2:-2326]]\n",
    "train_features = pd.concat([train_features, padel_features], axis = 1)\n",
    "train_features = train_features.to_numpy()\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum train y value: 0.004496,       Maximum train y value: 0.999883\n"
     ]
    }
   ],
   "source": [
    "train_label = train_data['auc']\n",
    "print(f'Minimum train y value: {min(train_label)}, \\\n",
    "      Maximum train y value: {max(train_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padel_features = test_data[test_data.columns[-2326:-1]]\n",
    "padel_features = scaler.fit_transform(padel_features)\n",
    "padel_features = pd.DataFrame(padel_features)\n",
    "#test_features = test_data.drop(columns = ['ARXSPAN_ID', 'DRUG_NAME','auc'])\n",
    "#test_features = scaler.transform(test_features)\n",
    "test_features = test_data[test_data.columns[2:-2326]]\n",
    "test_features = pd.concat([test_features, padel_features], axis = 1)\n",
    "test_features = test_features.to_numpy()\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum test y value: 0.013524,       Maximum test y value: 0.998284\n"
     ]
    }
   ],
   "source": [
    "test_label = test_data['auc']\n",
    "print(f'Minimum test y value: {min(test_label)}, \\\n",
    "      Maximum test y value: {max(test_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = train_features, train_label, test_features, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203918, 2649, 1) (203918,) (22878, 2649, 1) (22878,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (203918, 2649, 1)\n",
      "203918 train samples\n",
      "22878 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X)\n",
    "train_y = np.nan_to_num(train_y)\n",
    "test_X = np.nan_to_num(test_X)\n",
    "test_y = np.nan_to_num(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization, UtilityFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split into train and validation set\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters set\n",
    "params_lst = [\"learning_rate\", \"batch_size\", \"optimizer\"]\n",
    "params_value_dict = {\"learning_rate\": [1e-4, 2e-4, 5e-4], \n",
    "                     \"batch_size\": [80, 100, 120], \n",
    "                     \"optimizer\": ['sgd', 'adam']}\n",
    "import itertools as it\n",
    "\n",
    "allparams = params_value_dict\n",
    "combinations = it.product(*(params_value_dict[param] for param in allparams))\n",
    "combinations_lst = list(combinations)\n",
    "print(len(combinations_lst))\n",
    "\n",
    "hyper_param_dict = {}\n",
    "for i in range(len(combinations_lst)):\n",
    "    hyper_param_dict[i] = {}\n",
    "    for j in range(len(params_lst)):\n",
    "        hyper_param_dict[i][params_lst[j]] = combinations_lst[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2023-03-15 16:36:10.976750\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 346s 175ms/step - loss: 0.6638 - mse: 0.6638 - mae: 0.6419 - val_loss: 0.2243 - val_mse: 0.2243 - val_mae: 0.3766\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 333s 174ms/step - loss: 0.4121 - mse: 0.4121 - mae: 0.5081 - val_loss: 0.1603 - val_mse: 0.1603 - val_mae: 0.3188\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 342s 179ms/step - loss: 0.3073 - mse: 0.3073 - mae: 0.4389 - val_loss: 0.1202 - val_mse: 0.1202 - val_mae: 0.2756\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 339s 177ms/step - loss: 0.2398 - mse: 0.2398 - mae: 0.3879 - val_loss: 0.1014 - val_mse: 0.1014 - val_mae: 0.2544\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 347s 181ms/step - loss: 0.1950 - mse: 0.1950 - mae: 0.3500 - val_loss: 0.0839 - val_mse: 0.0839 - val_mae: 0.2325\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 348s 182ms/step - loss: 0.1652 - mse: 0.1652 - mae: 0.3224 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.2165\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 335s 175ms/step - loss: 0.1424 - mse: 0.1424 - mae: 0.2990 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.2063\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 336s 176ms/step - loss: 0.1244 - mse: 0.1244 - mae: 0.2795 - val_loss: 0.0569 - val_mse: 0.0569 - val_mae: 0.1912\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 344s 180ms/step - loss: 0.1095 - mse: 0.1095 - mae: 0.2620 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1870\n",
      "Epoch 10/10\n",
      "1912/1912 [==============================] - 347s 181ms/step - loss: 0.0967 - mse: 0.0967 - mae: 0.2463 - val_loss: 0.0490 - val_mse: 0.0490 - val_mae: 0.1784\n",
      "EndTime : 2023-03-15 17:33:09.110075\n",
      "Evaluating model 0...\n",
      "715/715 [==============================] - 25s 35ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1777\n",
      "loss=0.048888, mse=0.048888, mae=0.177700\n",
      "StartTime : 2023-03-15 17:33:37.145986\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 363s 183ms/step - loss: 0.3627 - mse: 0.3627 - mae: 0.3923 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1091\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 344s 180ms/step - loss: 0.0784 - mse: 0.0784 - mae: 0.1856 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0865\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 339s 177ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1452 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0825\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 340s 178ms/step - loss: 0.0309 - mse: 0.0309 - mae: 0.1214 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0791\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 339s 178ms/step - loss: 0.0222 - mse: 0.0222 - mae: 0.1047 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0731\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 334s 175ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0945 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0727\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 329s 172ms/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0885 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0707\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 330s 173ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0843 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0704\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 331s 173ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0817 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0688\n",
      "Epoch 10/10\n",
      "1357/1912 [====================>.........] - ETA: 1:29 - loss: 0.0134 - mse: 0.0134 - mae: 0.0791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 333s 211ms/step - loss: 0.9382 - mse: 0.9382 - mae: 0.7597 - val_loss: 0.3313 - val_mse: 0.3313 - val_mae: 0.4617\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 316s 207ms/step - loss: 0.5069 - mse: 0.5069 - mae: 0.5617 - val_loss: 0.2151 - val_mse: 0.2151 - val_mae: 0.3703\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 323s 211ms/step - loss: 0.3653 - mse: 0.3653 - mae: 0.4770 - val_loss: 0.1497 - val_mse: 0.1497 - val_mae: 0.3082\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 321s 210ms/step - loss: 0.2804 - mse: 0.2804 - mae: 0.4166 - val_loss: 0.1138 - val_mse: 0.1138 - val_mae: 0.2704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 319s 209ms/step - loss: 0.2273 - mse: 0.2273 - mae: 0.3729 - val_loss: 0.0952 - val_mse: 0.0952 - val_mae: 0.2465\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 316s 206ms/step - loss: 0.1878 - mse: 0.1878 - mae: 0.3381 - val_loss: 0.0776 - val_mse: 0.0776 - val_mae: 0.2223\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 316s 207ms/step - loss: 0.1628 - mse: 0.1628 - mae: 0.3125 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.2029\n",
      "Epoch 8/10\n",
      " 448/1530 [=======>......................] - ETA: 3:31 - loss: 0.1473 - mse: 0.1473 - mae: 0.2971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 315s 206ms/step - loss: 0.1129 - mse: 0.1129 - mae: 0.2588 - val_loss: 0.0456 - val_mse: 0.0456 - val_mae: 0.1697\n",
      "EndTime : 2023-03-15 19:23:48.535253\n",
      "Evaluating model 2...\n",
      "715/715 [==============================] - 26s 36ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1729\n",
      "loss=0.047316, mse=0.047316, mae=0.172861\n",
      "StartTime : 2023-03-15 19:24:32.984215\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 305s 191ms/step - loss: 0.1517 - mse: 0.1517 - mae: 0.2669 - val_loss: 0.0305 - val_mse: 0.0305 - val_mae: 0.1110\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 297s 194ms/step - loss: 0.0559 - mse: 0.0559 - mae: 0.1557 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0915\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 302s 197ms/step - loss: 0.0357 - mse: 0.0357 - mae: 0.1303 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0795\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 306s 200ms/step - loss: 0.0241 - mse: 0.0241 - mae: 0.1108 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0745\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 309s 202ms/step - loss: 0.0191 - mse: 0.0191 - mae: 0.0986 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0729\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 304s 198ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0913 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0730\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 302s 197ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0872 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 304s 199ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0840 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0689\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 304s 199ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0812 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0676\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 304s 199ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0795 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0672\n",
      "EndTime : 2023-03-15 20:15:12.566535\n",
      "Evaluating model 3...\n",
      "715/715 [==============================] - 25s 35ms/step - loss: 0.0170 - mse: 0.0170 - mae: 0.0787\n",
      "loss=0.017037, mse=0.017037, mae=0.078715\n",
      "StartTime : 2023-03-15 20:15:40.083264\n",
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 305s 227ms/step - loss: 0.5184 - mse: 0.5184 - mae: 0.5706 - val_loss: 0.1953 - val_mse: 0.1953 - val_mae: 0.3519\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 288s 226ms/step - loss: 0.3851 - mse: 0.3851 - mae: 0.4916 - val_loss: 0.1615 - val_mse: 0.1615 - val_mae: 0.3206\n",
      "Epoch 3/10\n",
      "1118/1275 [=========================>....] - ETA: 31s - loss: 0.3145 - mse: 0.3145 - mae: 0.4449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 282s 221ms/step - loss: 0.1914 - mse: 0.1914 - mae: 0.3470 - val_loss: 0.0827 - val_mse: 0.0827 - val_mae: 0.2295\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 287s 225ms/step - loss: 0.1690 - mse: 0.1690 - mae: 0.3260 - val_loss: 0.0757 - val_mse: 0.0757 - val_mae: 0.2197\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 293s 230ms/step - loss: 0.1530 - mse: 0.1530 - mae: 0.3100 - val_loss: 0.0684 - val_mse: 0.0684 - val_mae: 0.2094\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 291s 228ms/step - loss: 0.1363 - mse: 0.1363 - mae: 0.2924 - val_loss: 0.0636 - val_mse: 0.0636 - val_mae: 0.2018\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 296s 232ms/step - loss: 0.1235 - mse: 0.1235 - mae: 0.2785 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1953\n",
      "EndTime : 2023-03-15 21:03:40.018626\n",
      "Evaluating model 4...\n",
      "715/715 [==============================] - 27s 38ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.1944\n",
      "loss=0.059530, mse=0.059530, mae=0.194360\n",
      "StartTime : 2023-03-15 21:04:10.083872\n",
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 302s 227ms/step - loss: 0.2421 - mse: 0.2421 - mae: 0.3334 - val_loss: 0.0399 - val_mse: 0.0399 - val_mae: 0.1380\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 281s 220ms/step - loss: 0.0743 - mse: 0.0743 - mae: 0.1789 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0927\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 281s 221ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.1487 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0851\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 278s 218ms/step - loss: 0.0371 - mse: 0.0371 - mae: 0.1300 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0785\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 277s 217ms/step - loss: 0.0258 - mse: 0.0258 - mae: 0.1124 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0786\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 277s 217ms/step - loss: 0.0205 - mse: 0.0205 - mae: 0.1009 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0726\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 280s 219ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.0934 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0709\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 276s 217ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0884 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0690\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 272s 214ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0855 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0691\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 276s 217ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0821 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0680\n",
      "EndTime : 2023-03-15 21:51:46.456423\n",
      "Evaluating model 5...\n",
      "715/715 [==============================] - 28s 40ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.0801\n",
      "loss=0.017642, mse=0.017642, mae=0.080127\n",
      "StartTime : 2023-03-15 21:52:18.880840\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 389s 196ms/step - loss: 0.5066 - mse: 0.5066 - mae: 0.5602 - val_loss: 0.1947 - val_mse: 0.1947 - val_mae: 0.3551\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 378s 198ms/step - loss: 0.2743 - mse: 0.2743 - mae: 0.4148 - val_loss: 0.1296 - val_mse: 0.1296 - val_mae: 0.2918\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 379s 198ms/step - loss: 0.1893 - mse: 0.1893 - mae: 0.3444 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2485\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 382s 200ms/step - loss: 0.1432 - mse: 0.1432 - mae: 0.2991 - val_loss: 0.0767 - val_mse: 0.0767 - val_mae: 0.2269\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 388s 203ms/step - loss: 0.1139 - mse: 0.1139 - mae: 0.2667 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.2129\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 387s 202ms/step - loss: 0.0933 - mse: 0.0933 - mae: 0.2410 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1960\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 368s 192ms/step - loss: 0.0779 - mse: 0.0779 - mae: 0.2197 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1878\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 367s 192ms/step - loss: 0.0672 - mse: 0.0672 - mae: 0.2039 - val_loss: 0.0474 - val_mse: 0.0474 - val_mae: 0.1822\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 365s 191ms/step - loss: 0.0592 - mse: 0.0592 - mae: 0.1912 - val_loss: 0.0437 - val_mse: 0.0437 - val_mae: 0.1753\n",
      "Epoch 10/10\n",
      "1912/1912 [==============================] - 358s 187ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.1795 - val_loss: 0.0405 - val_mse: 0.0405 - val_mae: 0.1688\n",
      "EndTime : 2023-03-15 22:55:03.338338\n",
      "Evaluating model 6...\n",
      "715/715 [==============================] - 26s 36ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1711\n",
      "loss=0.042032, mse=0.042032, mae=0.171068\n",
      "StartTime : 2023-03-15 22:55:32.392874\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 360s 182ms/step - loss: 0.1455 - mse: 0.1455 - mae: 0.2493 - val_loss: 0.0252 - val_mse: 0.0252 - val_mae: 0.1055\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 355s 186ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1376 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0791\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 356s 186ms/step - loss: 0.0260 - mse: 0.0260 - mae: 0.1098 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0754\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 355s 185ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.0942 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0733\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 350s 183ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0867 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0715\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 359s 188ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0833 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0692\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 351s 183ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0806 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0700\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 344s 180ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0784 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0700\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 344s 180ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0766 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0682\n",
      "Epoch 10/10\n",
      "1343/1912 [====================>.........] - ETA: 1:34 - loss: 0.0126 - mse: 0.0126 - mae: 0.0746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 325s 207ms/step - loss: 0.6269 - mse: 0.6269 - mae: 0.6217 - val_loss: 0.2252 - val_mse: 0.2252 - val_mae: 0.3826\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 310s 203ms/step - loss: 0.3353 - mse: 0.3353 - mae: 0.4591 - val_loss: 0.1453 - val_mse: 0.1453 - val_mae: 0.3071\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 319s 208ms/step - loss: 0.2399 - mse: 0.2399 - mae: 0.3889 - val_loss: 0.1127 - val_mse: 0.1127 - val_mae: 0.2715\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 313s 204ms/step - loss: 0.1858 - mse: 0.1858 - mae: 0.3415 - val_loss: 0.0906 - val_mse: 0.0906 - val_mae: 0.2437\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 312s 204ms/step - loss: 0.1489 - mse: 0.1489 - mae: 0.3055 - val_loss: 0.0763 - val_mse: 0.0763 - val_mae: 0.2254\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 315s 206ms/step - loss: 0.1224 - mse: 0.1224 - mae: 0.2771 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.2099\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 309s 202ms/step - loss: 0.1035 - mse: 0.1035 - mae: 0.2543 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.1989\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 308s 201ms/step - loss: 0.0892 - mse: 0.0892 - mae: 0.2356 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 311s 203ms/step - loss: 0.0781 - mse: 0.0781 - mae: 0.2204 - val_loss: 0.0474 - val_mse: 0.0474 - val_mae: 0.1795\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 309s 202ms/step - loss: 0.0685 - mse: 0.0685 - mae: 0.2062 - val_loss: 0.0458 - val_mse: 0.0458 - val_mae: 0.1772\n",
      "EndTime : 2023-03-16 00:46:50.881716\n",
      "Evaluating model 8...\n",
      "715/715 [==============================] - 24s 34ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1780\n",
      "loss=0.046456, mse=0.046456, mae=0.177979\n",
      "StartTime : 2023-03-16 00:47:17.702497\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 318s 200ms/step - loss: 0.1518 - mse: 0.1518 - mae: 0.2526 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.0884\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 305s 199ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1461 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0797\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 314s 205ms/step - loss: 0.0270 - mse: 0.0270 - mae: 0.1150 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0753\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 308s 201ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.0966 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0717\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 313s 205ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0886 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0695\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 300s 196ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0848 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0705\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 304s 199ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0820 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0723\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 305s 199ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0801 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0679\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 308s 201ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0779 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0675\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 299s 196ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0761 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0686\n",
      "EndTime : 2023-03-16 01:38:32.715853\n",
      "Evaluating model 9...\n",
      "715/715 [==============================] - 23s 32ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0786\n",
      "loss=0.016430, mse=0.016430, mae=0.078640\n",
      "StartTime : 2023-03-16 01:38:58.048172\n",
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 295s 225ms/step - loss: 0.6747 - mse: 0.6747 - mae: 0.6441 - val_loss: 0.2216 - val_mse: 0.2216 - val_mae: 0.3760\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 290s 228ms/step - loss: 0.3711 - mse: 0.3711 - mae: 0.4821 - val_loss: 0.1483 - val_mse: 0.1483 - val_mae: 0.3079\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 288s 226ms/step - loss: 0.2687 - mse: 0.2687 - mae: 0.4113 - val_loss: 0.1071 - val_mse: 0.1071 - val_mae: 0.2620\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 289s 227ms/step - loss: 0.2058 - mse: 0.2058 - mae: 0.3593 - val_loss: 0.0898 - val_mse: 0.0898 - val_mae: 0.2409\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 286s 224ms/step - loss: 0.1682 - mse: 0.1682 - mae: 0.3248 - val_loss: 0.0769 - val_mse: 0.0769 - val_mae: 0.2237\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 285s 223ms/step - loss: 0.1399 - mse: 0.1399 - mae: 0.2963 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.2116\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 282s 221ms/step - loss: 0.1173 - mse: 0.1173 - mae: 0.2707 - val_loss: 0.0585 - val_mse: 0.0585 - val_mae: 0.1953\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 286s 224ms/step - loss: 0.1006 - mse: 0.1006 - mae: 0.2507 - val_loss: 0.0496 - val_mse: 0.0496 - val_mae: 0.1797\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 308s 242ms/step - loss: 0.0871 - mse: 0.0871 - mae: 0.2335 - val_loss: 0.0444 - val_mse: 0.0444 - val_mae: 0.1690\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 284s 223ms/step - loss: 0.0772 - mse: 0.0772 - mae: 0.2193 - val_loss: 0.0424 - val_mse: 0.0424 - val_mae: 0.1664\n",
      "EndTime : 2023-03-16 02:27:13.452771\n",
      "Evaluating model 10...\n",
      "715/715 [==============================] - 23s 32ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1677\n",
      "loss=0.043652, mse=0.043652, mae=0.167745\n",
      "StartTime : 2023-03-16 02:27:38.840661\n",
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 289s 218ms/step - loss: 0.1983 - mse: 0.1983 - mae: 0.2876 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.0943\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 286s 224ms/step - loss: 0.0538 - mse: 0.0538 - mae: 0.1528 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0835\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 273s 214ms/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1263 - val_loss: 0.0172 - val_mse: 0.0172 - val_mae: 0.0864\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 284s 223ms/step - loss: 0.0249 - mse: 0.0249 - mae: 0.1091 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0768\n",
      "Epoch 5/10\n",
      " 158/1275 [==>...........................] - ETA: 3:32 - loss: 0.0202 - mse: 0.0202 - mae: 0.0995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 266s 209ms/step - loss: 0.0163 - mse: 0.0163 - mae: 0.0893 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0695\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 265s 208ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0845 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0705\n",
      "Epoch 8/10\n",
      " 113/1275 [=>............................] - ETA: 3:39 - loss: 0.0146 - mse: 0.0146 - mae: 0.0839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 268s 210ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0827 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0688\n",
      "Epoch 9/10\n",
      "1130/1275 [=========================>....] - ETA: 27s - loss: 0.0138 - mse: 0.0138 - mae: 0.0805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 363s 186ms/step - loss: 0.3372 - mse: 0.3372 - mae: 0.4484 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2576\n",
      "Epoch 2/10\n",
      "1217/1912 [==================>...........] - ETA: 1:58 - loss: 0.1426 - mse: 0.1426 - mae: 0.2978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 348s 182ms/step - loss: 0.0797 - mse: 0.0797 - mae: 0.2210 - val_loss: 0.0484 - val_mse: 0.0484 - val_mae: 0.1813\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 342s 179ms/step - loss: 0.0582 - mse: 0.0582 - mae: 0.1874 - val_loss: 0.0420 - val_mse: 0.0420 - val_mae: 0.1703\n",
      "Epoch 5/10\n",
      " 597/1912 [========>.....................] - ETA: 3:34 - loss: 0.0498 - mse: 0.0498 - mae: 0.1731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 353s 185ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1529 - val_loss: 0.0327 - val_mse: 0.0327 - val_mae: 0.1507\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 351s 183ms/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1439 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1433\n",
      "Epoch 8/10\n",
      " 545/1912 [=======>......................] - ETA: 3:47 - loss: 0.0337 - mse: 0.0337 - mae: 0.1390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628/1912 [========================>.....] - ETA: 49s - loss: 0.0311 - mse: 0.0311 - mae: 0.1333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 25s 35ms/step - loss: 0.0254 - mse: 0.0254 - mae: 0.1277\n",
      "loss=0.025373, mse=0.025373, mae=0.127677\n",
      "StartTime : 2023-03-16 04:12:56.120078\n",
      "Epoch 1/10\n",
      "1357/1912 [====================>.........] - ETA: 1:29 - loss: 0.0977 - mse: 0.0977 - mae: 0.2075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 335s 175ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.0882 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0761\n",
      "Epoch 4/10\n",
      " 884/1912 [============>.................] - ETA: 2:47 - loss: 0.0153 - mse: 0.0153 - mae: 0.0846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 330s 173ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0816 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0716\n",
      "Epoch 6/10\n",
      " 202/1912 [==>...........................] - ETA: 4:33 - loss: 0.0141 - mse: 0.0141 - mae: 0.0796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618/1912 [========================>.....] - ETA: 47s - loss: 0.0138 - mse: 0.0138 - mae: 0.0774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 332s 173ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0754 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0715\n",
      "Epoch 9/10\n",
      " 944/1912 [=============>................] - ETA: 2:35 - loss: 0.0128 - mse: 0.0128 - mae: 0.0740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 326s 171ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0740 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0680\n",
      "Epoch 10/10\n",
      "1716/1912 [=========================>....] - ETA: 30s - loss: 0.0126 - mse: 0.0126 - mae: 0.0729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 320s 203ms/step - loss: 0.4313 - mse: 0.4313 - mae: 0.5078 - val_loss: 0.1422 - val_mse: 0.1422 - val_mae: 0.2997\n",
      "Epoch 2/10\n",
      " 127/1530 [=>............................] - ETA: 4:42 - loss: 0.2277 - mse: 0.2277 - mae: 0.3748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 315s 206ms/step - loss: 0.1048 - mse: 0.1048 - mae: 0.2525 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1811\n",
      "Epoch 4/10\n",
      " 947/1530 [=================>............] - ETA: 1:49 - loss: 0.0779 - mse: 0.0779 - mae: 0.2165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 315s 206ms/step - loss: 0.0483 - mse: 0.0483 - mae: 0.1686 - val_loss: 0.0331 - val_mse: 0.0331 - val_mae: 0.1428\n",
      "Epoch 7/10\n",
      " 261/1530 [====>.........................] - ETA: 4:02 - loss: 0.0446 - mse: 0.0446 - mae: 0.1618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 308s 201ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1489 - val_loss: 0.0277 - val_mse: 0.0277 - val_mae: 0.1285\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 322s 211ms/step - loss: 0.0354 - mse: 0.0354 - mae: 0.1423 - val_loss: 0.0265 - val_mse: 0.0265 - val_mae: 0.1250\n",
      "Epoch 10/10\n",
      " 239/1530 [===>..........................] - ETA: 4:12 - loss: 0.0342 - mse: 0.0342 - mae: 0.1403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 24s 34ms/step - loss: 0.0273 - mse: 0.0273 - mae: 0.1256\n",
      "loss=0.027276, mse=0.027276, mae=0.125636\n",
      "StartTime : 2023-03-16 06:02:03.742557\n",
      "Epoch 1/10\n",
      " 957/1530 [=================>............] - ETA: 1:40 - loss: 0.1307 - mse: 0.1307 - mae: 0.2216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 311s 204ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0910 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0750\n",
      "Epoch 4/10\n",
      " 637/1530 [===========>..................] - ETA: 2:46 - loss: 0.0154 - mse: 0.0154 - mae: 0.0859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 311s 203ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0825 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0753\n",
      "Epoch 6/10\n",
      "   3/1530 [..............................] - ETA: 4:03 - loss: 0.0143 - mse: 0.0143 - mae: 0.0780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 306s 200ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0786 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0725\n",
      "Epoch 8/10\n",
      " 427/1530 [=======>......................] - ETA: 3:19 - loss: 0.0136 - mse: 0.0136 - mae: 0.0774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1530 [===========================>..] - ETA: 18s - loss: 0.0132 - mse: 0.0132 - mae: 0.0756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 296s 194ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0741 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0684\n",
      "EndTime : 2023-03-16 06:52:48.788519\n",
      "Evaluating model 15...\n",
      "715/715 [==============================] - 24s 33ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.0769\n",
      "loss=0.016008, mse=0.016008, mae=0.076916\n",
      "StartTime : 2023-03-16 06:53:14.729665\n",
      "Epoch 1/10\n",
      " 730/1275 [================>.............] - ETA: 1:53 - loss: 0.4871 - mse: 0.4871 - mae: 0.5459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143/1275 [=========================>....] - ETA: 26s - loss: 0.1062 - mse: 0.1062 - mae: 0.2561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 273s 214ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1866 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1493\n",
      "Epoch 6/10\n",
      "1080/1275 [========================>.....] - ETA: 40s - loss: 0.0474 - mse: 0.0474 - mae: 0.1699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 280s 219ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1566 - val_loss: 0.0281 - val_mse: 0.0281 - val_mae: 0.1341\n",
      "Epoch 8/10\n",
      " 649/1275 [==============>...............] - ETA: 2:03 - loss: 0.0372 - mse: 0.0372 - mae: 0.1492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 284s 223ms/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1414 - val_loss: 0.0258 - val_mse: 0.0258 - val_mae: 0.1283\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 279s 219ms/step - loss: 0.0318 - mse: 0.0318 - mae: 0.1367 - val_loss: 0.0251 - val_mse: 0.0251 - val_mae: 0.1261\n",
      "EndTime : 2023-03-16 07:39:47.891799\n",
      "Evaluating model 16...\n",
      "260/715 [=========>....................] - ETA: 15s - loss: 0.0256 - mse: 0.0256 - mae: 0.1263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 284s 216ms/step - loss: 0.1114 - mse: 0.1114 - mae: 0.2122 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0801\n",
      "Epoch 2/10\n",
      " 449/1275 [=========>....................] - ETA: 2:36 - loss: 0.0286 - mse: 0.0286 - mae: 0.1215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 273s 214ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0946 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0715\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 275s 215ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0869 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0778\n",
      "Epoch 5/10\n",
      " 706/1275 [===============>..............] - ETA: 1:51 - loss: 0.0150 - mse: 0.0150 - mae: 0.0844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 271s 213ms/step - loss: 0.0143 - mse: 0.0143 - mae: 0.0809 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0754\n",
      "Epoch 7/10\n",
      " 604/1275 [=============>................] - ETA: 2:15 - loss: 0.0137 - mse: 0.0137 - mae: 0.0789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 268s 210ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0779 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0714\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 271s 213ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0768 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0771\n",
      "Epoch 10/10\n",
      "  25/1275 [..............................] - ETA: 4:12 - loss: 0.0139 - mse: 0.0139 - mae: 0.0794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 267s 210ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0755 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0686\n",
      "EndTime : 2023-03-16 08:25:49.158965\n",
      "Evaluating model 17...\n",
      "715/715 [==============================] - 25s 35ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0780\n",
      "loss=0.016639, mse=0.016639, mae=0.078004\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"resnet_ht_models/cnv_model\"\n",
    "\n",
    "model_eval_dict = {}\n",
    "model_dict = {}\n",
    "training_epochs = 10\n",
    "model_ht_history = {}\n",
    "\n",
    "for i in hyper_param_dict:\n",
    "    params_dict = hyper_param_dict[i]\n",
    "    learning_rate=params_dict[\"learning_rate\"] \n",
    "    batch_size=params_dict[\"batch_size\"] \n",
    "    opt_name=params_dict[\"optimizer\"]\n",
    "    \n",
    "    # hyper parameters\n",
    "    num_classes = 1\n",
    "    if opt_name == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    else: # sgd\n",
    "        optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    with K.tf.device('/GPU:0'): # model compile\n",
    "        inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "        x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    #     y = x\n",
    "        x = Activation('tanh')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "    #     x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "    #     x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    #     x = AveragePooling1D(pool_size=8)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(units=2048, name='dense1'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout1') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    #    x = Reshape((300,1))(x)\n",
    "\n",
    "    #    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "    #    x = MaxPooling1D(pool_size=2)(x)\n",
    "    #    x = BatchNormalization()(x)\n",
    "\n",
    "        x = Dense(units=1024, name='dense5'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Dropout(0.1, name='dropout5') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=512, name='dense6'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout6') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=1024, name='dense7'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout7') (x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=512, name='dense8'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout8') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=256, name='dense9'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout9') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=128, name='dense10'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Dropout(0.1, name='dropout10') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN')\n",
    "        model.compile(loss=keras.losses.mean_squared_error,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['mse','mae'])\n",
    "        \n",
    "        # model training\n",
    "        StartTime8 = datetime.now()\n",
    "        print(\"StartTime :\", StartTime8)\n",
    "        with K.tf.device('/GPU:0'):\n",
    "            model_train = model.fit(train_X, train_y, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                                validation_data=(val_X, val_y))\n",
    "\n",
    "        EndTime8 = datetime.now()\n",
    "        print(\"EndTime :\", EndTime8)\n",
    "    model.save_weights(workdir+ f'/model_{i}_new.h5')\n",
    "    with open(workdir + f'/model_architecture_{i}_new.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "        \n",
    "    # evaluation\n",
    "    print(f\"Evaluating model {i}...\")\n",
    "    test_score = model.evaluate(test_X, test_y, verbose=1)\n",
    "    model_ht_history[(learning_rate, batch_size)] = model\n",
    "    loss, mse, mae = test_score\n",
    "    print(\"loss=%.6f, mse=%.6f, mae=%.6f\"%(loss, mse, mae))\n",
    "    \n",
    "    model_dict[i] = model\n",
    "    model_eval_dict[i] = {\"loss\":loss, \"mse\":mse, \"mae\":mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mse = 10\n",
    "bst_model_id_lst = []\n",
    "for i in model_eval_dict:\n",
    "    if model_eval_dict[i]['mse'] < min_mse:\n",
    "        bst_model_id_lst = []\n",
    "        bst_model_id_lst.append(i)\n",
    "        min_mse = model_eval_dict[i]['mse']\n",
    "    elif model_eval_dict[i]['mse'] == min_mse:\n",
    "        bst_model_id_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_model_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.016008485108613968,\n",
       " 'mse': 0.016008485108613968,\n",
       " 'mae': 0.07691584527492523}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval_dict[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005, 'batch_size': 100, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_dict[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_dict[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ht_history[(0.0005, 100)] is best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"resnet_ht_models/cnv_model\"\n",
    "\n",
    "json_file = open(workdir +'/model_architecture_15_new.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(workdir +\"/model_15_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.0005),\n",
    "                  metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 29s 37ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.0769\n"
     ]
    }
   ],
   "source": [
    "test_eval = best_model.evaluate(test_X, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016008485108613968, 0.016008485108613968, 0.07691584527492523]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 290s 218ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0726 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0726\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 282s 221ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0714 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0666\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 275s 216ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0705 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0661\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 279s 219ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0695 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0689\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 283s 222ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0685 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0656\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 286s 225ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0673 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0648\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 286s 225ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0666 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0658\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 283s 222ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0656 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0624\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 282s 222ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0648 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0654\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 281s 221ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0637 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0611\n"
     ]
    }
   ],
   "source": [
    "model_train = best_model.fit(train_X, train_y, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                                validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Test_v2_DNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 2649, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_330 (Conv1D)            (None, 1325, 16)     64          ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_15 (MaxPooling1D  (None, 265, 16)     0           ['conv1d_330[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_405 (Batch  (None, 265, 16)     64          ['max_pooling1d_15[0][0]']       \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_405 (Activation)    (None, 265, 16)      0           ['batch_normalization_405[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_331 (Conv1D)            (None, 265, 16)      784         ['activation_405[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_406 (Batch  (None, 265, 16)     64          ['conv1d_331[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_406 (Activation)    (None, 265, 16)      0           ['batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_332 (Conv1D)            (None, 265, 16)      784         ['activation_406[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_407 (Batch  (None, 265, 16)     64          ['conv1d_332[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_407 (Activation)    (None, 265, 16)      0           ['batch_normalization_407[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_333 (Conv1D)            (None, 265, 16)      784         ['activation_407[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_408 (Batch  (None, 265, 16)     64          ['conv1d_333[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_135 (Add)                  (None, 265, 16)      0           ['batch_normalization_408[0][0]',\n",
      "                                                                  'batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " activation_408 (Activation)    (None, 265, 16)      0           ['add_135[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_334 (Conv1D)            (None, 265, 16)      784         ['activation_408[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_409 (Batch  (None, 265, 16)     64          ['conv1d_334[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_409 (Activation)    (None, 265, 16)      0           ['batch_normalization_409[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_335 (Conv1D)            (None, 265, 16)      784         ['activation_409[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_410 (Batch  (None, 265, 16)     64          ['conv1d_335[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_410 (Activation)    (None, 265, 16)      0           ['batch_normalization_410[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_336 (Conv1D)            (None, 265, 16)      784         ['activation_410[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_411 (Batch  (None, 265, 16)     64          ['conv1d_336[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_411 (Activation)    (None, 265, 16)      0           ['batch_normalization_411[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_337 (Conv1D)            (None, 265, 16)      784         ['activation_411[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_412 (Batch  (None, 265, 16)     64          ['conv1d_337[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_136 (Add)                  (None, 265, 16)      0           ['batch_normalization_412[0][0]',\n",
      "                                                                  'batch_normalization_409[0][0]']\n",
      "                                                                                                  \n",
      " activation_412 (Activation)    (None, 265, 16)      0           ['add_136[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_338 (Conv1D)            (None, 133, 32)      1568        ['activation_412[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_413 (Batch  (None, 133, 32)     128         ['conv1d_338[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_413 (Activation)    (None, 133, 32)      0           ['batch_normalization_413[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_339 (Conv1D)            (None, 133, 32)      3104        ['activation_413[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_340 (Conv1D)            (None, 133, 32)      3104        ['conv1d_339[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_414 (Batch  (None, 133, 32)     128         ['conv1d_340[0][0]']             \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_137 (Add)                  (None, 133, 32)      0           ['batch_normalization_414[0][0]',\n",
      "                                                                  'batch_normalization_413[0][0]']\n",
      "                                                                                                  \n",
      " activation_414 (Activation)    (None, 133, 32)      0           ['add_137[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_341 (Conv1D)            (None, 133, 32)      3104        ['activation_414[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_415 (Batch  (None, 133, 32)     128         ['conv1d_341[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_415 (Activation)    (None, 133, 32)      0           ['batch_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_342 (Conv1D)            (None, 133, 32)      3104        ['activation_415[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_416 (Batch  (None, 133, 32)     128         ['conv1d_342[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_138 (Add)                  (None, 133, 32)      0           ['batch_normalization_416[0][0]',\n",
      "                                                                  'batch_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " activation_416 (Activation)    (None, 133, 32)      0           ['add_138[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_343 (Conv1D)            (None, 133, 32)      3104        ['activation_416[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_417 (Batch  (None, 133, 32)     128         ['conv1d_343[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_417 (Activation)    (None, 133, 32)      0           ['batch_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_344 (Conv1D)            (None, 133, 32)      3104        ['activation_417[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_418 (Batch  (None, 133, 32)     128         ['conv1d_344[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_139 (Add)                  (None, 133, 32)      0           ['batch_normalization_418[0][0]',\n",
      "                                                                  'batch_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " activation_418 (Activation)    (None, 133, 32)      0           ['add_139[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_345 (Conv1D)            (None, 67, 64)       6208        ['activation_418[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_419 (Batch  (None, 67, 64)      256         ['conv1d_345[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_419 (Activation)    (None, 67, 64)       0           ['batch_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_346 (Conv1D)            (None, 67, 64)       12352       ['activation_419[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_347 (Conv1D)            (None, 67, 64)       12352       ['conv1d_346[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_420 (Batch  (None, 67, 64)      256         ['conv1d_347[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_140 (Add)                  (None, 67, 64)       0           ['batch_normalization_420[0][0]',\n",
      "                                                                  'batch_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " activation_420 (Activation)    (None, 67, 64)       0           ['add_140[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_348 (Conv1D)            (None, 67, 64)       12352       ['activation_420[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_421 (Batch  (None, 67, 64)      256         ['conv1d_348[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_421 (Activation)    (None, 67, 64)       0           ['batch_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_349 (Conv1D)            (None, 67, 64)       12352       ['activation_421[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_422 (Batch  (None, 67, 64)      256         ['conv1d_349[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_141 (Add)                  (None, 67, 64)       0           ['batch_normalization_422[0][0]',\n",
      "                                                                  'batch_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " activation_422 (Activation)    (None, 67, 64)       0           ['add_141[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_350 (Conv1D)            (None, 67, 64)       12352       ['activation_422[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_423 (Batch  (None, 67, 64)      256         ['conv1d_350[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_423 (Activation)    (None, 67, 64)       0           ['batch_normalization_423[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_351 (Conv1D)            (None, 67, 64)       12352       ['activation_423[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_424 (Batch  (None, 67, 64)      256         ['conv1d_351[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_142 (Add)                  (None, 67, 64)       0           ['batch_normalization_424[0][0]',\n",
      "                                                                  'batch_normalization_423[0][0]']\n",
      "                                                                                                  \n",
      " activation_424 (Activation)    (None, 67, 64)       0           ['add_142[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 4288)         0           ['activation_424[0][0]']         \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 2048)         8783872     ['flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_425 (Batch  (None, 2048)        8192        ['dense1[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)             (None, 2048)         0           ['batch_normalization_425[0][0]']\n",
      "                                                                                                  \n",
      " activation_425 (Activation)    (None, 2048)         0           ['dropout1[0][0]']               \n",
      "                                                                                                  \n",
      " dense5 (Dense)                 (None, 1024)         2098176     ['activation_425[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_426 (Batch  (None, 1024)        4096        ['dense5[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout5 (Dropout)             (None, 1024)         0           ['batch_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " activation_426 (Activation)    (None, 1024)         0           ['dropout5[0][0]']               \n",
      "                                                                                                  \n",
      " dense6 (Dense)                 (None, 512)          524800      ['activation_426[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_427 (Batch  (None, 512)         2048        ['dense6[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout6 (Dropout)             (None, 512)          0           ['batch_normalization_427[0][0]']\n",
      "                                                                                                  \n",
      " activation_427 (Activation)    (None, 512)          0           ['dropout6[0][0]']               \n",
      "                                                                                                  \n",
      " dense7 (Dense)                 (None, 1024)         525312      ['activation_427[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_428 (Batch  (None, 1024)        4096        ['dense7[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout7 (Dropout)             (None, 1024)         0           ['batch_normalization_428[0][0]']\n",
      "                                                                                                  \n",
      " add_143 (Add)                  (None, 1024)         0           ['dropout7[0][0]',               \n",
      "                                                                  'batch_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " activation_428 (Activation)    (None, 1024)         0           ['add_143[0][0]']                \n",
      "                                                                                                  \n",
      " dense8 (Dense)                 (None, 512)          524800      ['activation_428[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_429 (Batch  (None, 512)         2048        ['dense8[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout8 (Dropout)             (None, 512)          0           ['batch_normalization_429[0][0]']\n",
      "                                                                                                  \n",
      " activation_429 (Activation)    (None, 512)          0           ['dropout8[0][0]']               \n",
      "                                                                                                  \n",
      " dense9 (Dense)                 (None, 256)          131328      ['activation_429[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_430 (Batch  (None, 256)         1024        ['dense9[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout9 (Dropout)             (None, 256)          0           ['batch_normalization_430[0][0]']\n",
      "                                                                                                  \n",
      " activation_430 (Activation)    (None, 256)          0           ['dropout9[0][0]']               \n",
      "                                                                                                  \n",
      " dense10 (Dense)                (None, 128)          32896       ['activation_430[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_431 (Batch  (None, 128)         512         ['dense10[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout10 (Dropout)            (None, 128)          0           ['batch_normalization_431[0][0]']\n",
      "                                                                                                  \n",
      " activation_431 (Activation)    (None, 128)          0           ['dropout10[0][0]']              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1)            129         ['activation_431[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,752,209\n",
      "Trainable params: 12,739,793\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse and loss monitor\n",
    "accuracy = model_train.history['mse']\n",
    "val_accuracy = model_train.history['val_mse']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 28s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# test validation\n",
    "predicted_classes = best_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_y)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '/DeepAUCv2_epoch_10_ht_result_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776219</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935249</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.890053</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941818</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882936</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>0.743234</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>0.979556</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>0.899360</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>0.983109</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>0.727004</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted      Test\n",
       "0       0.776219  0.528562\n",
       "1       0.935249  0.930958\n",
       "2       0.890053  0.759249\n",
       "3       0.941818  0.936510\n",
       "4       0.882936  0.823453\n",
       "...          ...       ...\n",
       "22873   0.743234  0.975578\n",
       "22874   0.979556  0.980529\n",
       "22875   0.899360  0.960501\n",
       "22876   0.983109  0.970524\n",
       "22877   0.727004  0.706073\n",
       "\n",
       "[22878 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22878, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted_AUC_value')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA95UlEQVR4nO19e5RlV1nn76tbVWmqqgP07WQGhapOJC6JOMOjxTDjCNgEY6NhucAYVqUJDNKkMg5RRCdYrlGYacVhQMOEENoIJKlCUBkwYpRZIpAlQzQVknRCNJk8umOERZIOr6bAJN17/thnW6dO7ce399nnnPv4fmt9q+ree/Y++zz2997fJqUUBAKBQDC+mOh6AAKBQCDoFiIIBAKBYMwhgkAgEAjGHCIIBAKBYMwhgkAgEAjGHJNdDyAFO3fuVLt27ep6GAKBQDBUuPnmmx9RSp1S/X4oBcGuXbuwtrbW9TAEAoFgqEBER2zfi2tIIBAIxhwiCAQCgWDMIYJAIBAIxhwiCAQCgWDMIYJAIBAIxhwiCAQCgaAjrK4Cu3YBExP67+pqN+MYyvRRgUAgGHasrgL79wPr6/rzkSP6MwAsLrY7FrEIBAKBoAMsL28IAYP1deCSS9ofiwgCgUAg6AAPPGD//ujR9l1EIggEAoGgA8zPu39bXm5vHIAIAoFAIGgdq6vAsWPu348cAXbubC+ILIJAIBAIWoQJEh896j/u6FFAKS0ULrhAC4amBIIIAoFAICjQVDpnud8LL9waJObg6FEtQJoQBiIIBAKBABua+pEjG5p4DsZb7ff48fS+1tebiR+IIBAIBAK40zljGW/VqrjkkjQLwIUj1kLS9SCCQCAQCOBO53R9b4PNqgjFAmJBlN89JIJAIBAI4E7n9KV5VmGzKnJDqfzuIREEAoFAAODAAWBmZvN3MzP6ey5irIc6yH2eRgUBEX2AiB4iojscvxMRvYeI7iGiQ0T0vCbHIxAIBC4sLgIHDwILC9r9srCgP8fU/YmxHuog93matgg+BOAcz+8/CeCMgvYDeF/D4xEIBAInFheBw4eBEyf039jibzarogns3Zu3v0YFgVLqBgCPeg55BYBrlMaNAJ5CRE9rckwCgUDQFMpWBaAtiyZw/fV5++s6RvC9AP6x9PnB4rstIKL9RLRGRGsPP/xwK4MTCATDAc5CsNTFYrZ25jsiYHJS/zW/Gaui39eB3SaQPRahlGqUAOwCcIfjt08C+NHS508D2B3q8/nPf74SCFxYWVFqYUEpIv13ZaXrEXWDYbsPZryAUr2e/ssZ98qKUjMz+nhD09NK9fsb1760tPWYmZnNfZfv1+ysUhMTm48fNEp5ngDWlI0X277MSQFB8H4Ary59vgvA00J9iiAQuGBjClNTm5nCoDNEDlZW9DWZa+z3tzK1EOPrCjYBZRuvi8y1rqxoht81Q+6KUp7noAqClwP4CwAE4CwAf8fpUwTB+IGr3RqNMvcEaguc6/QxQCPwjEZdpYWF5sZlOx7YrN27NPOyUBPiU+zz7EQQAPhDAF8B8Di0///1AC4CcFHxOwF4L4B7AdzOcQsplU8QDJvp3CRSzfKcWFraOHevpz9XNd8QMydqZgJVUX53+v2tFkfod1efNq24qu1zhJ2PXMLFNRdWVrRVVe5jYkK7T8znubmNa+z3tx5viPt8hHhEFPfedmYRNEE5BEEO09k1eVIETFtCKdYsL9+TumP0tV9asp/f56e1MfMYJlnnOnxujOlpNyMsM8PquX1jLz+HHMx0dpbnP3c9F6HBoH4/7t0VQVCBa9JxNUUXM5id3coEZmb0hPJpXNW+XMyiDlzCL2SWmzG4mAXXnWFrb+5LyiSwaUMxvubqdbjuWdVScrldUqh8bu6kr2sRcGlurp3zCKWTCIKacGlVXFMrdjJWz1dmAKG+cvm06zBcX9vqtRFpBs85dx3t1iW0q24ZTkDR1leKUEm9jpUV/r0Qf7qQIXEN1URdiyCXr5PLnOv6tOuMOUWAEG0WXrl9wzHCcWWFp8VXrZq2NO+QoBUSctFQBIubokGIEeScuBwmGSv5bUjRJI37JoWRl1/S1PtlixFUg6ccxI6/DUugfJ8kiCqUQrnSR7teWdwZ6haYiqkpElpmrlT4mLpFplZXga99jXdsr6f/mnty/fV6jLEor3603S/fNfd6wNIScM01m5/RygrwyCP+52RbCRp7/9bXN+5DCLOzehWpGWO/H3euY8eAHTvi2ggEQHwtJCds0mHQaVDWEbhSGzmrGm1ktGZfPME3Fle6Ivf8ZgxV1HEpucbIXe1pa+e7F76gdIqWz4kvVAN2odjCoK9YFRoeigXENdQcuFkzPvdImWmmLN7xMR4uI3cJnBwxgpR7F7uGwDfWVL+/WZUcOq46HlfapVESumYgQqNBsRBBYEEXC8qaWPpfJ17hSlMNZd5wGFru+1Qml+D0XWdqANiciyvIfcea/P2uGYjQaFAsRBBU0GUtltwCKPUl6vX4Of+Aziuvjrlu9pULHIbtG2uV+v30ALAJ1K+shI8xEGYv1DRNT8fPKxEEFTTFwLjIJQy4+eecuENIY7a5e2IFKve6OdfE1fBz1LIxY/X1wxGQQkK5KHYxmVJKiSCooO6CsjoIMc8qw/GlS3IYjrlWXw0hrmbtWnjFKbXBDQ5zr8sExEPXnpr+WiVO0NkcI3EAoaYphVeJIKigS4sgFNC01amZnk4rssbNQOJqsNyXz1c2g3PPYwQT55hcGjrHMhC3kFAblMKrRBBU0GWMwGeNxAQklfILlRhhF1PegOPeiS3+VkbZ5RNKteSkhRqXVq5FYm2uOhYSclEKrxJBYEEXWUNK+Rl0iCHH+Ohj3F9cxjY5udVisWUexWjFZV9nLMPmpoUa11QOBi4av9AgUApEENRETqHhY97cAnS+BWTmd5c23WSBNe51lGlubuNaYit7loVa6BpSxiYkNKgkFkHLgiCHG8kWOHUFWH217AF7KmQ12OxaETs15U4ZzRXgNNfXhubsWr3c9SQVEmqaJEZQUxDYasz7tPy6geWUFMsUpmzWBfgYoS3lrIlyy20UbbOVuzYQ943QqJNkDdUQBD6mF7v9oWtjFG4545AgSdFsOYHTOucJ7b4F5N24JUQTE3a3mAgCoVEnsQhqCAJOUJHbproy16X5u84VkugxKZixLw+nLEOV+n2tgZf3qq1Sm+WbbTQ11a4gEhLqivbsied/IggKcPLuq+BaET6BYfueI9GrFkadF8fEB7iuoF5vq6btswZCFlC/L/57IaFc1OvF8z8RBAVSLAKlNINzMXTjd/cJmVxrFlIZaXl1MrcsQ3V8vnZloWHL7TdVPEOCWLR5ISE+xUIEQYGUGIGBj4n5ctTLmjK3pr6vNHOM+8Vm4XCZcfXcXDfS9PTmrKiYfYObCFwLCY0iiUXQctaQQaggW0wtHd/YQn3Y1hD4Xpjqtbmuw1QXdZ07JpOpnJ0Ua4FUr29urrvJJiQ0qCQxgo42pvGVIQbiNX8bUjOMuIupOMdWKdW3zwlGV2MQrnsnWUBCQptJsoYaEARcBh4qNlYXKVVRbRZO6MXJuYCs7svMCWCLIBAS2kyyjiCzIIhZ8OXLUc9RuTTWIojR7qsvzqBk8Iw6k5c9ioWaoJwWwUSdje9HBcvLwPr65u/W1/X3VSwuAhddBBBt/n5mBjhwoP5YDhzQfXH7to3dhYkJYHV14/MDD6SNMTeU6noEzeLEia5HIBg15OI3/wKbdBh0ym0R1HHH5KxcmhLEjtWmOeseuNTv2yuRSnBXSKhZcpVWCQFiEbgxPx/3fQ6srgK7dmktfdcu4OKLgf37gSNH9O/Hj+u/x475+/GNsWq1AJstHZv1wcHMDLCyAszNAY8/vvk3pfgWikAgSMM112Tu0CYdchKAcwDcBeAeAJdafp8H8BkAtwA4BGBvqM8uYwQpx3Pa+yg0lliroGzpLC1t9WH7UlInJjbG0rVWJCQ0ztRZGWoACwBeWvz/JADbA8f3ANwL4HQA0wBuA3Bm5ZiDAJaK/88EcDg0ji6zhpSqX400NRXThdS+fNtiLi3pTWiqv/V6vBXCXRORBGmFRps6CRYT0RsA/AmA9xdfPR3AJwLNXgDgHqXUfUqpxwB8BMArqkYJgJOL/58M4MvcMeXE4qJ2lczP6yDq8rJ239hcOMZ9U8WRI5uPLQdmy0gJ0vraLCzE9bV3r/67vLzVtQMAjz0GvO99wBNPbP3t+HHg6FH9KnaBiQmg39dur37ffZxSwORke+MSCNpG1mQPm3SwEYBbobX6W0rf3R5o8yoAV5U+7wNweeWYpwG4HcCDAL4G4PmOvvYDWAOwNj8/Hy8KA7C5a6ameKURDOXeKJ4r/ZeW0voadK3eReX72vVYhIS6oq7SR/9Zaa0eAEBEkwBUugj6F7wawIeUUk8HsBfAtUS0ZVxKqYNKqd1Kqd2nnHJKhtNuhi0N8/HHtXbMharcDVcKamyQlmjD2rBZGddfz+8L0H2trgI7dsS1GxSsrwMXXqitg16v69EIBN0gZ/pojPH8OSL6NQBPIqKzAVwM4M8Cbf4JwDNKn59efFfG66EDylBKfYGItgHYCeChiLHVRlM59bZ+Fxf130su0W4WG4i0YDF/Ac3A9+/fOGZ5WfdfFUAc7N9vzyrKiYUF4JFHgG9/O3/fJqvK/BUIxg2Gj+RAjEVwKYCHod04bwRwPYBfD7S5CcAZRHQaEU0DOB/AdZVjHgCwBwCI6FkAthXnaRVNpYq6+l1cBC67zO3nVkpruzYr46KLNlJNU4SA6acJBg0A09M6vfTwYUklFQiagisGmQSbvygnQbt77obOHlouvns7gHOL/88E8HnojKJbAbws1GdTWUPVGEHdrJPYFNRBJLMbWexOZgaDUsZCSGjUqJOicwDuB3Bflbjtc1JOQWAr6eyqoU+kS7+6BESZWZY3gqmeZ2FhMAq+hWh21r/jmIvK6xRCu5oJCQmlUc6iczExgt2l/7cB+FkAQxpu1Fhd1S4W4744elS7NXbssPvulQLuuUf/taH8/Xe+4z6PK/20LrZtA7773Xz9ffvbm8fNRdkdZvyY+/a575tAIIhHTnc2O0aglDpaon9SSv0egJfnG0r7sGUKPfaYO4AL6OAs5wGsr+tgsOs8dWErenfVVcDSks6myYX19bjMHCLgmc/cvJ5CIBDkxdRUR0XnADyvRLsBXATgNm77nJTLNZSSRx+7nWJKCQgOzc5uuLG4O5DVoTrxjJmZ4XCFCQkNC5XjcDFABtfQu0r/PwHgMIDzskijjjA/H+emMaVfjbvDpG9OTLjTGJeX3efp93XhtiNHtNZ9/LhOuTx2zG+VANptoxRw7bUb59m3L/6aOOj3gfPOAw4eTEvXXF/XLqupKftKZoFAEIcQf4iGTToMOuWyCGI0e1/9odAWlin7ENvKO7s0g2rfnO0hY7SP6ek8Vo3U/hESykMpG9crpRQcFgHp39wgojcHBMm7cwomDnbv3q3W1tay9LW6uqHZ79gBfPObm7XWmRmtCYcWb/R69g1Iej1ds6d8nvn5zZZFNZgM6KD19u3Ao4+mafnlhWgCgWD0kDK/iehmpdTu6vecsOL2AA01Fhf1wqcTJ/Qq2A9+ULtniPTfgwf1caFicq5dqIwrxZzHuHL27dvoyxW0npvT/R4+HF9YTqmNNibYK+UYBILRQCw/CMJmJgw6NbGgzAWXW2dpibcuoLphvK0vl/lXzcePCdiWS02bcXZtzvpIgslCQnzKvUPZli9cBL124D8BuALABwxx2+ekpgVBmXmaLSOrVGWs09Nb/frVOIArm8d1jurKwZWVjZW+PjLnbXr1slk0J6uHhYTapZRVxUop5RIEMRnn1wL41wB+AsDnoAvIfSujcTIQuPhi7bYxdXxcWTJKbf782GPAySdvdSuVYwuuwnbHj/M3rA/VByq7sy68sNlaP0eP6tjG3r1pW14KBII0ZF+UapMONkKxDwGAQ8XfKQA3ctvnpKYsgro5/6El376dzUI7pHG0+7I7qM06Rma8LsumCWrzXEJCg0a5s4ZiLAKTS/N1Ino29G5ip+YTSe2juvvYJZfo2xyCq3xzaMWxax8Cs0G9CVofPrw1S4mzOtlYEE2sZPbhyBF9zrZKQs/MAFdfrZ/VykreldQCwTAg+1yzSQcbAfh5AE8F8CLognMPAXgjt31OymERxGrNvd6Gtr60lL55/cqKPTAaas+xVGKOBYbTt29bUT3ogXAhodyUO0aw5QsXAehxj22acgiCGCZIZHfVcDe7rx7PDQ7HjDe29LM5V9PZOm2UlxBBIDRuxFE6bcghCB4AcBB6ExnitmuCcggCLvMgSk/VMuBaH74YQ0jzLQuC0PlM+mvTDNpkFQ3L3gtCQsNCqXAJghjv6g8A+CvoFNLDRHQ5Ef1oFv9UB3D58/v9zZk/114LXHGF/q0aU+DuEMT12ftiDIuL+hVw4dFHNx978ODGdfT7msw1XXih9rFnr1dSwde/vvH/k5608X+/r337KyuyyE0gSEHW3ckAbJEMHIKOFVwD4HhK+7qUK0ZQ3XhmenrD5Kq6fmxxgakpdwXQMjjWByfG4NPgY3yGbcYGQusrutashISGkbpcRwAiehERXQHgZugFZkNdfVQp+2dT+8esJThyBLjyyq1a/eOPa63aHLN/v11SuzT9Xs++5sBmeayuAt9yrNqYno6rTe5az9AEHntsa8XR9XXggguAnTvdGVgCgcCNLtcRHAbwcQCvBjDLbdcENRksXliopzHbJLXNR26shKolsbS01YLwBVwnJvyWhC2oPYzZQkJCQhuUex3Bli9cBODkwO9v5fZVl5oMFhPlX1TmShk1VCd4Gwow24K027bJPsJCQsNOKXAJgpitKr8ZOORnEwySzrDDsdvy/LzblcNxY1TbGjeTLzC7vq5dTynBW1+A2RWk/u539askEAiGE7mrj+Zckzk03t7VVb3vQBXG125bATwzA/z4j4ezXPbu3fyZmzEUYsz9Pr8ekYEvFvDEE5KxIxAMI0LzPgU5BcHQ6JjLy/YtE7dv1wHbavqlSbn8whfCS7uvv37z5xyBWSLgssu2jqm6V8LOnZpMkDlUCO74cb19pEAgGB5wNsqKRXCHMnZHRLcopZ6bpbMA6u5QNjFh18CJ3BvM7NrFi9RX++C28/V30UUbaxkMVld1baSm1wIIBILBQh2WXWeHMi7+OGNfjcLlV/f527mafbUPV6E5Dvr9zQvaDDhxh2GCFI0TCLpFcAoS0TuJ6I2W799IRO8wn5VSv5V7cE3BFQPw+d1ClUVdfZTdTFwsLOhVt488otvbqqS2WV3Uhpz5/ydO6G05xU0lEISRfVUxgC1pRFWCXjy2pbYQtBC5I9S+CUpNHy3n1Pf7vFXB5bapK4td7as0NZW2D0HblLIXgBSGExLKQ6mripVSCqnrCHzMHsCXQu2boBRB4NovOKZqaKzwKCO0iGt21t6fLP4SEhof2rYtfExoAywf6giCmwCcYfn+DFenTVOKIPCtJHYhVXjY4NOI6+5DYMjU6u/qJTaC0nfMxER34xMSGnTizPdypeFYuHg2J0z3XwH8BRG9loh+qKDXAfjz4jcviOgcIrqLiO4hoksdx5xHRHcS0ZeI6MOMMUXDFez1BYFtawDW1/X3Nviqk7piDAsL/lQwTmzCVPM8dkzHFTjxCK6Pv98HZmfDx01NAeedB3znO+5jFhaAa66R+kICgQtKdXbisAYO4NkAroaOF9wMXXn0hxjtegDuBXA6gGkAtwE4s3LMGQBuAfDU4vOpoX5zWwSuTWZitPiQ9VDHNRXSEKr92M41Pb3ZrbVnD79fjiZj+ueMsWutS0homKkT11AdAvBCAJ8qfX4rKjWJAPwPAD8f02/OGIFv20mff77KfDmup9hdzUwbzstRdXGVx2+Cu+acMds75opRLC2Fd2gTEhIKU1fB4j8DcF2J/hTAHwC4gNH2VQCuKn3eB+DyyjGfKITB5wHcCOCcUL85soZClTh7PbuQcD0QXxG7mPFUEcOIuVZKbBxhdrbei9vvD17mk5DQIJOLn6TGKA3qCIIXWehnAHwMwDsCbTmC4JPQ5a2nAJwG4B8BPMXS134AawDW5ufnk29Elfn6HoaxGHwPyyA2GM11FcUEi7lWSixVN/BxkY3ht7FnsZDQoJDZ2raJdGmz9WsdZHcNFf7/WwPHcFxDVwJ4XenzpwH8sK/fOhaBa18AF/n2J6i6fXw7nlXBFRyxzJxjpaQQJ9tnaclu5cgaAqFxoqZcn3VcQgYuQZC8uF8pFSi/BqBIPSWi04hoGsD50O6lMj4B4MUAQEQ7AXw/gPtSx+WDLQtIKX8Wy5EjOhunCtsqYqX8n8vgZDGtrtrP7UO5vW9f5tiyFydOhNtcf73OgDp8WJfGAIB9+9z3V0pLCEYRocKUqWh0Z0GbdCgTgB0W+j4AbwOwymi/F8Dd0NlDy8V3bwdwbvE/AXg3gDsB3A7g/FCfqRaBTzN1SXFbG5uJFusaCh3vc0mFtBHfPsvGfRTaLMd2zUtLYW1HFsAJtU3DZHHOzaXPkSYtgi1fbDkAuB9aQ7+/9P9NAN6JwK5lTVGqIHA9ANdCKNcL1uvxffmuYLEvRsDNFOKQWWRWDUjH+jFnZ8MB32GakEJCsZRDyTH8IKV0TN34gFJKJQsCHwGYqtM+lXLGCKam7MHQkLackj5qG48tayi3Vl2tidRUMEto/KhuRtmwkEkcqTtvqhZ7zFwfqGBx4crZA51C+tXY9jmozp7FVeY7N2e/6ZxN7KvB4lzlKEIvhDBxoUGhccoKyz3vOOuVXG1SUVsQADgLwHsAPADgGIALUawGbptybF6vlN8FQxQ236pun5gFY75jfX74fr99P/zExPhMdiGhGOr16s0NM/dj3ERdLSj7LQD/Dzqt8+cB9AHcH2rXJOUSBD6Gam62L/3RV/ypWrW0bHnMzmp3TbkvbgkGE0Ootm+KTFXUQSyHLSTkorasZqMwps7HcsyAq+B1VX30IQB/A7047KTiu/tC7ZqkXIKAW0vIJfFdgiCVaRrh4wtqm/65i7xSxuCyZGIzjYSEhoUmJsKVBGxk5kvqfKy6lzkCrCuLoAfgHOiicw8CuBbAVwBMhto2RU1bBFUG73s4OYO9voyCssXQlGuo/DK7AlOSHirUNM3OdhMHi10IluLjL1N1wSmnn85jBLoPnATglQD+BMBXAXw4pn0uyhkj4AR4XQ+o+rKatqkvMbdAXZuTxKwWFktAqE1q6n3zpXnH9FNOIU+dj2ULnytM6mYOZU8fBXAygNeUPl+Y2lcs5RIESvECvDGLuzjZRjaKkfRta+WTk3HHN+W2EhoPalLRmZzc6s+PPZ+JC9Sdj5yEFBvVsQoaWUewqSPgi7n6ClFOQVBFTIVSF8U+XFOoKmaMqYHbhQXR7oXGm8qZdyl1gapzNXUBaJ0MwNQ4QRuC4JZcfYWoKUHgchXFPKBeb6OvmJcsRspXXTX9vt5oJnS+cgxC1iIIjSulauI+hS1lYV1IIfPN59TMobG3COrU/o/VGgximS1HynN2QnP1PzGRXmJCSGhUKNV9W55jVYui34/fj7vOJk1iEah4QdBE7X/XseUHlPKypQqrGDfW3NzG+gZTekI2lRcaRpqejtPGQ1uquqi8rshlScSOJdUtNOgxgstz9RWiWEGQu/a/qcQZEi4psYLQA/cJq5S4gelPBIHQMNBJJ9mLKPoYsHnHU7R2IC51m6vhp6aecre4daHOOoI3+yjUvgmKFQTcyqBcxl3WDmwafHVVsXlx+/24ctfmxeLs9yv7AAsNK3EscTMPXPC1NfMyNUkiV+q2i1dwFbiuy1D/RkEfLkpNvKuguwGshNo3QU1ZBErxcuZD+xC7LIWm0j6l9IPQsJIpX8Ip91KdZ9wtZw1SxhfrNXApZD7lsfydT1EciDLUAG4AsL30eTuAG7jtc1JTMQLXsZwX08AndHJvHVknxVVIqElK0XJzW+6AjocZpFyHLVXUdW5Tqtq2Ha5ZmFnHnRyTYu5CDkFwl6k1VHw+CcBd3PY5qamsIaV4DNX3QHwvc25mXb0+yQISGgQyq25DWq6h0HGpsTxALx6r4xryWSPmWoHNLmBbvMJXrrt6jpUVd3n8PXvcvIeDHIJgGcBtAH6zoFsB/Bq3fU5qch1B6sth0KZmXh17rk1CRKAI1aGyohRytYbetbrZfcBmt0xsLI2Tr1+3Mq/tHL5xdl5iAsDzAFxS0HNj2uakuoLA5afjPszYGEETVC6Ml+Oc5sUz96Pp8Q8ijYMAzFVrx0VljbXue+kKEMcqW+WFlLFWASdAW1f5s52j7phcyCUIfhTA64r/TwFwWkz7XFR3hzKbny7mBXEVh3Ptfex6yV3mX5lsmUZlc1ep+i+iWeouMYfhofIz4753xlddd/W8j7jraDjvvhlbVQNO2cglRShV55kLMc+MG6sMCeZU5HAN/QaAPwNwd/H5ewB8nts+J9URBHUZXHUVb51J5NvMomx1hOIbuTXZ2IUxg0ZN3I9BLKRXfRdCxxvt2ubjzpl+zLEqY85n04BjVsZzspKWljYLU9N3KG+fG5szfMN2723n8AnKOhlEOQTBrdD7Fd9S+u4Qt31OqiMI6uYB59TEyy+cbaL4AtsxwbhRohBTbqKgnin927SVlLr/rxlf6Ljq+9OkCzOn4LS5YrnPYnbWP+85GUm+lbyccVTnMOccIT7VWYkJAH9X/P1i8Xd2GAWB68GFJqDtxufSPEMTsqqdtBWHSKUYF1kKdeHLr7soKUTm2caUPC8T533gzIO2VpjHPMM6c8/E0upWF3BlD6WMnXOOkIDprOgcgLcAeD+A+wC8AcAXALyJ2z4nNREj4GQ3VJFDQyz75LnafWiy+q5jdnazbzn3BDepgysrg+lOSaWpqXz3y7aQqI3YTBkpwjSn5Tk3t3UeTk/79/JOmXvcXf9C9yV1LYONb/jOUX4HQjsjpiBXsPhsAO8E8D8BnB3TNic1kTVkvg/d/JRaQsYHmbvwnY047gVu3ZQUKvsv6zC2hYXR3DehvCtVk0Fb1z2t++zrJlpU3xPfKluff54796rZdaG+c9cli7EIbMFk1zPoMkbwO5zv2qAmN6YJBaFsKwF9E6EaXK7uI1B9oG0wv1RhE7taNFUQlNsPckpnythCropQDfq6Yy4HLWMFTzlWYphpNcga+4xjYDu3+eyykqv7j3POkUthc2U82e6XT6DasvpSkUMQbNlvYBhjBBzE1j4JMbsyYwvtJTCo7pTYgGm/X+9ahiUAbiYoN8vKuAp8jMSWTZbzvXDVvQldQzWdMjVWlaLRhuYO16XDPVeq5eBL8nDdLzO3cl6DC3WKzi0BuB3AOoBDJbofwGqofRPUtCAw4D6YkHZgjg8tMR/k3H2fMBtXignucZ+10XTL79TcXN74gYuxcDT7lGs25zTtY1xAoXNx7mcTiM0uGpRrqCMIngxgF4A/BLBQoh2htk1R03sWx2YQcSwCX4YBR0uMpdyWRXVdwyC7bNqg2HS/ahtXdtCePW4Gk+u+uxgLp+/ye1Cn1EMsEw0pZdw+YwWQD7F95bqGOsjhGjqrUn30ZAA/wm2fk5qsNeRb5AVoBlt9ML6UP04J6liLYG4uPE5AC7Rt2+ImK5d5jKMg8C0yinUVxMYIzP2vew05cuINYmMDhuGlaL6+AGs5C862aY1BXUZbV4hwrjunoLIhhyC4BQCVPk/Y4gaWducUlUvvAXCp57hXAlAAdof6bEoQcCaCzU/qYsrlYLCPcZZjBLaUOtvLzXUV5GLYZlc285Lm6HOYqLzfsw2xTCb2HoaYKOAWItWS5a6khZDbjxPPmphwB24Nw0vxhbvmhivdNDY1N8R0c2jrbWj8IWRZWWz5zhssBtADcC+A0wFMF9VLz7Qctx16v4MbuxQE3MnJ9ZNyjqtmNXA0gqbzzUeFci6O4pT88D276m8ubdr1DnLcKhxG41JcjKVbHqdPw/a9z7ZzlBWoVF849x66avqEnnGKtRTrv29a4w8hhyD43wDeBGCqoEsAfCLQ5oUAPlX6/FYAb7Uc93sAXg7gs4NuEVSZgk94VJlHDm1AgrXd1EEq5//7mBz3mU1P2wXV5GR4UVWMwOG6sAAeUwspIWZ9QNVaKLtUc/nzY60qTiZabPwkZ0aP7ZrLVngOwZFDEJwK4CMAHgLwVeitK08NtHkVgKtKn/ehssk9dGnrjxX/OwUBgP0A1gCszc/P17sbBao3fc8e3guVYhHYzpfyUMfdEjA7TnGKjuV0YZmaNT4tNPaZ+XLfuX7vWITuSaxAs73zOXzhHGGRMhdiS3GEzuUSHClznXN/67qSsqwsjqWQICjiDJ8FsKv43JpFkCsHOsbUbmMi16FB9/2X7yknK4pb6phLSvl/dz3f1HhAivURQoh51gkmm60aQ9dVd5zlWIdtW8hQu1CcxQbfuWxWWYr1zxVsddJJ66SP/mrx938BeE+VAm29rqEiNfURAIcL+i6AL4eEQQ5BwL3pnFV9McE3M1lShUOTFoHP79oVEW29T5wxNuE+Uip8jG3Cx2YIGesixfoIgZMZl5Je2uvZU185/caeq3yfq4qWr035uYSes+vemXNUx1d+7qnxBK7CUMcdVUcQ/HTx90IbBdpOQhepO60ULP5Bz/GtWQRt3HTXC1E9N5F9JyabNVE3RhAKoE5NDc7qZpcWxblGzjX0+7w0XHOsUvGLrpTyrxmwjdNo/b5z1EFVceG+8yFGyy3NwrGSY1NZQ+3KxRZ9Cg9HWIUYfWo8YaAtgroEYC+Au4vsoeXiu7cDONdybGuCIOWmxwZyYlwCJshmzuOqR2KEQZMlGIwVlKuf2Ptg7rvLUspxjWX3C2eMobRJ34T3MQ4fQ/KdIwdS/N6pSogvUGxThDjnsjFW7hhjKp1WEWL0dbKiBjZGAL0r2XUuCrVvgtqKEVSZc+xDimWmhvlxzOumYwV1z1G9FzEuJ1PK2tz3qrDN4b6yTUqf5l59d2KSBHyMw/dbE66h6nXE+rJTUpfL98OXNuvKGop5hqYd5x1JLeYWYvR1MgQHNmsIwIsKugzARwH8dEEfBvC7ofZNUK700aUlt2Zd1VJSLYgYDYrj5+QsLKpLhhGnnqPMyM194LpgyhPHVbr7zDPrXZ9rkV71nbBtnl7Ns69aBzExglCGTSgNMwdSkxm4bs+qS4g7d6pj5KyP4Lh+bHMp9j5xnnvuJJFcyJE+uqUDV6dNU1MWgc8tkRpTKL8QIXcOx0WRUysOMeI9e9KsAq5rJER13F+2OAxgjwvEaGvVd8ZsWBNKJohZBAboOMfS0uAylJRECK6S4zqfq99UlxXX157y3Af1ueUQBH8P4PTS59MA/D23fU5qMkbgejlyBHJCbffsCZ9nGDaVr7ou2j6/jyGl+m/rtg0xMtdztSURpJyjCbiSGVxjyMWYq0hRNGJ87TliKW2XknAhhyA4B8ADRUD3c0W6509w2+ekJrOGbEFE46urE8hZWeEtgOIslEoho127NOWcVHVfpGr2Ke1mZ/1aaWxGByeYnOpiKI/Nda2uvHZbv7Huk9yMyfbulscQep6p44mx1oH4RXqx70wdhaFpZMkaAnASgH9b0EkxbXNS0xZByOx1MVSf9hZjUdgmVB2Gba7JjKGcQtrURvPllz6lvbmfKSa/LR4xO+u/Ttsk5boc6rgYDKP09c9BrgBmqrDwKTpmDL5rrBMAd127LRicoq3HMvbU9NE2kMMimAHw6wB+v/h8BoCf4rbPSU3FCEIlo82DT5H4sTGG6oRMZciuoGuVcTa5f4EvsGgbW1moxsRY6tyj1Fz2XC6GuhZBjpTGOi4N370KjcGWMRSDmHGnzN3Y+zLSFkGRMfSrAO4oPs/AUpG0DcqVNeTSfkKTKkXi140xhCaa67eyFeOjsvaUg+FWGYxPWwxl6hg04cbyab2+dinuFd9740pd5cYIQsyH887WYWC+Z+OzSkKWNBdcSyZVW4+xlEY9RrBW/L2l9N1t3PY5qemtKl0TIpRWGdIqQowsFGOwafVmnwAfo+Uw0PJE4LpETjrJ/dvs7OZJE7puzn2oYxnFTn6OqyMWoffGtUUlB773g/vO1nFpcLX9rrNp2tLWu75OF3IIgv8L4EkoNqMB8H0A/o7bPie1sXm9ixH68tvL+dK2l8DHsKuacO6MjBBVl+BzLAluvf+ZGbd/PrQjF/e5pJBv8jfhxghpiiFmzunftSI99M76rpmbFcV18XXJGAdZW28DOQTB2UW20MMAVousoRdz2+ekNjavX1nxMykXo/aVhjD9ugLOvtzy1IBWKpnz5XLH2DYL8ZFLC82VVRW6n75z1IGPIfqeYV1fveudrY6tDpN09T9ozDeUyjsIAqsp1BIE0OWizwPQh95A5qcA7OS0bYLaEARKxZnKIW21qlX5JixHM6v61UOVH1PINxZz3tg+uVZESqykKnhcq5ldEzwmMN0Ek+AIuNB562asNMEIuw6ecq9p0ARWE2hkZXFX1JYgiHmBOQyKG5D2/bay4l58xFmQFkPmfK79FlLTO0Pkq7nPYZauEsU+BpCSQpubSXCfXZcZKxyrovp7l+mUTWcUDRtyCIJ3AHgLgGcA2GGI2z4ntSUIYl4irrvCMLkUi8BMHtdvJpjt02ZtLppQULTKKMs+61Qm6qOU3b7K9yB2NW4dYZaTScSMxXXeJrXalBiHLz7UhnCKYe6DnP+fCzkEwf3QewtsIm77nNSmIHAxwCpiNHHTT2z9mbpkVvxy3EqxzKM8GcsrN1PGGcrmyVmqt64FlZtJcAVr6B414ecOMdUYBaYt4RTD3MUiYFCRMfTLAD4OvZH9LwF4Erd9TmorWBzDHGMDq6ZNKGiVSwgY4eMqA7Bnz2b//exsnomaMtbQxOP48rmTN/TMOLGCJhB6/l0wp9T1NVVhMAjCiZuVJjGC6oHAHwG4CsBLCvp9AH/EbZ+T2hAEKdpBTEYLV2PLlbVjLI2Y/uruj6tUvNsoNkvFx3Q4CGXq+OIgdawmLjMcJOZUxyJoSoCFhFOKQidZQx4CcCfnuzaoDUGQYwViTJ59DpdTaAKm9BUzcW2TyLeZeahscehcMVlaLrjGVy6cV9bOjYUQyyRcefacvgaFOaXECFIFNBcchW1Q7t8gIIcgWAFwVunzjwC4hts+Jw2qRVDFygq/hk9M8K/KQHKvIbCRCcLG5IrbtgOs9pf7+YQEK7efuvVvYsYbO+Yuwc0ayqFYcMczKBbTMCDXfgQnioVkh4v//x7A7QAOcfvJQYMYI/D1U544KZoSZ/I1EVy2UdXKCRXqa4r5+VxcMX2mCGcXfM+Ju0ZgVNAmgxaNn48cgmDBR9x+clCbWUODsrimribmE0B79tSrPmrGldq2zftYvWe+cce4MUKMj/NsRilNUanhYNDDMMacyLIfwaBQ09VHm0SKphTbJoYRm2yiOusBQtZOE8wvh8YZGnOMUAkJJo7VNkoWwTCgaatlEIWMCIIKYl6C3A80tr+Qz7XaPpYp2647pnyEGYMtRtBk+mXd5+KzBmIzpjjJBeX1G5xnIGgWTa4bGNTYhQiCCrjZBqEick3DlyLpGs/KijtIG2LmhrHOzdmPc8UIzHnLjHlpyT+OrieGT2DG7piVYhE0kVcv4KPJlcSDujhNBMGWG+J/CXKlJ9ZBTBC4KsBSfP7Vc01ObkyWUNaQDbGWTNvIsQ6h3FdKjKBrxjDOaPKZDGq5ChEEJfiChNzFMW1Uc4xx8ZTHk+Kvr7tC14ZBnQxl5KyDk5I1NEj3YtzQpPtmUAW/CIISOLnjoSwYzgOt+6LFZOKUxxObweOzOuowqqYnQ47YTVu+3JDAGcTA4jigqfsuMYIhEAScTUdyLFiqywh9Ass3Hlc7sy9x2QIILUqrG8ztqhJmbF9NMmGXq84EpAeVaQwzBkGwDsIYqhBBUAI3UOzSlLkF2eouenIxiFBZhjZSVLloajIMqultg08w+34fxGtpGynvjwhWN0QQlBB6UcoasqteECe9MLSSmFNiIZWRpk6gOky7TQ3IdV/LVt2gILVq56DHD9qwpFIYughWNzoTBADOAXAXgHsAXGr5/c0A7gRwCMCnOauUc60jsLlJYnfd8k2AUNZPTD2bQTQzy2hbC3MFt3u9Zs5XByHGNIyMq43nnXpfhlWwtoFOBAGAHoB7AZwOYBrAbQDOrBzzEgAzxf9LAD4a6jfnymLubl0+CpW19bXl5KsPsqnriy9wmVmKkBsmi4BjgQ7q83WhDeGVytCHUbC2ha4EwQsBfKr0+a0A3uo5/rkAPh/qN5cgSC2LEMvQQ+ex+fjLjLHprf5c5w3FFOrupGX6GQfzP3RvB93iq6INrTv1GQ+jYG0LXQmCVwG4qvR5H4DLPcdfDuDXHb/tB7AGYG1+fj76BtgmWq5NXwy5grihc3GD1K5J13YaZepCNxtksneDuu9MG4K4zjMeNsHaFgZeEAC4AMCNAE4K9RtrEbheKG6RtelpnSnEYcyul9a3QUvqYjDzgudgiDETmztGzjjqaJYy2dOQ451pSxDLM86LgXYNAXhpsbfBqZx+YwWBL33PVgtncnJj8/Xqyxfy+fsYKcfFw7VSQvsAxGpmMQyZW1u/jbUWgnjkuufCpIcPXQmCSQD3ATitFCz+wcoxzy0Cymdw+40VBD4mx/W/l1/6GJdSmZGGXCr9vns8ExN24ZTLV5vLIsihWXJTawVpkKya8UWX6aN7AdxdMPvl4ru3Azi3+P+vAHwVwK0FXRfqM5dFYBh7XQbOtQhMXz5G2uu5C8bZmKyrr16vOVPfdT/M3gaxWFoKr5YW5INYYeOLsV5Q5mNyvkkRYtqhzelTN6Xv9/lF4HxCKkU7d5WgcB2bwy0wzoypC/eKBNrHF2MtCJRyTzjXpIhdWOYSJC6EtkiMKU+xspKvemgXTGJcXRVdMmTx748nxl4Q+GCbFHXWGHAYWGgRVqwfvotYQS6Mq0Uwrtct6A4uQTCBMcfqKrC8DDzwADA/Dxw4ACwu6s8+zMwA/b79t/n58HkPHACmprZ+PzkJHDsGHDkCENnbrq/rMXPOyRlLGa7rDt2POjhwQN/PMmZm9PejjC7utUBgw1gLgtVVYP9+zXSV0n/379ff+xjowgJw8CBw2WXpDGxxEfjgBzcLk7k5zfyPHtWflXK3P3IE2LULmJjQf/fuzcNMd+ywf6+UPs/qalx/HCwu6vu5sKCv39zfxcX85xok5BLeAkFt2MyEQaemS0yYbRk5/ts2gqYul48trlG3jEFokZ25B+Jjrg8J2graBiRGsBW+gOzMjFJ79mwEYY1waBLc9QmhbTZt4DIdzhj6fWFguSACVdAmXIJgrF1DPhN8fR34678Gjh/Xn48fB66+uhnXSGg8/f5mt4lyuIx8vuXlZX1NZVRjDaur2tUUwtGj4b4EPCwuAocPAydO6L9tucNWVze7Fpt8rwWDj7EWBLYgZRlVhru+DlxwAXDxxe2NZ2ZGxyLKzMIVpHb594FwYNLES4zgS4EEOYcDvtjYqEAEXSRsZsKgU870UV8Ovo+achPV8eOnlMIObY5ic5m1VRbbB3GppGPU01Yl9uIGJEbgRkoJifJOWG0yJV/RO9+agdDkCJXJLl/bysrWYn2crTtzQSZ6PYz6Ar5RF3R1IILAAVtZBW7Q1rRviymGBBanhr9LYPkyqGyrsav1kKan22PEMtHrYdTv36gLujoQQWBBnWJyxiLgumlyWA05q36m3IvpaX96aVuMRCZ6PYy6RTXqgq4ORBBYUKeMhIkRhCwGpdylls3LyZ2AMfWHUlAWVilxk7YYsUz0+hjlGMuoC7o6EEFgQepWleVAMUcQhAQOt/5+mwww5d60xYhlogtCGGVBVwcuQTDW6aMpS/kXFoArrtj47ErlLH8fSqtUCrjyynCKW5s1eWLvTZu1gca1JIWAj67WZwwrxloQHDjgLuxmW1hlY3aXXQZMT2/+bnpaf2/AYapKbV3cVc2DbpMBhtZYlNEFI5aJLhBkhM1MGHTKmTXk2x2La16GjuMGpY2PfVBcH+Xrsu3vLO6YeIjLQtAlIDECN9qYnJw9DkKLu7oOhgoTq4dBEfCC8YVLEJD+bbiwe/dutba21vUwknHxxTomUL71MzMb7pWJic2/GRBpV4hgOLFrly7nUMXCgnZvCQRNg4huVkrtrn4/1jGCrnDFFcC117p9/VKnfjQhG9EIBhUiCDqCL9g5rjt2jTpEwAsGFSIIBhCSHjmaEAEvGFRMdj0AgR2Li8L4Rw3medr2yBYIuoRYBAxIbXNBLsj6B8EgQiyCAMwmHmZHLrOJByCTWCAQjAbEIgiAs8WjQCAQDDNEEAQgKX8CgWDUIYIgAEn5EwgEow4RBAFIyp9AIBh1NC4IiOgcIrqLiO4hokstv59ERB8tfv9bItrV9JhiIDn9AoFg1NFo1hAR9QC8F8DZAB4EcBMRXaeUurN02OsBfE0p9UwiOh/A7wD4uSbHFQvJ6RcIBKOMpi2CFwC4Ryl1n1LqMQAfAfCKyjGvAHB18f+fANhD5NolQCAQCAS50bQg+F4A/1j6/GDxnfUYpdQTAL4BwLHvl0AgEAhyY2iCxUS0n4jWiGjt4Ycf7no4AoFAMDJoWhD8E4BnlD4/vfjOegwRTQJ4MoCj1Y6UUgeVUruVUrtPOeWUhoYrEAgE44emBcFNAM4gotOIaBrA+QCuqxxzHYALi/9fBeCv1TDuliMQCARDisZ3KCOivQB+D0APwAeUUgeI6O3QW6ZdR0TbAFwL4LkAHgVwvlLqvkCfDwOw7PVkxU4Aj6SOf4gh1z0+GMdrBuS6U7CglNriUhnKrSpjQERrtq3ZRh1y3eODcbxmQK47Z59DEywWCAQCQTMQQSAQCARjjnEQBAe7HkBHkOseH4zjNQNy3dkw8jECgUAgEPgxDhaBQCAQCDwQQSAQCARjjpERBMNe7joVjOt+MxHdSUSHiOjTRLTQxThzInTNpeNeSUSKiEYixZBz3UR0XvG8v0REH257jE2A8Y7PE9FniOiW4j3f28U4c4KIPkBEDxHRHY7fiYjeU9yTQ0T0vFonVEoNPUEvVrsXwOkApgHcBuDMyjEXA7iy+P98AB/tetwtXfdLAMwU/y8N+3Vzrrk4bjuAGwDcCGB31+Nu6VmfAeAWAE8tPp/a9bhbuu6DAJaK/88EcLjrcWe47h8D8DwAdzh+3wvgLwAQgLMA/G2d842KRTCu5a6D162U+oxSar34eCN0vadhBudZA8B/g97b4rttDq5BcK77DQDeq5T6GgAopR5qeYxNgHPdCsDJxf9PBvDlFsfXCJRSN0BXWnDhFQCuURo3AngKET0t9XyjIgjGtdw157rLeD20FjHMCF5zYSY/Qyn1520OrGFwnvX3A/h+Ivo8Ed1IROe0NrrmwLnu3wRwARE9COB6AP+5naF1iti570WjO5QJBgdEdAGA3QBe1PVYmgQRTQB4N4DXdjyULjAJ7R56MbTldwMR/ZBS6utdDqoFvBrAh5RS7yKiFwK4loierZQ60fXAhgWjYhFkK3c9ZOBcN4jopQCWAZyrlPrnlsbWFELXvB3AswF8logOQ/tPrxuBgDHnWT8I4Dql1ONKqfsB3A0tGIYZnOt+PYA/AgCl1BcAbIMuzDbKYM19LkZFEIxruevgdRPRcwG8H1oIjILP2HvNSqlvKKV2KqV2KaV2QcdFzlVKrXUz3GzgvOOfgLYGQEQ7oV1F3kq+QwDOdT8AYA8AENGzoAXBqO9edR2A1xTZQ2cB+IZS6iupnY2Ea0gp9QQR/QKAT2Gj3PWXyuWuAfwBtMl4D4py192NOA+Y1/1OAHMA/riIjT+glDq3s0HXBPOaRw7M6/4UgJcR0Z0AjgP4FaXUUFu9zOv+ZQC/T0S/BB04fu2wK3lE9IfQQn1nEfv4DQBTAKCUuhI6FrIXwD0A1gG8rtb5hvx+CQQCgaAmRsU1JBAIBIJEiCAQCASCMYcIAoFAIBhziCAQCASCMYcIAoFAIBhziCAQCASCMYcIAsFQgoieQkQXJ7b9RSKaYRz3nKKM9Tml73ZVSwMT0W8S0VtKn99CRP9ARLcS0U1E9JqUcTrG9NkRWCUtGDCIIBAMK54CXVo8Bb8IICgIoGvY/E3xlwUiugjA2QBeoJR6DvSK12GvcisYcYggEAwr3gHg+wqt+51E9CuF9n2IiN4GAEQ0S0R/TkS3EdEdRPRzRPQmAN8D4DNE9BlX50WJ8p+FLl53NhFtY47r16Br438TAJRS31RKXW07sNhw5Y9Ln19MRJ8s/n8fEa0VG8y8zdH+WOn/VxHRh4r/TyGijxX34yYi+vfMsQvGFCNRYkIwlrgUwLOVUs8hopdB1496AbT2fR0R/RiAUwB8WSn1cgAgoicrpb5BRG8G8BKl1COe/v8dgPuVUvcS0WcBvBzAx3wDIqKTAWxXSnHr+/wVgINENKuU+jaAn4Outw8Ay0qpR4moB+DTRPRvlFKHmP1eBuB3lVJ/Q0Tz0OUZnsVsKxhDiEUgGAW8rKBbAHwRwA9AV928HVqb/x0i+g9KqW9E9PlqbDDlj2DDPeSqyRJdq6XYF+MvAfx0URH35QD+tPj5PCL6IvQ1/SD0zltcvBTA5UR0K3RxspOJaC52fILxgVgEglEAAfhtpdT7t/ygN6nZC+C/E9GnlVJvD3amtfBXAngFES0X/feJaDt06fKnVprsgLYevklEx4jo9Air4CMAfgG6EOKaUupbRHQagLcA+GGl1NcKl4/NNVUWPuXfJwCcpZQald3ZBA1DLALBsOJb0HsPANr18R+N1ktE30tEpxLR9wBYV0qtQFdhfZ6lrQ17ABxSSj2jKGe9AO0W+hml1DEAXyGiHy/OtQPAOdBBZQD4bQDvLdxEIKK5QNbQ54pxvQEbFsjJAL4N4BtE9K8A/KSj7VeJ6FmkN+P5mdL3/welXbqI6Dme8wsEYhEIhhNKqaOkt2S8A3r7zQ8D+EJRavsYgAsAPBPAO4noBIDHASwVzQ8C+Esi+rJS6iWW7l8N4OOV7z5WtL8GwGugmf27i9/eppS6t/j/fdBlv28ioseL877Lcx3HiwDxa1Hsl6GUuo2IbgHwD9DbEX7e0fxSAJ+Err2/VpwXAN5UjO8Q9By/AcBFrjEIBFKGWiAQCMYc4hoSCASCMYe4hgRjDSL6WwAnVb7ep5S6PfN5Pg7gtMrX/0Up9amc5xEIUiCuIYFAIBhziGtIIBAIxhwiCAQCgWDMIYJAIBAIxhwiCAQCgWDM8f8BroI0xE69LPsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot as test validation\n",
    "plt.scatter(test_y,predicted_value,c='blue')\n",
    "plt.xlabel('test_AUC_value')\n",
    "plt.ylabel('predicted_AUC_value')\n",
    "# plt.savefig(workdir + '/DeepAUCv2_epoch_10_ht_test_scatterplot_new.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 0.12679861064567194\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "\n",
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07608268393580953"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = (np.abs(b[0]-a[0])).sum()\n",
    "mae / len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016077887661672712"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5219426542836239\n"
     ]
    }
   ],
   "source": [
    "# R-squared value\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_value = r2_score(b, a) \n",
    "print(r2_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = pd.read_csv('/data/yingfei/cancer_data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = full_test[['ARXSPAN_ID', 'DRUG_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>auc</th>\n",
       "      <th>pred_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.528562</td>\n",
       "      <td>0.776219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.930958</td>\n",
       "      <td>0.935249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.759249</td>\n",
       "      <td>0.890053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>0.936510</td>\n",
       "      <td>0.941818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>0.823453</td>\n",
       "      <td>0.882936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>KIN001-266</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.743234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0.980529</td>\n",
       "      <td>0.979556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0.960501</td>\n",
       "      <td>0.899360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0.970524</td>\n",
       "      <td>0.983109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0.706073</td>\n",
       "      <td>0.727004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARXSPAN_ID   DRUG_NAME       auc  pred_auc\n",
       "0      ACH-000802   JW-7-24-1  0.528562  0.776219\n",
       "1      ACH-000802  KIN001-260  0.930958  0.935249\n",
       "2      ACH-000802   NSC-87877  0.759249  0.890053\n",
       "3      ACH-000802    PLX-4720  0.936510  0.941818\n",
       "4      ACH-000802   ERK5-IN-1  0.823453  0.882936\n",
       "...           ...         ...       ...       ...\n",
       "22873  ACH-000438  KIN001-266  0.975578  0.743234\n",
       "22874  ACH-000438  LUMINESPIB  0.980529  0.979556\n",
       "22875  ACH-000438   NUTLIN-3A  0.960501  0.899360\n",
       "22876  ACH-000438     SGC0946  0.970524  0.983109\n",
       "22877  ACH-000438   SL 0101-1  0.706073  0.727004\n",
       "\n",
       "[22878 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data = test_data[['ARXSPAN_ID', 'DRUG_NAME', 'auc']].copy()\n",
    "eval_data['pred_auc'] = predicted_value\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test['comb'] = full_test.ARXSPAN_ID + full_test.DRUG_NAME\n",
    "eval_data['comb'] = eval_data.ARXSPAN_ID + eval_data.DRUG_NAME\n",
    "eval_data = pd.merge(full_test, eval_data, on = ['ARXSPAN_ID', 'DRUG_NAME'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_test.comb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>true_auc_arr</th>\n",
       "      <th>pred_auc_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-001496</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000267</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000508</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001106</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ACH-000953</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ACH-000561</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ACH-000819</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ARXSPAN_ID true_auc_arr pred_auc_arr\n",
       "0   ACH-000802           []           []\n",
       "1   ACH-001496           []           []\n",
       "2   ACH-000267           []           []\n",
       "3   ACH-000508           []           []\n",
       "4   ACH-001106           []           []\n",
       "..         ...          ...          ...\n",
       "64  ACH-000953           []           []\n",
       "65  ACH-000561           []           []\n",
       "66  ACH-000819           []           []\n",
       "67  ACH-000873           []           []\n",
       "68  ACH-000438           []           []\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_arr = pd.DataFrame(eval_data.ARXSPAN_ID.unique(), columns = ['ARXSPAN_ID'])\n",
    "eval_data_arr['true_auc_arr'] = [[] for _ in range(len(eval_data_arr))]\n",
    "eval_data_arr['pred_auc_arr'] = [[] for _ in range(len(eval_data_arr))]\n",
    "eval_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eval_data)):\n",
    "    cl_id = eval_data.loc[i, 'ARXSPAN_ID']\n",
    "    auc = eval_data.loc[i, 'auc']\n",
    "    pred_auc =  eval_data.loc[i, 'pred_auc']\n",
    "    if np.isnan(auc):\n",
    "        #eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'true_auc_arr'].values[0].append(1)\n",
    "        #eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'pred_auc_arr'].values[0].append(1)\n",
    "        continue\n",
    "    eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'true_auc_arr'].values[0].append(auc)\n",
    "    eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'pred_auc_arr'].values[0].append(pred_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>true_auc_arr</th>\n",
       "      <th>pred_auc_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>[0.528562, 0.930958, 0.759249, 0.93651, 0.8234...</td>\n",
       "      <td>[0.7762189, 0.93524885, 0.89005286, 0.9418184,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-001496</td>\n",
       "      <td>[0.8600040000000001, 0.935607, 0.919367, 0.861...</td>\n",
       "      <td>[0.721455, 0.91140664, 0.85157484, 0.9372215, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000267</td>\n",
       "      <td>[0.730128, 0.930868, 0.761296, 0.94428, 0.7239...</td>\n",
       "      <td>[0.7628348, 0.9592155, 0.90200263, 0.7027653, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000508</td>\n",
       "      <td>[0.958722, 0.966097, 0.832343, 0.818851, 0.953...</td>\n",
       "      <td>[0.7669825, 0.91619885, 0.86654806, 0.7948702,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001106</td>\n",
       "      <td>[0.670247, 0.845083, 0.720917, 0.705755, 0.865...</td>\n",
       "      <td>[0.6862056, 0.9008161, 0.8519385, 0.66277045, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ACH-000953</td>\n",
       "      <td>[0.771624, 0.902238, 0.788892, 0.987629, 0.977...</td>\n",
       "      <td>[0.7513126, 0.87975883, 0.8032219, 0.7316645, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ACH-000561</td>\n",
       "      <td>[0.806557, 0.92585, 0.747498, 0.974266, 0.7882...</td>\n",
       "      <td>[0.7398468, 0.929042, 0.8975643, 0.9491248, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ACH-000819</td>\n",
       "      <td>[0.8246040000000001, 0.93947, 0.778985, 0.9747...</td>\n",
       "      <td>[0.7589171, 0.9422953, 0.8850465, 0.945125, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>[0.6613979999999999, 0.876398, 0.837356, 0.971...</td>\n",
       "      <td>[0.69982064, 0.8735905, 0.80489826, 0.95107853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>[0.95799, 0.8848719999999999, 0.748696, 0.7972...</td>\n",
       "      <td>[0.6784454, 0.8887086, 0.8036526, 0.69288725, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ARXSPAN_ID                                       true_auc_arr  \\\n",
       "0   ACH-000802  [0.528562, 0.930958, 0.759249, 0.93651, 0.8234...   \n",
       "1   ACH-001496  [0.8600040000000001, 0.935607, 0.919367, 0.861...   \n",
       "2   ACH-000267  [0.730128, 0.930868, 0.761296, 0.94428, 0.7239...   \n",
       "3   ACH-000508  [0.958722, 0.966097, 0.832343, 0.818851, 0.953...   \n",
       "4   ACH-001106  [0.670247, 0.845083, 0.720917, 0.705755, 0.865...   \n",
       "..         ...                                                ...   \n",
       "64  ACH-000953  [0.771624, 0.902238, 0.788892, 0.987629, 0.977...   \n",
       "65  ACH-000561  [0.806557, 0.92585, 0.747498, 0.974266, 0.7882...   \n",
       "66  ACH-000819  [0.8246040000000001, 0.93947, 0.778985, 0.9747...   \n",
       "67  ACH-000873  [0.6613979999999999, 0.876398, 0.837356, 0.971...   \n",
       "68  ACH-000438  [0.95799, 0.8848719999999999, 0.748696, 0.7972...   \n",
       "\n",
       "                                         pred_auc_arr  \n",
       "0   [0.7762189, 0.93524885, 0.89005286, 0.9418184,...  \n",
       "1   [0.721455, 0.91140664, 0.85157484, 0.9372215, ...  \n",
       "2   [0.7628348, 0.9592155, 0.90200263, 0.7027653, ...  \n",
       "3   [0.7669825, 0.91619885, 0.86654806, 0.7948702,...  \n",
       "4   [0.6862056, 0.9008161, 0.8519385, 0.66277045, ...  \n",
       "..                                                ...  \n",
       "64  [0.7513126, 0.87975883, 0.8032219, 0.7316645, ...  \n",
       "65  [0.7398468, 0.929042, 0.8975643, 0.9491248, 0....  \n",
       "66  [0.7589171, 0.9422953, 0.8850465, 0.945125, 0....  \n",
       "67  [0.69982064, 0.8735905, 0.80489826, 0.95107853...  \n",
       "68  [0.6784454, 0.8887086, 0.8036526, 0.69288725, ...  \n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = eval_data_arr.pred_auc_arr.apply(lambda x: np.array(x)).to_numpy()\n",
    "true_values = eval_data_arr.true_auc_arr.apply(lambda x: np.array(x)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9255710872371127\n",
      "0.7657867002046594\n"
     ]
    }
   ],
   "source": [
    "### NDCG\n",
    "from sklearn.metrics import ndcg_score\n",
    "#ndcg_all = ndcg_score([p for p in pred_values],[t for t in true_values])\n",
    "#ndcg_10 = ndcg_score([p for p in pred_values],[t for t in true_values], k = 10)\n",
    "ndcg_all_values = []\n",
    "ndcg_10_values = []\n",
    "for i in range(len(pred_values)):\n",
    "    pred_value = eval_data_arr['pred_auc_arr'].apply(lambda x:list(map(lambda y:1-y, x)))[i]\n",
    "    true_value = eval_data_arr['true_auc_arr'].apply(lambda x:list(map(lambda y:1-y, x)))[i]\n",
    "    ndcg_all_values.append(ndcg_score([pred_value],[true_value]))\n",
    "    ndcg_10_values.append(ndcg_score([pred_value],[true_value], k = 10))\n",
    "    \n",
    "ndcg_all = np.mean(ndcg_all_values)\n",
    "ndcg_10 = np.mean(ndcg_10_values)\n",
    "\n",
    "print(ndcg_all)\n",
    "print(ndcg_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Recall@1', 0.3768), ('Recall@2', 0.4058), ('Recall@5', 0.4203), ('Recall@10', 0.4522)]\n"
     ]
    }
   ],
   "source": [
    "### Recall\n",
    "results = []\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    dict_test_cell_line_idx_perf = {}\n",
    "    for cur_cell_line_idx in range(len(pred_values)):\n",
    "        # step 1\n",
    "        # per the ground truth\n",
    "        gt_aucs = true_values[cur_cell_line_idx]\n",
    "        # find the top k drugs's idx\n",
    "        topk_drug_idx_gt = np.argsort(gt_aucs)[:top_k]\n",
    "        # step 2\n",
    "        # per the predicted scores\n",
    "        pred_scores = pred_values[cur_cell_line_idx]\n",
    "        assert gt_aucs.shape == pred_scores.shape\n",
    "        # find the top k drugs'idx (note: here its by pred scores)\n",
    "        topk_drug_idx_pred = np.argsort(pred_scores)[:top_k]\n",
    "        # step 3\n",
    "        # recall@k\n",
    "        cur_recall_at_k = len(\n",
    "            set(topk_drug_idx_pred).intersection(set(topk_drug_idx_gt))\n",
    "        ) / len(set(topk_drug_idx_gt))\n",
    "        dict_test_cell_line_idx_perf[cur_cell_line_idx] = cur_recall_at_k\n",
    "\n",
    "    avg_recall_at_k = np.mean(list(dict_test_cell_line_idx_perf.values()))\n",
    "    results.append((f\"Recall@{top_k}\", round(avg_recall_at_k, 4)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Auc@1', '0.2468 (GT: 0.1198)'), ('Auc@2', '0.3131 (GT: 0.157)'), ('Auc@5', '0.378 (GT: 0.222)'), ('Auc@10', '0.4392 (GT: 0.2893)')]\n"
     ]
    }
   ],
   "source": [
    "### AUC\n",
    "results = []\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    dict_test_cell_line_topk_auc_sum_gt = {}\n",
    "    dict_test_cell_line_topk_auc_sum_pred = {}\n",
    "    for cur_cell_line_idx in range(len(pred_values)):\n",
    "        # step 1\n",
    "        # per the predicted scores\n",
    "        pred_scores = pred_values[cur_cell_line_idx]\n",
    "        # find the top k drugs'idx (note: here its by pred scores)\n",
    "        topk_drug_idx_pred = np.argsort(pred_scores)[:top_k]\n",
    "        # step 2\n",
    "        # per the ground truth\n",
    "        gt_aucs = true_values[cur_cell_line_idx]\n",
    "        # find the top k predicted drugs' (per ground truth) aucs\n",
    "        topk_drug_idx_gt = np.argsort(gt_aucs)[:top_k]\n",
    "        dict_test_cell_line_topk_auc_sum_gt[cur_cell_line_idx] = np.mean(\n",
    "            gt_aucs[topk_drug_idx_gt]\n",
    "        )\n",
    "        dict_test_cell_line_topk_auc_sum_pred[cur_cell_line_idx] = np.mean(\n",
    "            gt_aucs[topk_drug_idx_pred]\n",
    "        )\n",
    "\n",
    "    avg_auc_topk_gt = np.mean(\n",
    "        list(dict_test_cell_line_topk_auc_sum_gt.values())\n",
    "    )\n",
    "    avg_auc_topk_pred = np.mean(\n",
    "        list(dict_test_cell_line_topk_auc_sum_pred.values())\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        (\n",
    "            f\"Auc@{top_k}\",\n",
    "            f\"{round(avg_auc_topk_pred, 4)} (GT: {round(avg_auc_topk_gt, 4)})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294949189925679 0.7278606688434116\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "print(pearsonr(c.Predicted, c.Test)[0], spearmanr(c.Predicted, c.Test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776219</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935249</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.890053</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941818</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882936</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>0.743234</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>0.979556</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>0.899360</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>0.983109</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>0.727004</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted      Test\n",
       "0       0.776219  0.528562\n",
       "1       0.935249  0.930958\n",
       "2       0.890053  0.759249\n",
       "3       0.941818  0.936510\n",
       "4       0.882936  0.823453\n",
       "...          ...       ...\n",
       "22873   0.743234  0.975578\n",
       "22874   0.979556  0.980529\n",
       "22875   0.899360  0.960501\n",
       "22876   0.983109  0.970524\n",
       "22877   0.727004  0.706073\n",
       "\n",
       "[22878 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('Auc@1', '0.36090001463890076 (GT: 0.11209999769926071)'), ('Auc@2', '0.40849998593330383 (GT: 0.24279999732971191)'), ('Auc@5', '0.4742000102996826 (GT: 0.3368000090122223)'), ('Auc@10', '0.5327000021934509 (GT: 0.3993000090122223)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
