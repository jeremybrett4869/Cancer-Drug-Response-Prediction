{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4070228022074215087\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/data/yingfei/cancer_data/train_data_comb.csv')\n",
    "test_data = pd.read_csv('/data/yingfei/cancer_data/test_data_comb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (203918, 2976)\n",
      "Test Shape: (22878, 2976)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Shape: {train_data.shape}')\n",
    "print(f'Test Shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.loc[train_data['auc'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>ABL1_cnv</th>\n",
       "      <th>ACVR1B_cnv</th>\n",
       "      <th>AKT1_cnv</th>\n",
       "      <th>AKT2_cnv</th>\n",
       "      <th>AKT3_cnv</th>\n",
       "      <th>ALK_cnv</th>\n",
       "      <th>ALOX12B_cnv</th>\n",
       "      <th>FAM123B_cnv</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.891908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203913</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>KIN001-236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203914</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203915</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203916</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203917</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203918 rows × 2976 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ARXSPAN_ID   DRUG_NAME  ABL1_cnv  ACVR1B_cnv  AKT1_cnv  AKT2_cnv  \\\n",
       "0       ACH-000001   JW-7-24-1         1           1         1         1   \n",
       "1       ACH-000001  KIN001-260         1           1         1         1   \n",
       "2       ACH-000001   NSC-87877         1           1         1         1   \n",
       "3       ACH-000001    PLX-4720         1           1         1         1   \n",
       "4       ACH-000001   ERK5-IN-1         1           1         1         1   \n",
       "...            ...         ...       ...         ...       ...       ...   \n",
       "203913  ACH-001716  KIN001-236         0           0         0         0   \n",
       "203914  ACH-001716  LUMINESPIB         0           0         0         0   \n",
       "203915  ACH-001716   NUTLIN-3A         0           0         0         0   \n",
       "203916  ACH-001716     SGC0946         0           0         0         0   \n",
       "203917  ACH-001716   SL 0101-1         0           0         0         0   \n",
       "\n",
       "        AKT3_cnv  ALK_cnv  ALOX12B_cnv  FAM123B_cnv  ...  PubchemFP872  \\\n",
       "0              1        0           -1            0  ...             0   \n",
       "1              1        0           -1            0  ...             0   \n",
       "2              1        0           -1            0  ...             0   \n",
       "3              1        0           -1            0  ...             0   \n",
       "4              1        0           -1            0  ...             0   \n",
       "...          ...      ...          ...          ...  ...           ...   \n",
       "203913         0        1            0            0  ...             0   \n",
       "203914         0        1            0            0  ...             0   \n",
       "203915         0        1            0            0  ...             0   \n",
       "203916         0        1            0            0  ...             0   \n",
       "203917         0        1            0            0  ...             0   \n",
       "\n",
       "        PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "203913             0             0             0             0             0   \n",
       "203914             0             0             0             0             0   \n",
       "203915             0             0             0             0             0   \n",
       "203916             0             0             0             0             0   \n",
       "203917             0             0             0             0             0   \n",
       "\n",
       "        PubchemFP878  PubchemFP879  PubchemFP880       auc  \n",
       "0                  0             0             0  0.778432  \n",
       "1                  0             0             0  0.951321  \n",
       "2                  0             0             0  0.840287  \n",
       "3                  0             0             0  0.936410  \n",
       "4                  0             0             0  0.891908  \n",
       "...              ...           ...           ...       ...  \n",
       "203913             0             0             0  0.956865  \n",
       "203914             0             0             0  0.975168  \n",
       "203915             0             0             0  0.871995  \n",
       "203916             0             0             0  0.975417  \n",
       "203917             0             0             0  0.942321  \n",
       "\n",
       "[203918 rows x 2976 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reset_index(drop = True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.loc[test_data['auc'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>ABL1_cnv</th>\n",
       "      <th>ACVR1B_cnv</th>\n",
       "      <th>AKT1_cnv</th>\n",
       "      <th>AKT2_cnv</th>\n",
       "      <th>AKT3_cnv</th>\n",
       "      <th>ALK_cnv</th>\n",
       "      <th>ALOX12B_cnv</th>\n",
       "      <th>FAM123B_cnv</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>KIN001-266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2976 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARXSPAN_ID   DRUG_NAME  ABL1_cnv  ACVR1B_cnv  AKT1_cnv  AKT2_cnv  \\\n",
       "0      ACH-000802   JW-7-24-1         1           0         1        -1   \n",
       "1      ACH-000802  KIN001-260         1           0         1        -1   \n",
       "2      ACH-000802   NSC-87877         1           0         1        -1   \n",
       "3      ACH-000802    PLX-4720         1           0         1        -1   \n",
       "4      ACH-000802   ERK5-IN-1         1           0         1        -1   \n",
       "...           ...         ...       ...         ...       ...       ...   \n",
       "22873  ACH-000438  KIN001-266         0           0         0         1   \n",
       "22874  ACH-000438  LUMINESPIB         0           0         0         1   \n",
       "22875  ACH-000438   NUTLIN-3A         0           0         0         1   \n",
       "22876  ACH-000438     SGC0946         0           0         0         1   \n",
       "22877  ACH-000438   SL 0101-1         0           0         0         1   \n",
       "\n",
       "       AKT3_cnv  ALK_cnv  ALOX12B_cnv  FAM123B_cnv  ...  PubchemFP872  \\\n",
       "0             1        1           -1            0  ...             0   \n",
       "1             1        1           -1            0  ...             0   \n",
       "2             1        1           -1            0  ...             0   \n",
       "3             1        1           -1            0  ...             0   \n",
       "4             1        1           -1            0  ...             0   \n",
       "...         ...      ...          ...          ...  ...           ...   \n",
       "22873         0        0            0            0  ...             0   \n",
       "22874         0        0            0            0  ...             0   \n",
       "22875         0        0            0            0  ...             0   \n",
       "22876         0        0            0            0  ...             0   \n",
       "22877         0        0            0            0  ...             0   \n",
       "\n",
       "       PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  \\\n",
       "0                 0             0             0             0             0   \n",
       "1                 0             0             0             0             0   \n",
       "2                 0             0             0             0             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "22873             0             0             0             0             0   \n",
       "22874             0             0             0             0             0   \n",
       "22875             0             0             0             0             0   \n",
       "22876             0             0             0             0             0   \n",
       "22877             0             0             0             0             0   \n",
       "\n",
       "       PubchemFP878  PubchemFP879  PubchemFP880       auc  \n",
       "0                 0             0             0  0.528562  \n",
       "1                 0             0             0  0.930958  \n",
       "2                 0             0             0  0.759249  \n",
       "3                 0             0             0  0.936510  \n",
       "4                 0             0             0  0.823453  \n",
       "...             ...           ...           ...       ...  \n",
       "22873             0             0             0  0.975578  \n",
       "22874             0             0             0  0.980529  \n",
       "22875             0             0             0  0.960501  \n",
       "22876             0             0             0  0.970524  \n",
       "22877             0             0             0  0.706073  \n",
       "\n",
       "[22878 rows x 2976 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.reset_index(drop = True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "padel_features = train_data[train_data.columns[-2326:-1]]\n",
    "padel_features = scaler.fit_transform(padel_features)\n",
    "padel_features = pd.DataFrame(padel_features)\n",
    "#train_features = train_data.drop(columns = ['ARXSPAN_ID', 'DRUG_NAME','auc'])\n",
    "#train_features = scaler.fit_transform(train_features)\n",
    "train_features = train_data[train_data.columns[2:-2326]]\n",
    "train_features = pd.concat([train_features, padel_features], axis = 1)\n",
    "train_features = train_features.to_numpy()\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum train y value: 0.004496,       Maximum train y value: 0.999883\n"
     ]
    }
   ],
   "source": [
    "train_label = train_data['auc']\n",
    "print(f'Minimum train y value: {min(train_label)}, \\\n",
    "      Maximum train y value: {max(train_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padel_features = test_data[test_data.columns[-2326:-1]]\n",
    "padel_features = scaler.transform(padel_features)\n",
    "padel_features = pd.DataFrame(padel_features)\n",
    "#test_features = test_data.drop(columns = ['ARXSPAN_ID', 'DRUG_NAME','auc'])\n",
    "#test_features = scaler.transform(test_features)\n",
    "test_features = test_data[test_data.columns[2:-2326]]\n",
    "test_features = pd.concat([test_features, padel_features], axis = 1)\n",
    "test_features = test_features.to_numpy()\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum test y value: 0.013524,       Maximum test y value: 0.998284\n"
     ]
    }
   ],
   "source": [
    "test_label = test_data['auc']\n",
    "print(f'Minimum test y value: {min(test_label)}, \\\n",
    "      Maximum test y value: {max(test_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = train_features, train_label, test_features, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203918, 2973, 1) (203918,) (22878, 2973, 1) (22878,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (203918, 2973, 1)\n",
      "203918 train samples\n",
      "22878 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X)\n",
    "train_y = np.nan_to_num(train_y)\n",
    "test_X = np.nan_to_num(test_X)\n",
    "test_y = np.nan_to_num(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization, UtilityFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split into train and validation set\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters set\n",
    "params_lst = [\"learning_rate\", \"batch_size\", \"optimizer\"]\n",
    "params_value_dict = {\"learning_rate\": [1e-4, 2e-4, 5e-4], \n",
    "                     \"batch_size\": [80, 100, 120], \n",
    "                     \"optimizer\": ['sgd', 'adam']}\n",
    "import itertools as it\n",
    "\n",
    "allparams = params_value_dict\n",
    "combinations = it.product(*(params_value_dict[param] for param in allparams))\n",
    "combinations_lst = list(combinations)\n",
    "print(len(combinations_lst))\n",
    "\n",
    "hyper_param_dict = {}\n",
    "for i in range(len(combinations_lst)):\n",
    "    hyper_param_dict[i] = {}\n",
    "    for j in range(len(params_lst)):\n",
    "        hyper_param_dict[i][params_lst[j]] = combinations_lst[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2023-03-16 16:58:26.110549\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 386s 195ms/step - loss: 0.7704 - mse: 0.7704 - mae: 0.6914 - val_loss: 0.2699 - val_mse: 0.2699 - val_mae: 0.4169\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 362s 189ms/step - loss: 0.4464 - mse: 0.4464 - mae: 0.5293 - val_loss: 0.1830 - val_mse: 0.1830 - val_mae: 0.3420\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 361s 189ms/step - loss: 0.3341 - mse: 0.3341 - mae: 0.4575 - val_loss: 0.1467 - val_mse: 0.1467 - val_mae: 0.3072\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 356s 186ms/step - loss: 0.2619 - mse: 0.2619 - mae: 0.4045 - val_loss: 0.1196 - val_mse: 0.1196 - val_mae: 0.2770\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 358s 188ms/step - loss: 0.2138 - mse: 0.2138 - mae: 0.3648 - val_loss: 0.0982 - val_mse: 0.0982 - val_mae: 0.2508\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 352s 184ms/step - loss: 0.1784 - mse: 0.1784 - mae: 0.3329 - val_loss: 0.0835 - val_mse: 0.0835 - val_mae: 0.2304\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 355s 185ms/step - loss: 0.1536 - mse: 0.1536 - mae: 0.3084 - val_loss: 0.0733 - val_mse: 0.0733 - val_mae: 0.2161\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 359s 188ms/step - loss: 0.1330 - mse: 0.1330 - mae: 0.2862 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.2045\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 367s 192ms/step - loss: 0.1183 - mse: 0.1183 - mae: 0.2699 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1945\n",
      "Epoch 10/10\n",
      "1912/1912 [==============================] - 356s 186ms/step - loss: 0.1051 - mse: 0.1051 - mae: 0.2547 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1885\n",
      "EndTime : 2023-03-16 17:58:41.343884\n",
      "Evaluating model 0...\n",
      "715/715 [==============================] - 30s 42ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.1908\n",
      "loss=0.056589, mse=0.056589, mae=0.190805\n",
      "StartTime : 2023-03-16 17:59:13.495253\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 376s 189ms/step - loss: 0.1849 - mse: 0.1849 - mae: 0.3083 - val_loss: 0.0267 - val_mse: 0.0267 - val_mae: 0.1165\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 383s 200ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1576 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.0918\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 396s 207ms/step - loss: 0.0284 - mse: 0.0284 - mae: 0.1223 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0778\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 391s 205ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.1047 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0763\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 371s 194ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0938 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0797\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 357s 186ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0876 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0717\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 358s 187ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0834 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0694\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 365s 191ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0810 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0667\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 361s 189ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0786 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0656\n",
      "Epoch 10/10\n",
      "1912/1912 [==============================] - 367s 192ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0764 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0656\n",
      "EndTime : 2023-03-16 19:01:20.441844\n",
      "Evaluating model 1...\n",
      "715/715 [==============================] - 28s 38ms/step - loss: 0.0170 - mse: 0.0170 - mae: 0.0791\n",
      "loss=0.016987, mse=0.016987, mae=0.079078\n",
      "StartTime : 2023-03-16 19:01:51.170959\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 378s 237ms/step - loss: 0.7192 - mse: 0.7192 - mae: 0.6654 - val_loss: 0.2419 - val_mse: 0.2419 - val_mae: 0.3937\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 353s 231ms/step - loss: 0.4077 - mse: 0.4077 - mae: 0.5060 - val_loss: 0.1772 - val_mse: 0.1772 - val_mae: 0.3369\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 353s 231ms/step - loss: 0.3212 - mse: 0.3212 - mae: 0.4493 - val_loss: 0.1379 - val_mse: 0.1379 - val_mae: 0.2974\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 350s 229ms/step - loss: 0.2656 - mse: 0.2656 - mae: 0.4086 - val_loss: 0.1194 - val_mse: 0.1194 - val_mae: 0.2778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 356s 232ms/step - loss: 0.2266 - mse: 0.2266 - mae: 0.3780 - val_loss: 0.1036 - val_mse: 0.1036 - val_mae: 0.2584\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 345s 225ms/step - loss: 0.1974 - mse: 0.1974 - mae: 0.3522 - val_loss: 0.0924 - val_mse: 0.0924 - val_mae: 0.2449\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 343s 224ms/step - loss: 0.1754 - mse: 0.1754 - mae: 0.3321 - val_loss: 0.0828 - val_mse: 0.0828 - val_mae: 0.2320\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 337s 220ms/step - loss: 0.1555 - mse: 0.1555 - mae: 0.3127 - val_loss: 0.0762 - val_mse: 0.0762 - val_mae: 0.2232\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 342s 224ms/step - loss: 0.1401 - mse: 0.1401 - mae: 0.2968 - val_loss: 0.0700 - val_mse: 0.0700 - val_mae: 0.2139\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 334s 219ms/step - loss: 0.1249 - mse: 0.1249 - mae: 0.2803 - val_loss: 0.0653 - val_mse: 0.0653 - val_mae: 0.2067\n",
      "EndTime : 2023-03-16 20:00:04.901140\n",
      "Evaluating model 2...\n",
      "715/715 [==============================] - 28s 39ms/step - loss: 0.0646 - mse: 0.0646 - mae: 0.2056\n",
      "loss=0.064583, mse=0.064583, mae=0.205617\n",
      "StartTime : 2023-03-16 20:00:36.623499\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 333s 209ms/step - loss: 0.4457 - mse: 0.4457 - mae: 0.4188 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1323\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 315s 206ms/step - loss: 0.0929 - mse: 0.0929 - mae: 0.1929 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0901\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 316s 207ms/step - loss: 0.0605 - mse: 0.0605 - mae: 0.1576 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0782\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 312s 204ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1363 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0761\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 312s 204ms/step - loss: 0.0272 - mse: 0.0272 - mae: 0.1148 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0733\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 309s 202ms/step - loss: 0.0204 - mse: 0.0204 - mae: 0.1008 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0716\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 313s 204ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.0926 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.0849\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 313s 204ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0871 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.0786\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 311s 203ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0837 - val_loss: 0.0323 - val_mse: 0.0323 - val_mae: 0.0815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 310s 202ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0808 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.0715\n",
      "EndTime : 2023-03-16 20:53:02.474788\n",
      "Evaluating model 3...\n",
      "715/715 [==============================] - 29s 40ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0781\n",
      "loss=0.016893, mse=0.016893, mae=0.078116\n",
      "StartTime : 2023-03-16 20:53:47.246697\n",
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 310s 235ms/step - loss: 0.7719 - mse: 0.7719 - mae: 0.6939 - val_loss: 0.3208 - val_mse: 0.3208 - val_mae: 0.4584\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 307s 241ms/step - loss: 0.4747 - mse: 0.4747 - mae: 0.5454 - val_loss: 0.2237 - val_mse: 0.2237 - val_mae: 0.3804\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 308s 241ms/step - loss: 0.3733 - mse: 0.3733 - mae: 0.4843 - val_loss: 0.1854 - val_mse: 0.1854 - val_mae: 0.3463\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 307s 240ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.4376 - val_loss: 0.1468 - val_mse: 0.1468 - val_mae: 0.3091\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 308s 242ms/step - loss: 0.2602 - mse: 0.2602 - mae: 0.4047 - val_loss: 0.1243 - val_mse: 0.1243 - val_mae: 0.2835\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 311s 244ms/step - loss: 0.2228 - mse: 0.2228 - mae: 0.3742 - val_loss: 0.1073 - val_mse: 0.1073 - val_mae: 0.2638\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 306s 240ms/step - loss: 0.1949 - mse: 0.1949 - mae: 0.3492 - val_loss: 0.0979 - val_mse: 0.0979 - val_mae: 0.2521\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 311s 244ms/step - loss: 0.1729 - mse: 0.1729 - mae: 0.3294 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2360\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 305s 239ms/step - loss: 0.1557 - mse: 0.1557 - mae: 0.3125 - val_loss: 0.0813 - val_mse: 0.0813 - val_mae: 0.2307\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 307s 241ms/step - loss: 0.1413 - mse: 0.1413 - mae: 0.2977 - val_loss: 0.0749 - val_mse: 0.0749 - val_mae: 0.2211\n",
      "EndTime : 2023-03-16 21:45:09.568593\n",
      "Evaluating model 4...\n",
      "715/715 [==============================] - 30s 41ms/step - loss: 0.0734 - mse: 0.0734 - mae: 0.2188\n",
      "loss=0.073415, mse=0.073415, mae=0.218770\n",
      "StartTime : 2023-03-16 21:45:42.343882\n",
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 311s 234ms/step - loss: 0.2303 - mse: 0.2303 - mae: 0.3521 - val_loss: 0.0270 - val_mse: 0.0270 - val_mae: 0.1200\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 296s 232ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.1700 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0837\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 302s 237ms/step - loss: 0.0343 - mse: 0.0343 - mae: 0.1333 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0796\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 296s 232ms/step - loss: 0.0265 - mse: 0.0265 - mae: 0.1165 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0788\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 295s 231ms/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1046 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0776\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 291s 228ms/step - loss: 0.0182 - mse: 0.0182 - mae: 0.0952 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0756\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 290s 227ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0894 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0739\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 292s 229ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0856 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0721\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 292s 229ms/step - loss: 0.0143 - mse: 0.0143 - mae: 0.0824 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0685\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 294s 230ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0803 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0662\n",
      "EndTime : 2023-03-16 22:35:20.754908\n",
      "Evaluating model 5...\n",
      "715/715 [==============================] - 31s 43ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.0791\n",
      "loss=0.017247, mse=0.017247, mae=0.079057\n",
      "StartTime : 2023-03-16 22:35:54.409090\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 400s 202ms/step - loss: 0.5484 - mse: 0.5484 - mae: 0.5821 - val_loss: 0.1877 - val_mse: 0.1877 - val_mae: 0.3494\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 380s 199ms/step - loss: 0.2938 - mse: 0.2938 - mae: 0.4290 - val_loss: 0.1236 - val_mse: 0.1236 - val_mae: 0.2848\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 380s 199ms/step - loss: 0.2031 - mse: 0.2031 - mae: 0.3570 - val_loss: 0.0956 - val_mse: 0.0956 - val_mae: 0.2509\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 386s 202ms/step - loss: 0.1543 - mse: 0.1543 - mae: 0.3109 - val_loss: 0.0771 - val_mse: 0.0771 - val_mae: 0.2262\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 379s 198ms/step - loss: 0.1214 - mse: 0.1214 - mae: 0.2756 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.2134\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 383s 200ms/step - loss: 0.0979 - mse: 0.0979 - mae: 0.2474 - val_loss: 0.0547 - val_mse: 0.0547 - val_mae: 0.1921\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 385s 201ms/step - loss: 0.0825 - mse: 0.0825 - mae: 0.2266 - val_loss: 0.0490 - val_mse: 0.0490 - val_mae: 0.1820\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 379s 198ms/step - loss: 0.0694 - mse: 0.0694 - mae: 0.2077 - val_loss: 0.0436 - val_mse: 0.0436 - val_mae: 0.1724\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 386s 202ms/step - loss: 0.0608 - mse: 0.0608 - mae: 0.1938 - val_loss: 0.0409 - val_mse: 0.0409 - val_mae: 0.1674\n",
      "Epoch 10/10\n",
      "1912/1912 [==============================] - 378s 198ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.1825 - val_loss: 0.0378 - val_mse: 0.0378 - val_mae: 0.1616\n",
      "EndTime : 2023-03-16 23:39:53.577100\n",
      "Evaluating model 6...\n",
      "715/715 [==============================] - 28s 40ms/step - loss: 0.0386 - mse: 0.0386 - mae: 0.1624\n",
      "loss=0.038646, mse=0.038646, mae=0.162366\n",
      "StartTime : 2023-03-16 23:40:24.366613\n",
      "Epoch 1/10\n",
      "1912/1912 [==============================] - 383s 193ms/step - loss: 0.1582 - mse: 0.1582 - mae: 0.2708 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0979\n",
      "Epoch 2/10\n",
      "1912/1912 [==============================] - 369s 193ms/step - loss: 0.0358 - mse: 0.0358 - mae: 0.1352 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0851\n",
      "Epoch 3/10\n",
      "1912/1912 [==============================] - 358s 187ms/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1060 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0741\n",
      "Epoch 4/10\n",
      "1912/1912 [==============================] - 357s 187ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0921 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0746\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 362s 189ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0865 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0761\n",
      "Epoch 6/10\n",
      "1912/1912 [==============================] - 356s 186ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0831 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0692\n",
      "Epoch 7/10\n",
      "1912/1912 [==============================] - 353s 185ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0805 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0691\n",
      "Epoch 8/10\n",
      "1912/1912 [==============================] - 359s 188ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0781 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0677\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 352s 184ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0761 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0661\n",
      "Epoch 10/10\n",
      "1912/1912 [==============================] - 352s 184ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0741 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0692\n",
      "EndTime : 2023-03-17 00:40:28.668836\n",
      "Evaluating model 7...\n",
      "715/715 [==============================] - 27s 37ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0796\n",
      "loss=0.016399, mse=0.016399, mae=0.079604\n",
      "StartTime : 2023-03-17 00:40:58.181797\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 347s 218ms/step - loss: 0.5949 - mse: 0.5949 - mae: 0.6031 - val_loss: 0.1869 - val_mse: 0.1869 - val_mae: 0.3434\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 336s 220ms/step - loss: 0.3161 - mse: 0.3161 - mae: 0.4439 - val_loss: 0.1234 - val_mse: 0.1234 - val_mae: 0.2805\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 333s 218ms/step - loss: 0.2169 - mse: 0.2169 - mae: 0.3686 - val_loss: 0.0947 - val_mse: 0.0947 - val_mae: 0.2470\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 340s 222ms/step - loss: 0.1612 - mse: 0.1612 - mae: 0.3174 - val_loss: 0.0797 - val_mse: 0.0797 - val_mae: 0.2279\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 338s 221ms/step - loss: 0.1268 - mse: 0.1268 - mae: 0.2816 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.2114\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 339s 221ms/step - loss: 0.1038 - mse: 0.1038 - mae: 0.2541 - val_loss: 0.0573 - val_mse: 0.0573 - val_mae: 0.1954\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 336s 220ms/step - loss: 0.0882 - mse: 0.0882 - mae: 0.2343 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1874\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 335s 219ms/step - loss: 0.0755 - mse: 0.0755 - mae: 0.2164 - val_loss: 0.0468 - val_mse: 0.0468 - val_mae: 0.1779\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 336s 219ms/step - loss: 0.0658 - mse: 0.0658 - mae: 0.2014 - val_loss: 0.0441 - val_mse: 0.0441 - val_mae: 0.1735\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 336s 220ms/step - loss: 0.0591 - mse: 0.0591 - mae: 0.1906 - val_loss: 0.0412 - val_mse: 0.0412 - val_mae: 0.1683\n",
      "EndTime : 2023-03-17 01:37:16.641573\n",
      "Evaluating model 8...\n",
      "715/715 [==============================] - 30s 42ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1703\n",
      "loss=0.042521, mse=0.042521, mae=0.170280\n",
      "StartTime : 2023-03-17 01:37:49.264162\n",
      "Epoch 1/10\n",
      "1143/1530 [=====================>........] - ETA: 1:13 - loss: 0.1606 - mse: 0.1606 - mae: 0.2700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 317s 207ms/step - loss: 0.0255 - mse: 0.0255 - mae: 0.1093 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0719\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 318s 208ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0934 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0706\n",
      "Epoch 5/10\n",
      " 961/1530 [=================>............] - ETA: 1:50 - loss: 0.0160 - mse: 0.0160 - mae: 0.0879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510/1530 [============================>.] - ETA: 3s - loss: 0.0137 - mse: 0.0137 - mae: 0.0792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 325s 212ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0775 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0693\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 320s 209ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0758 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0664\n",
      "EndTime : 2023-03-17 02:31:27.423866\n",
      "Evaluating model 9...\n",
      "715/715 [==============================] - 31s 43ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0777\n",
      "loss=0.016787, mse=0.016787, mae=0.077738\n",
      "StartTime : 2023-03-17 02:32:11.581942\n",
      "Epoch 1/10\n",
      " 146/1275 [==>...........................] - ETA: 3:57 - loss: 0.9524 - mse: 0.9524 - mae: 0.7799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 973/1275 [=====================>........] - ETA: 1:05 - loss: 0.2309 - mse: 0.2309 - mae: 0.3788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 294s 230ms/step - loss: 0.1759 - mse: 0.1759 - mae: 0.3305 - val_loss: 0.0818 - val_mse: 0.0818 - val_mae: 0.2302\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 297s 233ms/step - loss: 0.1425 - mse: 0.1425 - mae: 0.2975 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.2100\n",
      "Epoch 6/10\n",
      " 995/1275 [======================>.......] - ETA: 59s - loss: 0.1209 - mse: 0.1209 - mae: 0.2739 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 294s 231ms/step - loss: 0.0892 - mse: 0.0892 - mae: 0.2352 - val_loss: 0.0490 - val_mse: 0.0490 - val_mae: 0.1800\n",
      "Epoch 9/10\n",
      " 441/1275 [=========>....................] - ETA: 2:56 - loss: 0.0812 - mse: 0.0812 - mae: 0.2242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 298s 234ms/step - loss: 0.0703 - mse: 0.0703 - mae: 0.2079 - val_loss: 0.0415 - val_mse: 0.0415 - val_mae: 0.1655\n",
      "EndTime : 2023-03-17 03:21:48.386565\n",
      "Evaluating model 10...\n",
      "715/715 [==============================] - 27s 38ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1725\n",
      "loss=0.045415, mse=0.045415, mae=0.172548\n",
      "StartTime : 2023-03-17 03:22:18.029086\n",
      "Epoch 1/10\n",
      " 718/1275 [===============>..............] - ETA: 1:54 - loss: 0.2683 - mse: 0.2683 - mae: 0.3807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 287s 225ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.0983 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0729\n",
      "Epoch 5/10\n",
      " 996/1275 [======================>.......] - ETA: 57s - loss: 0.0163 - mse: 0.0163 - mae: 0.0895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 287s 225ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0845 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0717\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 286s 225ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0812 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0690\n",
      "Epoch 8/10\n",
      " 239/1275 [====>.........................] - ETA: 3:35 - loss: 0.0137 - mse: 0.0137 - mae: 0.0798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 287s 225ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0779 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0682\n",
      "Epoch 10/10\n",
      "1037/1275 [=======================>......] - ETA: 49s - loss: 0.0126 - mse: 0.0126 - mae: 0.0756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 383s 195ms/step - loss: 0.3818 - mse: 0.3818 - mae: 0.4799 - val_loss: 0.1161 - val_mse: 0.1161 - val_mae: 0.2761\n",
      "Epoch 2/10\n",
      "1362/1912 [====================>.........] - ETA: 1:39 - loss: 0.1627 - mse: 0.1627 - mae: 0.3192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 378s 198ms/step - loss: 0.0639 - mse: 0.0639 - mae: 0.1986 - val_loss: 0.0485 - val_mse: 0.0485 - val_mae: 0.1873\n",
      "Epoch 5/10\n",
      "1857/1912 [============================>.] - ETA: 9s - loss: 0.0497 - mse: 0.0497 - mae: 0.1738 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 374s 196ms/step - loss: 0.0368 - mse: 0.0368 - mae: 0.1476 - val_loss: 0.0356 - val_mse: 0.0356 - val_mae: 0.1617\n",
      "Epoch 8/10\n",
      "1875/1912 [============================>.] - ETA: 6s - loss: 0.0339 - mse: 0.0339 - mae: 0.1409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/1912 [===========================>..] - ETA: 22s - loss: 0.0316 - mse: 0.0316 - mae: 0.1351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 364s 183ms/step - loss: 0.0889 - mse: 0.0889 - mae: 0.1851 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0826\n",
      "Epoch 2/10\n",
      "1539/1912 [=======================>......] - ETA: 1:03 - loss: 0.0218 - mse: 0.0218 - mae: 0.1053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 359s 188ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0841 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0709\n",
      "Epoch 5/10\n",
      "1912/1912 [==============================] - 357s 187ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0817 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0760\n",
      "Epoch 6/10\n",
      " 356/1912 [====>.........................] - ETA: 4:25 - loss: 0.0145 - mse: 0.0145 - mae: 0.0804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 359s 188ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0758 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0697\n",
      "Epoch 9/10\n",
      "1912/1912 [==============================] - 358s 187ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0748 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0689\n",
      "Epoch 10/10\n",
      " 693/1912 [=========>....................] - ETA: 3:30 - loss: 0.0127 - mse: 0.0127 - mae: 0.0735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 348s 227ms/step - loss: 0.0791 - mse: 0.0791 - mae: 0.2207 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1884\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 345s 226ms/step - loss: 0.0625 - mse: 0.0625 - mae: 0.1949 - val_loss: 0.0463 - val_mse: 0.0463 - val_mae: 0.1796\n",
      "Epoch 6/10\n",
      " 382/1530 [======>.......................] - ETA: 3:58 - loss: 0.0553 - mse: 0.0553 - mae: 0.1828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 343s 224ms/step - loss: 0.0368 - mse: 0.0368 - mae: 0.1465 - val_loss: 0.0353 - val_mse: 0.0353 - val_mae: 0.1589\n",
      "EndTime : 2023-03-17 07:13:12.564198\n",
      "Evaluating model 14...\n",
      "715/715 [==============================] - 27s 38ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1609\n",
      "loss=0.036875, mse=0.036875, mae=0.160922\n",
      "StartTime : 2023-03-17 07:13:45.814864\n",
      "Epoch 1/10\n",
      "1479/1530 [============================>.] - ETA: 9s - loss: 0.1131 - mse: 0.1131 - mae: 0.2102 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 318s 208ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0847 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0735\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 321s 210ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0820 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0701\n",
      "Epoch 6/10\n",
      "  83/1530 [>.............................] - ETA: 4:42 - loss: 0.0144 - mse: 0.0144 - mae: 0.0814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 322s 211ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0766 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0709\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 321s 210ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0759 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0739\n",
      "Epoch 10/10\n",
      "1282/1530 [========================>.....] - ETA: 46s - loss: 0.0127 - mse: 0.0127 - mae: 0.0741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 296s 232ms/step - loss: 0.1238 - mse: 0.1238 - mae: 0.2787 - val_loss: 0.0591 - val_mse: 0.0591 - val_mae: 0.1989\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 299s 234ms/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2337 - val_loss: 0.0441 - val_mse: 0.0441 - val_mae: 0.1714\n",
      "Epoch 5/10\n",
      " 688/1275 [===============>..............] - ETA: 2:09 - loss: 0.0704 - mse: 0.0704 - mae: 0.2098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 304s 239ms/step - loss: 0.0354 - mse: 0.0354 - mae: 0.1455 - val_loss: 0.0269 - val_mse: 0.0269 - val_mae: 0.1329\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 306s 240ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.1385 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1307\n",
      "EndTime : 2023-03-17 08:58:40.396260\n",
      "Evaluating model 16...\n",
      "715/715 [==============================] - 27s 38ms/step - loss: 0.0269 - mse: 0.0269 - mae: 0.1307\n",
      "loss=0.026893, mse=0.026893, mae=0.130717\n",
      "StartTime : 2023-03-17 08:59:10.722545\n",
      "Epoch 1/10\n",
      " 661/1275 [==============>...............] - ETA: 2:09 - loss: 0.1157 - mse: 0.1157 - mae: 0.2247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 296s 232ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0802 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0681\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 298s 234ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0786 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0693\n",
      "Epoch 7/10\n",
      " 512/1275 [===========>..................] - ETA: 2:47 - loss: 0.0138 - mse: 0.0138 - mae: 0.0785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"resnet_ht_models/comb_model\"\n",
    "\n",
    "model_eval_dict = {}\n",
    "model_dict = {}\n",
    "training_epochs = 10\n",
    "model_ht_history = {}\n",
    "\n",
    "for i in hyper_param_dict:\n",
    "    params_dict = hyper_param_dict[i]\n",
    "    learning_rate=params_dict[\"learning_rate\"] \n",
    "    batch_size=params_dict[\"batch_size\"] \n",
    "    opt_name=params_dict[\"optimizer\"]\n",
    "    \n",
    "    # hyper parameters\n",
    "    num_classes = 1\n",
    "    if opt_name == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    else: # sgd\n",
    "        optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    with K.tf.device('/GPU:0'): # model compile\n",
    "        inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "        x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    #     y = x\n",
    "        x = Activation('tanh')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "    #     x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "    #     x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    #     x = AveragePooling1D(pool_size=8)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(units=2048, name='dense1'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout1') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    #    x = Reshape((300,1))(x)\n",
    "\n",
    "    #    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "    #    x = MaxPooling1D(pool_size=2)(x)\n",
    "    #    x = BatchNormalization()(x)\n",
    "\n",
    "        x = Dense(units=1024, name='dense5'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Dropout(0.1, name='dropout5') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=512, name='dense6'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout6') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=1024, name='dense7'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout7') (x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=512, name='dense8'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout8') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=256, name='dense9'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout9') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=128, name='dense10'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Dropout(0.1, name='dropout10') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN')\n",
    "        model.compile(loss=keras.losses.mean_squared_error,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['mse','mae'])\n",
    "        \n",
    "        # model training\n",
    "        StartTime8 = datetime.now()\n",
    "        print(\"StartTime :\", StartTime8)\n",
    "        with K.tf.device('/GPU:0'):\n",
    "            model_train = model.fit(train_X, train_y, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                                validation_data=(val_X, val_y))\n",
    "\n",
    "        EndTime8 = datetime.now()\n",
    "        print(\"EndTime :\", EndTime8)\n",
    "    model.save_weights(workdir+ f'/model_{i}_new.h5')\n",
    "    with open(workdir + f'/model_architecture_{i}_new.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "        \n",
    "    # evaluation\n",
    "    print(f\"Evaluating model {i}...\")\n",
    "    test_score = model.evaluate(test_X, test_y, verbose=1)\n",
    "    model_ht_history[(learning_rate, batch_size)] = model\n",
    "    loss, mse, mae = test_score\n",
    "    print(\"loss=%.6f, mse=%.6f, mae=%.6f\"%(loss, mse, mae))\n",
    "    \n",
    "    model_dict[i] = model\n",
    "    model_eval_dict[i] = {\"loss\":loss, \"mse\":mse, \"mae\":mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mse = 10\n",
    "bst_model_id_lst = []\n",
    "for i in model_eval_dict:\n",
    "    if model_eval_dict[i]['mse'] < min_mse:\n",
    "        bst_model_id_lst = []\n",
    "        bst_model_id_lst.append(i)\n",
    "        min_mse = model_eval_dict[i]['mse']\n",
    "    elif model_eval_dict[i]['mse'] == min_mse:\n",
    "        bst_model_id_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_model_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.015598895028233528,\n",
       " 'mse': 0.015598895028233528,\n",
       " 'mae': 0.07869283109903336}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval_dict[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005, 'batch_size': 100, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_dict[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_dict[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ht_history[(0.0005, 100)] is best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "workdir = \"resnet_ht_models/comb_model\"\n",
    "\n",
    "json_file = open(workdir +'/model_architecture_15_new.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(workdir +\"/model_15_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.0005),\n",
    "                  metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 27s 35ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0787\n"
     ]
    }
   ],
   "source": [
    "test_eval = best_model.evaluate(test_X, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.015598895028233528, 0.015598895028233528, 0.07869283109903336]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 299s 228ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0724 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0682\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 301s 236ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0708 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0674\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 292s 229ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0690 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0677\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 285s 223ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0681 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0636\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 289s 227ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0666 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0650\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 291s 228ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0652 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0626\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 304s 239ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0638 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0637\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 297s 233ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0628 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0625\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 305s 239ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0613 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0599\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 300s 235ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0599 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0601\n"
     ]
    }
   ],
   "source": [
    "model_train = best_model.fit(train_X, train_y, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                                validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Test_v2_DNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 2973, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_330 (Conv1D)            (None, 1487, 16)     64          ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_15 (MaxPooling1D  (None, 297, 16)     0           ['conv1d_330[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_405 (Batch  (None, 297, 16)     64          ['max_pooling1d_15[0][0]']       \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_405 (Activation)    (None, 297, 16)      0           ['batch_normalization_405[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_331 (Conv1D)            (None, 297, 16)      784         ['activation_405[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_406 (Batch  (None, 297, 16)     64          ['conv1d_331[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_406 (Activation)    (None, 297, 16)      0           ['batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_332 (Conv1D)            (None, 297, 16)      784         ['activation_406[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_407 (Batch  (None, 297, 16)     64          ['conv1d_332[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_407 (Activation)    (None, 297, 16)      0           ['batch_normalization_407[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_333 (Conv1D)            (None, 297, 16)      784         ['activation_407[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_408 (Batch  (None, 297, 16)     64          ['conv1d_333[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_135 (Add)                  (None, 297, 16)      0           ['batch_normalization_408[0][0]',\n",
      "                                                                  'batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " activation_408 (Activation)    (None, 297, 16)      0           ['add_135[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_334 (Conv1D)            (None, 297, 16)      784         ['activation_408[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_409 (Batch  (None, 297, 16)     64          ['conv1d_334[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_409 (Activation)    (None, 297, 16)      0           ['batch_normalization_409[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_335 (Conv1D)            (None, 297, 16)      784         ['activation_409[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_410 (Batch  (None, 297, 16)     64          ['conv1d_335[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_410 (Activation)    (None, 297, 16)      0           ['batch_normalization_410[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_336 (Conv1D)            (None, 297, 16)      784         ['activation_410[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_411 (Batch  (None, 297, 16)     64          ['conv1d_336[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_411 (Activation)    (None, 297, 16)      0           ['batch_normalization_411[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_337 (Conv1D)            (None, 297, 16)      784         ['activation_411[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_412 (Batch  (None, 297, 16)     64          ['conv1d_337[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_136 (Add)                  (None, 297, 16)      0           ['batch_normalization_412[0][0]',\n",
      "                                                                  'batch_normalization_409[0][0]']\n",
      "                                                                                                  \n",
      " activation_412 (Activation)    (None, 297, 16)      0           ['add_136[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_338 (Conv1D)            (None, 149, 32)      1568        ['activation_412[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_413 (Batch  (None, 149, 32)     128         ['conv1d_338[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_413 (Activation)    (None, 149, 32)      0           ['batch_normalization_413[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_339 (Conv1D)            (None, 149, 32)      3104        ['activation_413[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_340 (Conv1D)            (None, 149, 32)      3104        ['conv1d_339[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_414 (Batch  (None, 149, 32)     128         ['conv1d_340[0][0]']             \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_137 (Add)                  (None, 149, 32)      0           ['batch_normalization_414[0][0]',\n",
      "                                                                  'batch_normalization_413[0][0]']\n",
      "                                                                                                  \n",
      " activation_414 (Activation)    (None, 149, 32)      0           ['add_137[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_341 (Conv1D)            (None, 149, 32)      3104        ['activation_414[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_415 (Batch  (None, 149, 32)     128         ['conv1d_341[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_415 (Activation)    (None, 149, 32)      0           ['batch_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_342 (Conv1D)            (None, 149, 32)      3104        ['activation_415[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_416 (Batch  (None, 149, 32)     128         ['conv1d_342[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_138 (Add)                  (None, 149, 32)      0           ['batch_normalization_416[0][0]',\n",
      "                                                                  'batch_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " activation_416 (Activation)    (None, 149, 32)      0           ['add_138[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_343 (Conv1D)            (None, 149, 32)      3104        ['activation_416[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_417 (Batch  (None, 149, 32)     128         ['conv1d_343[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_417 (Activation)    (None, 149, 32)      0           ['batch_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_344 (Conv1D)            (None, 149, 32)      3104        ['activation_417[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_418 (Batch  (None, 149, 32)     128         ['conv1d_344[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_139 (Add)                  (None, 149, 32)      0           ['batch_normalization_418[0][0]',\n",
      "                                                                  'batch_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " activation_418 (Activation)    (None, 149, 32)      0           ['add_139[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_345 (Conv1D)            (None, 75, 64)       6208        ['activation_418[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_419 (Batch  (None, 75, 64)      256         ['conv1d_345[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_419 (Activation)    (None, 75, 64)       0           ['batch_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_346 (Conv1D)            (None, 75, 64)       12352       ['activation_419[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_347 (Conv1D)            (None, 75, 64)       12352       ['conv1d_346[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_420 (Batch  (None, 75, 64)      256         ['conv1d_347[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_140 (Add)                  (None, 75, 64)       0           ['batch_normalization_420[0][0]',\n",
      "                                                                  'batch_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " activation_420 (Activation)    (None, 75, 64)       0           ['add_140[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_348 (Conv1D)            (None, 75, 64)       12352       ['activation_420[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_421 (Batch  (None, 75, 64)      256         ['conv1d_348[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_421 (Activation)    (None, 75, 64)       0           ['batch_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_349 (Conv1D)            (None, 75, 64)       12352       ['activation_421[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_422 (Batch  (None, 75, 64)      256         ['conv1d_349[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_141 (Add)                  (None, 75, 64)       0           ['batch_normalization_422[0][0]',\n",
      "                                                                  'batch_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " activation_422 (Activation)    (None, 75, 64)       0           ['add_141[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_350 (Conv1D)            (None, 75, 64)       12352       ['activation_422[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_423 (Batch  (None, 75, 64)      256         ['conv1d_350[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_423 (Activation)    (None, 75, 64)       0           ['batch_normalization_423[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_351 (Conv1D)            (None, 75, 64)       12352       ['activation_423[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_424 (Batch  (None, 75, 64)      256         ['conv1d_351[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_142 (Add)                  (None, 75, 64)       0           ['batch_normalization_424[0][0]',\n",
      "                                                                  'batch_normalization_423[0][0]']\n",
      "                                                                                                  \n",
      " activation_424 (Activation)    (None, 75, 64)       0           ['add_142[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 4800)         0           ['activation_424[0][0]']         \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 2048)         9832448     ['flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_425 (Batch  (None, 2048)        8192        ['dense1[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)             (None, 2048)         0           ['batch_normalization_425[0][0]']\n",
      "                                                                                                  \n",
      " activation_425 (Activation)    (None, 2048)         0           ['dropout1[0][0]']               \n",
      "                                                                                                  \n",
      " dense5 (Dense)                 (None, 1024)         2098176     ['activation_425[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_426 (Batch  (None, 1024)        4096        ['dense5[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout5 (Dropout)             (None, 1024)         0           ['batch_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " activation_426 (Activation)    (None, 1024)         0           ['dropout5[0][0]']               \n",
      "                                                                                                  \n",
      " dense6 (Dense)                 (None, 512)          524800      ['activation_426[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_427 (Batch  (None, 512)         2048        ['dense6[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout6 (Dropout)             (None, 512)          0           ['batch_normalization_427[0][0]']\n",
      "                                                                                                  \n",
      " activation_427 (Activation)    (None, 512)          0           ['dropout6[0][0]']               \n",
      "                                                                                                  \n",
      " dense7 (Dense)                 (None, 1024)         525312      ['activation_427[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_428 (Batch  (None, 1024)        4096        ['dense7[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout7 (Dropout)             (None, 1024)         0           ['batch_normalization_428[0][0]']\n",
      "                                                                                                  \n",
      " add_143 (Add)                  (None, 1024)         0           ['dropout7[0][0]',               \n",
      "                                                                  'batch_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " activation_428 (Activation)    (None, 1024)         0           ['add_143[0][0]']                \n",
      "                                                                                                  \n",
      " dense8 (Dense)                 (None, 512)          524800      ['activation_428[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_429 (Batch  (None, 512)         2048        ['dense8[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout8 (Dropout)             (None, 512)          0           ['batch_normalization_429[0][0]']\n",
      "                                                                                                  \n",
      " activation_429 (Activation)    (None, 512)          0           ['dropout8[0][0]']               \n",
      "                                                                                                  \n",
      " dense9 (Dense)                 (None, 256)          131328      ['activation_429[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_430 (Batch  (None, 256)         1024        ['dense9[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout9 (Dropout)             (None, 256)          0           ['batch_normalization_430[0][0]']\n",
      "                                                                                                  \n",
      " activation_430 (Activation)    (None, 256)          0           ['dropout9[0][0]']               \n",
      "                                                                                                  \n",
      " dense10 (Dense)                (None, 128)          32896       ['activation_430[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_431 (Batch  (None, 128)         512         ['dense10[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout10 (Dropout)            (None, 128)          0           ['batch_normalization_431[0][0]']\n",
      "                                                                                                  \n",
      " activation_431 (Activation)    (None, 128)          0           ['dropout10[0][0]']              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1)            129         ['activation_431[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,800,785\n",
      "Trainable params: 13,788,369\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse and loss monitor\n",
    "\n",
    "accuracy = model_train.history['mse']\n",
    "val_accuracy = model_train.history['val_mse']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "\n",
    "np_acc = np.array(accuracy)\n",
    "np_val_acc = np.array(val_accuracy)\n",
    "np_loss = np.array(loss)\n",
    "np_val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training mse')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation mse')\n",
    "plt.title('Training and validation mse')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(workdir + '//mse_loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 30s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# test validation\n",
    "predicted_classes = best_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_y)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '/DeepAUCv2_epoch_10_ht_result_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682176</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917732</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875777</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.945663</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859368</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>0.729678</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>0.922746</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>0.976536</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>0.678524</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted      Test\n",
       "0       0.682176  0.528562\n",
       "1       0.917732  0.930958\n",
       "2       0.875777  0.759249\n",
       "3       0.945663  0.936510\n",
       "4       0.859368  0.823453\n",
       "...          ...       ...\n",
       "22873   0.729678  0.975578\n",
       "22874   0.976484  0.980529\n",
       "22875   0.922746  0.960501\n",
       "22876   0.976536  0.970524\n",
       "22877   0.678524  0.706073\n",
       "\n",
       "[22878 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22878, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted_AUC_value')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot as test validation\n",
    "plt.scatter(test_y,predicted_value,c='blue')\n",
    "plt.xlabel('test_AUC_value')\n",
    "plt.ylabel('predicted_AUC_value')\n",
    "# plt.savefig(workdir + '/DeepAUCv2_epoch_10_ht_test_scatterplot_new.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 0.12862237734620172\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "\n",
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07811579817565177"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = (np.abs(b[0]-a[0])).sum()\n",
    "mae / len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016543715954188704"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5080917901797122\n"
     ]
    }
   ],
   "source": [
    "# R-squared value\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_value = r2_score(b, a) \n",
    "print(r2_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = pd.read_csv('/data/yingfei/cancer_data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = full_test[['ARXSPAN_ID', 'DRUG_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>auc</th>\n",
       "      <th>pred_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.528562</td>\n",
       "      <td>0.682176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.930958</td>\n",
       "      <td>0.917732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.759249</td>\n",
       "      <td>0.875777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>0.936510</td>\n",
       "      <td>0.945663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>0.823453</td>\n",
       "      <td>0.859368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>KIN001-266</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.729678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0.980529</td>\n",
       "      <td>0.976484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0.960501</td>\n",
       "      <td>0.922746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0.970524</td>\n",
       "      <td>0.976536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0.706073</td>\n",
       "      <td>0.678524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARXSPAN_ID   DRUG_NAME       auc  pred_auc\n",
       "0      ACH-000802   JW-7-24-1  0.528562  0.682176\n",
       "1      ACH-000802  KIN001-260  0.930958  0.917732\n",
       "2      ACH-000802   NSC-87877  0.759249  0.875777\n",
       "3      ACH-000802    PLX-4720  0.936510  0.945663\n",
       "4      ACH-000802   ERK5-IN-1  0.823453  0.859368\n",
       "...           ...         ...       ...       ...\n",
       "22873  ACH-000438  KIN001-266  0.975578  0.729678\n",
       "22874  ACH-000438  LUMINESPIB  0.980529  0.976484\n",
       "22875  ACH-000438   NUTLIN-3A  0.960501  0.922746\n",
       "22876  ACH-000438     SGC0946  0.970524  0.976536\n",
       "22877  ACH-000438   SL 0101-1  0.706073  0.678524\n",
       "\n",
       "[22878 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data = test_data[['ARXSPAN_ID', 'DRUG_NAME', 'auc']].copy()\n",
    "eval_data['pred_auc'] = predicted_value\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test['comb'] = full_test.ARXSPAN_ID + full_test.DRUG_NAME\n",
    "eval_data['comb'] = eval_data.ARXSPAN_ID + eval_data.DRUG_NAME\n",
    "eval_data = pd.merge(full_test, eval_data, on = ['ARXSPAN_ID', 'DRUG_NAME'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_test.comb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>true_auc_arr</th>\n",
       "      <th>pred_auc_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-001496</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000267</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000508</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001106</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ACH-000953</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ACH-000561</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ACH-000819</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ARXSPAN_ID true_auc_arr pred_auc_arr\n",
       "0   ACH-000802           []           []\n",
       "1   ACH-001496           []           []\n",
       "2   ACH-000267           []           []\n",
       "3   ACH-000508           []           []\n",
       "4   ACH-001106           []           []\n",
       "..         ...          ...          ...\n",
       "64  ACH-000953           []           []\n",
       "65  ACH-000561           []           []\n",
       "66  ACH-000819           []           []\n",
       "67  ACH-000873           []           []\n",
       "68  ACH-000438           []           []\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_arr = pd.DataFrame(eval_data.ARXSPAN_ID.unique(), columns = ['ARXSPAN_ID'])\n",
    "eval_data_arr['true_auc_arr'] = [[] for _ in range(len(eval_data_arr))]\n",
    "eval_data_arr['pred_auc_arr'] = [[] for _ in range(len(eval_data_arr))]\n",
    "eval_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eval_data)):\n",
    "    cl_id = eval_data.loc[i, 'ARXSPAN_ID']\n",
    "    auc = eval_data.loc[i, 'auc']\n",
    "    pred_auc =  eval_data.loc[i, 'pred_auc']\n",
    "    if np.isnan(auc):\n",
    "        #eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'true_auc_arr'].values[0].append(1)\n",
    "        #eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'pred_auc_arr'].values[0].append(1)\n",
    "        continue\n",
    "    eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'true_auc_arr'].values[0].append(auc)\n",
    "    eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'pred_auc_arr'].values[0].append(pred_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>true_auc_arr</th>\n",
       "      <th>pred_auc_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>[0.528562, 0.930958, 0.759249, 0.93651, 0.8234...</td>\n",
       "      <td>[0.68217605, 0.9177323, 0.87577736, 0.9456634,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-001496</td>\n",
       "      <td>[0.8600040000000001, 0.935607, 0.919367, 0.861...</td>\n",
       "      <td>[0.5477828, 0.9244617, 0.90034974, 0.93516946,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000267</td>\n",
       "      <td>[0.730128, 0.930868, 0.761296, 0.94428, 0.7239...</td>\n",
       "      <td>[0.59813344, 0.91872066, 0.8638028, 0.6393524,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000508</td>\n",
       "      <td>[0.958722, 0.966097, 0.832343, 0.818851, 0.953...</td>\n",
       "      <td>[0.7384716, 0.94181216, 0.89044666, 0.8122955,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001106</td>\n",
       "      <td>[0.670247, 0.845083, 0.720917, 0.705755, 0.865...</td>\n",
       "      <td>[0.64777327, 0.8855921, 0.88230455, 0.7109167,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ACH-000953</td>\n",
       "      <td>[0.771624, 0.902238, 0.788892, 0.987629, 0.977...</td>\n",
       "      <td>[0.6940112, 0.83775795, 0.78701276, 0.69917464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ACH-000561</td>\n",
       "      <td>[0.806557, 0.92585, 0.747498, 0.974266, 0.7882...</td>\n",
       "      <td>[0.73899513, 0.92920077, 0.87240815, 0.96024, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ACH-000819</td>\n",
       "      <td>[0.8246040000000001, 0.93947, 0.778985, 0.9747...</td>\n",
       "      <td>[0.6987132, 0.8984181, 0.8696494, 0.9215788, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>[0.6613979999999999, 0.876398, 0.837356, 0.971...</td>\n",
       "      <td>[0.68555737, 0.89708185, 0.8991858, 0.92504114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>[0.95799, 0.8848719999999999, 0.748696, 0.7972...</td>\n",
       "      <td>[0.6473282, 0.89335674, 0.8648896, 0.70555377,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ARXSPAN_ID                                       true_auc_arr  \\\n",
       "0   ACH-000802  [0.528562, 0.930958, 0.759249, 0.93651, 0.8234...   \n",
       "1   ACH-001496  [0.8600040000000001, 0.935607, 0.919367, 0.861...   \n",
       "2   ACH-000267  [0.730128, 0.930868, 0.761296, 0.94428, 0.7239...   \n",
       "3   ACH-000508  [0.958722, 0.966097, 0.832343, 0.818851, 0.953...   \n",
       "4   ACH-001106  [0.670247, 0.845083, 0.720917, 0.705755, 0.865...   \n",
       "..         ...                                                ...   \n",
       "64  ACH-000953  [0.771624, 0.902238, 0.788892, 0.987629, 0.977...   \n",
       "65  ACH-000561  [0.806557, 0.92585, 0.747498, 0.974266, 0.7882...   \n",
       "66  ACH-000819  [0.8246040000000001, 0.93947, 0.778985, 0.9747...   \n",
       "67  ACH-000873  [0.6613979999999999, 0.876398, 0.837356, 0.971...   \n",
       "68  ACH-000438  [0.95799, 0.8848719999999999, 0.748696, 0.7972...   \n",
       "\n",
       "                                         pred_auc_arr  \n",
       "0   [0.68217605, 0.9177323, 0.87577736, 0.9456634,...  \n",
       "1   [0.5477828, 0.9244617, 0.90034974, 0.93516946,...  \n",
       "2   [0.59813344, 0.91872066, 0.8638028, 0.6393524,...  \n",
       "3   [0.7384716, 0.94181216, 0.89044666, 0.8122955,...  \n",
       "4   [0.64777327, 0.8855921, 0.88230455, 0.7109167,...  \n",
       "..                                                ...  \n",
       "64  [0.6940112, 0.83775795, 0.78701276, 0.69917464...  \n",
       "65  [0.73899513, 0.92920077, 0.87240815, 0.96024, ...  \n",
       "66  [0.6987132, 0.8984181, 0.8696494, 0.9215788, 0...  \n",
       "67  [0.68555737, 0.89708185, 0.8991858, 0.92504114...  \n",
       "68  [0.6473282, 0.89335674, 0.8648896, 0.70555377,...  \n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = eval_data_arr.pred_auc_arr.apply(lambda x: np.array(x)).to_numpy()\n",
    "true_values = eval_data_arr.true_auc_arr.apply(lambda x: np.array(x)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249250035022978\n",
      "0.7603030356834578\n"
     ]
    }
   ],
   "source": [
    "### NDCG\n",
    "from sklearn.metrics import ndcg_score\n",
    "#ndcg_all = ndcg_score([p for p in pred_values],[t for t in true_values])\n",
    "#ndcg_10 = ndcg_score([p for p in pred_values],[t for t in true_values], k = 10)\n",
    "ndcg_all_values = []\n",
    "ndcg_10_values = []\n",
    "for i in range(len(pred_values)):\n",
    "    pred_value = eval_data_arr['pred_auc_arr'].apply(lambda x:list(map(lambda y:1-y, x)))[i]\n",
    "    true_value = eval_data_arr['true_auc_arr'].apply(lambda x:list(map(lambda y:1-y, x)))[i]\n",
    "    ndcg_all_values.append(ndcg_score([pred_value],[true_value]))\n",
    "    ndcg_10_values.append(ndcg_score([pred_value],[true_value], k = 10))\n",
    "    \n",
    "ndcg_all = np.mean(ndcg_all_values)\n",
    "ndcg_10 = np.mean(ndcg_10_values)\n",
    "\n",
    "print(ndcg_all)\n",
    "print(ndcg_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Recall@1', 0.3333), ('Recall@2', 0.3913), ('Recall@5', 0.3739), ('Recall@10', 0.4406)]\n"
     ]
    }
   ],
   "source": [
    "### Recall\n",
    "results = []\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    dict_test_cell_line_idx_perf = {}\n",
    "    for cur_cell_line_idx in range(len(pred_values)):\n",
    "        # step 1\n",
    "        # per the ground truth\n",
    "        gt_aucs = true_values[cur_cell_line_idx]\n",
    "        # find the top k drugs's idx\n",
    "        topk_drug_idx_gt = np.argsort(gt_aucs)[:top_k]\n",
    "        # step 2\n",
    "        # per the predicted scores\n",
    "        pred_scores = pred_values[cur_cell_line_idx]\n",
    "        assert gt_aucs.shape == pred_scores.shape\n",
    "        # find the top k drugs'idx (note: here its by pred scores)\n",
    "        topk_drug_idx_pred = np.argsort(pred_scores)[:top_k]\n",
    "        # step 3\n",
    "        # recall@k\n",
    "        cur_recall_at_k = len(\n",
    "            set(topk_drug_idx_pred).intersection(set(topk_drug_idx_gt))\n",
    "        ) / len(set(topk_drug_idx_gt))\n",
    "        dict_test_cell_line_idx_perf[cur_cell_line_idx] = cur_recall_at_k\n",
    "\n",
    "    avg_recall_at_k = np.mean(list(dict_test_cell_line_idx_perf.values()))\n",
    "    results.append((f\"Recall@{top_k}\", round(avg_recall_at_k, 4)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Auc@1', '0.2453 (GT: 0.1198)'), ('Auc@2', '0.3106 (GT: 0.157)'), ('Auc@5', '0.4152 (GT: 0.222)'), ('Auc@10', '0.4475 (GT: 0.2893)')]\n"
     ]
    }
   ],
   "source": [
    "### AUC\n",
    "results = []\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    dict_test_cell_line_topk_auc_sum_gt = {}\n",
    "    dict_test_cell_line_topk_auc_sum_pred = {}\n",
    "    for cur_cell_line_idx in range(len(pred_values)):\n",
    "        # step 1\n",
    "        # per the predicted scores\n",
    "        pred_scores = pred_values[cur_cell_line_idx]\n",
    "        # find the top k drugs'idx (note: here its by pred scores)\n",
    "        topk_drug_idx_pred = np.argsort(pred_scores)[:top_k]\n",
    "        # step 2\n",
    "        # per the ground truth\n",
    "        gt_aucs = true_values[cur_cell_line_idx]\n",
    "        # find the top k predicted drugs' (per ground truth) aucs\n",
    "        topk_drug_idx_gt = np.argsort(gt_aucs)[:top_k]\n",
    "        dict_test_cell_line_topk_auc_sum_gt[cur_cell_line_idx] = np.mean(\n",
    "            gt_aucs[topk_drug_idx_gt]\n",
    "        )\n",
    "        dict_test_cell_line_topk_auc_sum_pred[cur_cell_line_idx] = np.mean(\n",
    "            gt_aucs[topk_drug_idx_pred]\n",
    "        )\n",
    "\n",
    "    avg_auc_topk_gt = np.mean(\n",
    "        list(dict_test_cell_line_topk_auc_sum_gt.values())\n",
    "    )\n",
    "    avg_auc_topk_pred = np.mean(\n",
    "        list(dict_test_cell_line_topk_auc_sum_pred.values())\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        (\n",
    "            f\"Auc@{top_k}\",\n",
    "            f\"{round(avg_auc_topk_pred, 4)} (GT: {round(avg_auc_topk_gt, 4)})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7191598193085215 0.7230984375685384\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "print(pearsonr(c.Predicted, c.Test)[0], spearmanr(c.Predicted, c.Test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682176</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917732</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875777</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.945663</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859368</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>0.729678</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>0.922746</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>0.976536</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>0.678524</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted      Test\n",
       "0       0.682176  0.528562\n",
       "1       0.917732  0.930958\n",
       "2       0.875777  0.759249\n",
       "3       0.945663  0.936510\n",
       "4       0.859368  0.823453\n",
       "...          ...       ...\n",
       "22873   0.729678  0.975578\n",
       "22874   0.976484  0.980529\n",
       "22875   0.922746  0.960501\n",
       "22876   0.976536  0.970524\n",
       "22877   0.678524  0.706073\n",
       "\n",
       "[22878 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(workdir + '/DeepAUCv2_epoch_10_ht_result_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('Auc@1', '0.36090001463890076 (GT: 0.11209999769926071)'), ('Auc@2', '0.40849998593330383 (GT: 0.24279999732971191)'), ('Auc@5', '0.4742000102996826 (GT: 0.3368000090122223)'), ('Auc@10', '0.5327000021934509 (GT: 0.3993000090122223)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
