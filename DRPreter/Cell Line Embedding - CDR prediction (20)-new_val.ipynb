{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e439afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DRPreter Graph Embedding + PaDEL Descriptor + ResNet\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D ,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce01cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/data/yingfei/cancer_data/train_data.csv')\n",
    "test_data = pd.read_csv('/data/yingfei/cancer_data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f08357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "with open('./Data/train_celllines_v1_1111.txt') as f:\n",
    "    train_index = list(map(lambda x: x[:-1],f.readlines()))\n",
    "train_set_index, val_set_index = train_test_split(train_index, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3bf05ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACVR1B</th>\n",
       "      <th>AKT1</th>\n",
       "      <th>AKT2</th>\n",
       "      <th>AKT3</th>\n",
       "      <th>ALK</th>\n",
       "      <th>ALOX12B</th>\n",
       "      <th>FAM123B</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.891908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203913</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>KIN001-236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203914</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203915</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203916</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203917</th>\n",
       "      <td>ACH-001716</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203918 rows × 2652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ARXSPAN_ID   DRUG_NAME  ABL1  ACVR1B  AKT1  AKT2  AKT3  ALK  ALOX12B  \\\n",
       "0       ACH-000001   JW-7-24-1   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "1       ACH-000001  KIN001-260   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "2       ACH-000001   NSC-87877   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "3       ACH-000001    PLX-4720   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "4       ACH-000001   ERK5-IN-1   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "...            ...         ...   ...     ...   ...   ...   ...  ...      ...   \n",
       "203913  ACH-001716  KIN001-236   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "203914  ACH-001716  LUMINESPIB   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "203915  ACH-001716   NUTLIN-3A   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "203916  ACH-001716     SGC0946   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "203917  ACH-001716   SL 0101-1   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "\n",
       "        FAM123B  ...  PubchemFP872  PubchemFP873  PubchemFP874  PubchemFP875  \\\n",
       "0           0.0  ...             0             0             0             0   \n",
       "1           0.0  ...             0             0             0             0   \n",
       "2           0.0  ...             0             0             0             0   \n",
       "3           0.0  ...             0             0             0             0   \n",
       "4           0.0  ...             0             0             0             0   \n",
       "...         ...  ...           ...           ...           ...           ...   \n",
       "203913      0.0  ...             0             0             0             0   \n",
       "203914      0.0  ...             0             0             0             0   \n",
       "203915      0.0  ...             0             0             0             0   \n",
       "203916      0.0  ...             0             0             0             0   \n",
       "203917      0.0  ...             0             0             0             0   \n",
       "\n",
       "        PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  PubchemFP880  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "203913             0             0             0             0             0   \n",
       "203914             0             0             0             0             0   \n",
       "203915             0             0             0             0             0   \n",
       "203916             0             0             0             0             0   \n",
       "203917             0             0             0             0             0   \n",
       "\n",
       "             auc  \n",
       "0       0.778432  \n",
       "1       0.951321  \n",
       "2       0.840287  \n",
       "3       0.936410  \n",
       "4       0.891908  \n",
       "...          ...  \n",
       "203913  0.956865  \n",
       "203914  0.975168  \n",
       "203915  0.871995  \n",
       "203916  0.975417  \n",
       "203917  0.942321  \n",
       "\n",
       "[203918 rows x 2652 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.loc[train_data['auc'] >= 0]\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f439db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = train_data.loc[train_data.ARXSPAN_ID.isin(train_set_index)].copy()\n",
    "train_data_new = train_data_new.reset_index(drop = True)\n",
    "val_data_new = train_data.loc[train_data.ARXSPAN_ID.isin(val_set_index)].copy() \n",
    "val_data_new = val_data_new.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b7c5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>ABL1</th>\n",
       "      <th>ACVR1B</th>\n",
       "      <th>AKT1</th>\n",
       "      <th>AKT2</th>\n",
       "      <th>AKT3</th>\n",
       "      <th>ALK</th>\n",
       "      <th>ALOX12B</th>\n",
       "      <th>FAM123B</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>KIN001-266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 2652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARXSPAN_ID   DRUG_NAME  ABL1  ACVR1B  AKT1  AKT2  AKT3  ALK  ALOX12B  \\\n",
       "0      ACH-000802   JW-7-24-1   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "1      ACH-000802  KIN001-260   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "2      ACH-000802   NSC-87877   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "3      ACH-000802    PLX-4720   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "4      ACH-000802   ERK5-IN-1   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "...           ...         ...   ...     ...   ...   ...   ...  ...      ...   \n",
       "22873  ACH-000438  KIN001-266   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "22874  ACH-000438  LUMINESPIB   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "22875  ACH-000438   NUTLIN-3A   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "22876  ACH-000438     SGC0946   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "22877  ACH-000438   SL 0101-1   0.0     0.0   0.0   0.0   0.0  0.0      0.0   \n",
       "\n",
       "       FAM123B  ...  PubchemFP872  PubchemFP873  PubchemFP874  PubchemFP875  \\\n",
       "0          0.0  ...             0             0             0             0   \n",
       "1          0.0  ...             0             0             0             0   \n",
       "2          0.0  ...             0             0             0             0   \n",
       "3          0.0  ...             0             0             0             0   \n",
       "4          0.0  ...             0             0             0             0   \n",
       "...        ...  ...           ...           ...           ...           ...   \n",
       "22873      0.0  ...             0             0             0             0   \n",
       "22874      0.0  ...             0             0             0             0   \n",
       "22875      0.0  ...             0             0             0             0   \n",
       "22876      0.0  ...             0             0             0             0   \n",
       "22877      0.0  ...             0             0             0             0   \n",
       "\n",
       "       PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  PubchemFP880  \\\n",
       "0                 0             0             0             0             0   \n",
       "1                 0             0             0             0             0   \n",
       "2                 0             0             0             0             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "22873             0             0             0             0             0   \n",
       "22874             0             0             0             0             0   \n",
       "22875             0             0             0             0             0   \n",
       "22876             0             0             0             0             0   \n",
       "22877             0             0             0             0             0   \n",
       "\n",
       "            auc  \n",
       "0      0.528562  \n",
       "1      0.930958  \n",
       "2      0.759249  \n",
       "3      0.936510  \n",
       "4      0.823453  \n",
       "...         ...  \n",
       "22873  0.975578  \n",
       "22874  0.980529  \n",
       "22875  0.960501  \n",
       "22876  0.970524  \n",
       "22877  0.706073  \n",
       "\n",
       "[22878 rows x 2652 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_new = test_data.loc[test_data['auc'] >= 0]\n",
    "test_data_new = test_data_new.reset_index(drop = True)\n",
    "test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45642fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_padel_features = train_data_new[train_data_new.columns[-2326:-1]]\n",
    "train_padel_features = scaler.fit_transform(train_padel_features)\n",
    "train_padel_features = pd.DataFrame(train_padel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf51c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_padel_features = val_data_new[val_data_new.columns[-2326:-1]]\n",
    "val_padel_features = scaler.transform(val_padel_features)\n",
    "val_padel_features = pd.DataFrame(val_padel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32afb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padel_features = test_data_new[test_data_new.columns[-2326:-1]]\n",
    "test_padel_features = scaler.transform(test_padel_features)\n",
    "test_padel_features = pd.DataFrame(test_padel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6e39f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingfei/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f67d776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cell_line_embedding_dict_seg_cnv.pickle', 'rb') as file:\n",
    "    cell_line_embedding_dict = CPU_Unpickler(file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa8e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('drug_embedding_dict_seg_cnv.pickle', 'rb') as file:\n",
    "    drug_embedding_dict = CPU_Unpickler(file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a360b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_embedding_dict_new = {key:value[:, :-1, :].sum(dim=1) for key,value in cell_line_embedding_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d01fe3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183501, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "641c8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padel_features = train_padel_features.to_numpy().reshape(train_padel_features.shape[0], train_padel_features.shape[1], 1)\n",
    "val_padel_features = val_padel_features.to_numpy().reshape(val_padel_features.shape[0], val_padel_features.shape[1], 1)\n",
    "test_padel_features = test_padel_features.to_numpy().reshape(test_padel_features.shape[0], test_padel_features.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "495e875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183501, 2325, 1) (20417, 2325, 1) (22878, 2325, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_padel_features.shape, val_padel_features.shape, test_padel_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54e64fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cell_emb = []\n",
    "for i in range(len(train_data_new)):\n",
    "    cell_line_id = train_data_new['ARXSPAN_ID'][i]\n",
    "    train_cell_emb.append(cell_line_embedding_dict_new[cell_line_id].detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61cedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cell_emb = []\n",
    "for i in range(len(val_data_new)):\n",
    "    cell_line_id = val_data_new['ARXSPAN_ID'][i]\n",
    "    val_cell_emb.append(cell_line_embedding_dict_new[cell_line_id].detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52a885f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cell_emb = []\n",
    "for i in range(len(test_data_new)):\n",
    "    cell_line_id = test_data_new['ARXSPAN_ID'][i]\n",
    "    test_cell_emb.append(cell_line_embedding_dict_new[cell_line_id].detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6675692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cell_emb = np.array(train_cell_emb)\n",
    "train_cell_emb = train_cell_emb.reshape(train_cell_emb.shape[0], train_cell_emb.shape[1], 1)\n",
    "val_cell_emb = np.array(val_cell_emb)\n",
    "val_cell_emb = val_cell_emb.reshape(val_cell_emb.shape[0], val_cell_emb.shape[1], 1)\n",
    "test_cell_emb = np.array(test_cell_emb)\n",
    "test_cell_emb = test_cell_emb.reshape(test_cell_emb.shape[0], test_cell_emb.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59266ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183501, 256, 1) (20417, 256, 1) (22878, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_cell_emb.shape, val_cell_emb.shape, test_cell_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "475399f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum train y value: 0.004496,       Maximum train y value: 0.999883\n",
      "Minimum validation y value: 0.010477,       Maximum validation y value: 0.997684\n",
      "Minimum test y value: 0.013524,       Maximum test y value: 0.998284\n"
     ]
    }
   ],
   "source": [
    "train_label = train_data_new['auc']\n",
    "print(f'Minimum train y value: {min(train_label)}, \\\n",
    "      Maximum train y value: {max(train_label)}')\n",
    "\n",
    "val_label = val_data_new['auc']\n",
    "print(f'Minimum validation y value: {min(val_label)}, \\\n",
    "      Maximum validation y value: {max(val_label)}')\n",
    "\n",
    "test_label = test_data_new['auc']\n",
    "print(f'Minimum test y value: {min(test_label)}, \\\n",
    "      Maximum test y value: {max(test_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ceaa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train test split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_padel_features\n",
    "# train_padel_features, val_padel_features, train_y, val_y = train_test_split(\n",
    "#     train_padel_features, train_label, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "904d1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cell_emb, val_cell_emb, train_y, val_y = train_test_split(\n",
    "#     train_cell_emb, train_label, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b652d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padel_features = np.nan_to_num(train_padel_features)\n",
    "train_cell_emb = np.nan_to_num(train_cell_emb)\n",
    "train_y = np.nan_to_num(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd731f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_padel_features = np.nan_to_num(val_padel_features)\n",
    "val_cell_emb = np.nan_to_num(val_cell_emb)\n",
    "val_y = np.nan_to_num(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fad942a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padel_features = np.nan_to_num(test_padel_features)\n",
    "test_cell_emb = np.nan_to_num(test_cell_emb)\n",
    "test_y = np.nan_to_num(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18aa722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters set\n",
    "params_lst = [\"learning_rate\", \"batch_size\", \"optimizer\"]\n",
    "params_value_dict = {\"learning_rate\": [5e-5, 1e-4, 2e-4], \n",
    "                     \"batch_size\": [64, 128, 256], \n",
    "                     \"optimizer\": ['sgd','adam']}\n",
    "import itertools as it\n",
    "\n",
    "allparams = params_value_dict\n",
    "combinations = it.product(*(params_value_dict[param] for param in allparams))\n",
    "combinations_lst = list(combinations)\n",
    "print(len(combinations_lst))\n",
    "\n",
    "hyper_param_dict = {}\n",
    "for i in range(len(combinations_lst)):\n",
    "    hyper_param_dict[i] = {}\n",
    "    for j in range(len(params_lst)):\n",
    "        hyper_param_dict[i][params_lst[j]] = combinations_lst[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b82fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime : 2023-03-28 18:48:04.491207\n",
      "Epoch 1/20\n",
      "1434/1434 [==============================] - 331s 221ms/step - loss: 0.5727 - mse: 0.5727 - mae: 0.5934 - val_loss: 0.1901 - val_mse: 0.1901 - val_mae: 0.3491\n",
      "Epoch 2/20\n",
      "1434/1434 [==============================] - 322s 225ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4340 - val_loss: 0.1227 - val_mse: 0.1227 - val_mae: 0.2818\n",
      "Epoch 3/20\n",
      "1434/1434 [==============================] - 322s 224ms/step - loss: 0.2127 - mse: 0.2127 - mae: 0.3631 - val_loss: 0.0997 - val_mse: 0.0997 - val_mae: 0.2542\n",
      "Epoch 4/20\n",
      "1434/1434 [==============================] - 322s 225ms/step - loss: 0.1560 - mse: 0.1560 - mae: 0.3102 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.2118\n",
      "Epoch 5/20\n",
      "1434/1434 [==============================] - 326s 227ms/step - loss: 0.1224 - mse: 0.1224 - mae: 0.2737 - val_loss: 0.0599 - val_mse: 0.0599 - val_mae: 0.1997\n",
      "Epoch 6/20\n",
      "1434/1434 [==============================] - 350s 244ms/step - loss: 0.1025 - mse: 0.1025 - mae: 0.2495 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1834\n",
      "Epoch 7/20\n",
      "1434/1434 [==============================] - 358s 249ms/step - loss: 0.0869 - mse: 0.0869 - mae: 0.2287 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1777\n",
      "Epoch 8/20\n",
      "1434/1434 [==============================] - 339s 236ms/step - loss: 0.0766 - mse: 0.0766 - mae: 0.2146 - val_loss: 0.0432 - val_mse: 0.0432 - val_mae: 0.1706\n",
      "Epoch 9/20\n",
      "1434/1434 [==============================] - 346s 241ms/step - loss: 0.0689 - mse: 0.0689 - mae: 0.2032 - val_loss: 0.0396 - val_mse: 0.0396 - val_mae: 0.1629\n",
      "Epoch 10/20\n",
      "1434/1434 [==============================] - 347s 242ms/step - loss: 0.0632 - mse: 0.0632 - mae: 0.1942 - val_loss: 0.0375 - val_mse: 0.0375 - val_mae: 0.1591\n",
      "Epoch 11/20\n",
      "1434/1434 [==============================] - 345s 241ms/step - loss: 0.0582 - mse: 0.0582 - mae: 0.1861 - val_loss: 0.0350 - val_mse: 0.0350 - val_mae: 0.1535\n",
      "Epoch 12/20\n",
      "1434/1434 [==============================] - 345s 241ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.1801 - val_loss: 0.0341 - val_mse: 0.0341 - val_mae: 0.1515\n",
      "Epoch 13/20\n",
      "1434/1434 [==============================] - 347s 242ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1749 - val_loss: 0.0331 - val_mse: 0.0331 - val_mae: 0.1493\n",
      "Epoch 14/20\n",
      "1434/1434 [==============================] - 349s 243ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1697 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.1480\n",
      "Epoch 15/20\n",
      "1434/1434 [==============================] - 354s 247ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1657 - val_loss: 0.0315 - val_mse: 0.0315 - val_mae: 0.1455\n",
      "Epoch 16/20\n",
      "1434/1434 [==============================] - 344s 240ms/step - loss: 0.0445 - mse: 0.0445 - mae: 0.1616 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1432\n",
      "Epoch 17/20\n",
      "1434/1434 [==============================] - 356s 248ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1591 - val_loss: 0.0296 - val_mse: 0.0296 - val_mae: 0.1404\n",
      "Epoch 18/20\n",
      "1434/1434 [==============================] - 359s 251ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1558 - val_loss: 0.0287 - val_mse: 0.0287 - val_mae: 0.1382\n",
      "Epoch 19/20\n",
      "1434/1434 [==============================] - 367s 256ms/step - loss: 0.0401 - mse: 0.0401 - mae: 0.1534 - val_loss: 0.0282 - val_mse: 0.0282 - val_mae: 0.1364\n",
      "Epoch 20/20\n",
      "1434/1434 [==============================] - 366s 256ms/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1511 - val_loss: 0.0282 - val_mse: 0.0282 - val_mae: 0.1365\n",
      "EndTime : 2023-03-28 20:43:06.772725\n",
      "Evaluating model 14...\n",
      "715/715 [==============================] - 28s 39ms/step - loss: 0.0333 - mse: 0.0333 - mae: 0.1466\n",
      "loss=0.033312, mse=0.033312, mae=0.146563\n",
      "StartTime : 2023-03-28 20:43:36.973745\n",
      "Epoch 1/20\n",
      "1434/1434 [==============================] - 407s 272ms/step - loss: 0.1051 - mse: 0.1051 - mae: 0.2235 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0816\n",
      "Epoch 2/20\n",
      "1434/1434 [==============================] - 377s 263ms/step - loss: 0.0254 - mse: 0.0254 - mae: 0.1165 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0810\n",
      "Epoch 3/20\n",
      "1434/1434 [==============================] - 366s 255ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.0978 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0756\n",
      "Epoch 4/20\n",
      "1434/1434 [==============================] - 373s 260ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0886 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0751\n",
      "Epoch 5/20\n",
      "1434/1434 [==============================] - 387s 270ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0836 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0751\n",
      "Epoch 6/20\n",
      "1434/1434 [==============================] - 388s 271ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0806 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0746\n",
      "Epoch 7/20\n",
      "1434/1434 [==============================] - 384s 267ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0783 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0758\n",
      "Epoch 8/20\n",
      "1434/1434 [==============================] - 399s 278ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0770 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0754\n",
      "Epoch 9/20\n",
      "1434/1434 [==============================] - 399s 278ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0754 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0738\n",
      "Epoch 10/20\n",
      "1434/1434 [==============================] - 397s 277ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0742 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0787\n",
      "Epoch 11/20\n",
      "1434/1434 [==============================] - 403s 281ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0726 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0761\n",
      "Epoch 12/20\n",
      "1434/1434 [==============================] - 402s 281ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0719 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0724\n",
      "Epoch 13/20\n",
      "1434/1434 [==============================] - 414s 289ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0708 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0735\n",
      "Epoch 14/20\n",
      "1434/1434 [==============================] - 406s 283ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0700 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0740\n",
      "Epoch 15/20\n",
      "1434/1434 [==============================] - 404s 282ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0690 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0736\n",
      "Epoch 16/20\n",
      "1434/1434 [==============================] - 400s 279ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0682 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0742\n",
      "Epoch 17/20\n",
      "1434/1434 [==============================] - 398s 278ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0675 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0772\n",
      "Epoch 18/20\n",
      "1434/1434 [==============================] - 395s 275ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0667 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0745\n",
      "Epoch 19/20\n",
      "1434/1434 [==============================] - 403s 281ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0660 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0739\n",
      "Epoch 20/20\n",
      "1434/1434 [==============================] - 401s 280ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0654 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0725\n",
      "EndTime : 2023-03-28 22:55:26.021922\n",
      "Evaluating model 15...\n",
      "715/715 [==============================] - 29s 40ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0746\n",
      "loss=0.014963, mse=0.014963, mae=0.074620\n",
      "StartTime : 2023-03-28 22:55:57.526395\n",
      "Epoch 1/20\n",
      "717/717 [==============================] - 317s 411ms/step - loss: 0.7174 - mse: 0.7174 - mae: 0.6671 - val_loss: 0.3051 - val_mse: 0.3051 - val_mae: 0.4469\n",
      "Epoch 2/20\n",
      "717/717 [==============================] - 293s 409ms/step - loss: 0.4576 - mse: 0.4576 - mae: 0.5344 - val_loss: 0.2136 - val_mse: 0.2136 - val_mae: 0.3710\n",
      "Epoch 3/20\n",
      "717/717 [==============================] - 291s 405ms/step - loss: 0.3566 - mse: 0.3566 - mae: 0.4726 - val_loss: 0.1811 - val_mse: 0.1811 - val_mae: 0.3447\n",
      "Epoch 4/20\n",
      "717/717 [==============================] - 292s 407ms/step - loss: 0.2925 - mse: 0.2925 - mae: 0.4272 - val_loss: 0.1442 - val_mse: 0.1442 - val_mae: 0.3064\n",
      "Epoch 5/20\n",
      "717/717 [==============================] - 298s 416ms/step - loss: 0.2512 - mse: 0.2512 - mae: 0.3965 - val_loss: 0.1367 - val_mse: 0.1367 - val_mae: 0.3000\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 293s 409ms/step - loss: 0.2200 - mse: 0.2200 - mae: 0.3704 - val_loss: 0.1139 - val_mse: 0.1139 - val_mae: 0.2755\n",
      "Epoch 7/20\n",
      "717/717 [==============================] - 292s 407ms/step - loss: 0.1912 - mse: 0.1912 - mae: 0.3451 - val_loss: 0.0974 - val_mse: 0.0974 - val_mae: 0.2527\n",
      "Epoch 8/20\n",
      "717/717 [==============================] - 295s 411ms/step - loss: 0.1698 - mse: 0.1698 - mae: 0.3245 - val_loss: 0.0840 - val_mse: 0.0840 - val_mae: 0.2333\n",
      "Epoch 9/20\n",
      "717/717 [==============================] - 297s 414ms/step - loss: 0.1504 - mse: 0.1504 - mae: 0.3046 - val_loss: 0.0811 - val_mse: 0.0811 - val_mae: 0.2307\n",
      "Epoch 10/20\n",
      "717/717 [==============================] - 297s 414ms/step - loss: 0.1357 - mse: 0.1357 - mae: 0.2894 - val_loss: 0.0795 - val_mse: 0.0795 - val_mae: 0.2317\n",
      "Epoch 11/20\n",
      "717/717 [==============================] - 299s 417ms/step - loss: 0.1241 - mse: 0.1241 - mae: 0.2769 - val_loss: 0.0727 - val_mse: 0.0727 - val_mae: 0.2201\n",
      "Epoch 12/20\n",
      "717/717 [==============================] - 298s 416ms/step - loss: 0.1138 - mse: 0.1138 - mae: 0.2652 - val_loss: 0.0662 - val_mse: 0.0662 - val_mae: 0.2098\n",
      "Epoch 13/20\n",
      "717/717 [==============================] - 296s 413ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2545 - val_loss: 0.0620 - val_mse: 0.0620 - val_mae: 0.2037\n",
      "Epoch 14/20\n",
      "717/717 [==============================] - 290s 404ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2438 - val_loss: 0.0615 - val_mse: 0.0615 - val_mae: 0.2038\n",
      "Epoch 15/20\n",
      "717/717 [==============================] - 290s 404ms/step - loss: 0.0903 - mse: 0.0903 - mae: 0.2357 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.2008\n",
      "Epoch 16/20\n",
      "717/717 [==============================] - 294s 411ms/step - loss: 0.0847 - mse: 0.0847 - mae: 0.2277 - val_loss: 0.0538 - val_mse: 0.0538 - val_mae: 0.1910\n",
      "Epoch 17/20\n",
      "717/717 [==============================] - 286s 399ms/step - loss: 0.0789 - mse: 0.0789 - mae: 0.2198 - val_loss: 0.0513 - val_mse: 0.0513 - val_mae: 0.1874\n",
      "Epoch 18/20\n",
      "717/717 [==============================] - 291s 406ms/step - loss: 0.0744 - mse: 0.0744 - mae: 0.2133 - val_loss: 0.0497 - val_mse: 0.0497 - val_mae: 0.1838\n",
      "Epoch 19/20\n",
      "717/717 [==============================] - 296s 412ms/step - loss: 0.0705 - mse: 0.0705 - mae: 0.2073 - val_loss: 0.0483 - val_mse: 0.0483 - val_mae: 0.1812\n",
      "Epoch 20/20\n",
      "717/717 [==============================] - 293s 408ms/step - loss: 0.0669 - mse: 0.0669 - mae: 0.2019 - val_loss: 0.0463 - val_mse: 0.0463 - val_mae: 0.1781\n",
      "EndTime : 2023-03-29 00:34:20.682284\n",
      "Evaluating model 16...\n",
      "715/715 [==============================] - 30s 42ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1750\n",
      "loss=0.045408, mse=0.045408, mae=0.174971\n",
      "StartTime : 2023-03-29 00:34:54.383276\n",
      "Epoch 1/20\n",
      "717/717 [==============================] - 297s 390ms/step - loss: 0.2604 - mse: 0.2604 - mae: 0.3236 - val_loss: 0.0301 - val_mse: 0.0301 - val_mae: 0.1127\n",
      "Epoch 2/20\n",
      "717/717 [==============================] - 288s 402ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1519 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0906\n",
      "Epoch 3/20\n",
      "717/717 [==============================] - 299s 417ms/step - loss: 0.0298 - mse: 0.0298 - mae: 0.1239 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0802\n",
      "Epoch 4/20\n",
      "717/717 [==============================] - 292s 407ms/step - loss: 0.0231 - mse: 0.0231 - mae: 0.1105 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0778\n",
      "Epoch 5/20\n",
      "717/717 [==============================] - 298s 416ms/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1009 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0746\n",
      "Epoch 6/20\n",
      "717/717 [==============================] - 302s 421ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0942 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0745\n",
      "Epoch 7/20\n",
      "717/717 [==============================] - 285s 398ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0890 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0755\n",
      "Epoch 8/20\n",
      "717/717 [==============================] - 298s 416ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0853 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0741\n",
      "Epoch 9/20\n",
      "717/717 [==============================] - 290s 404ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0825 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0724\n",
      "Epoch 10/20\n",
      "717/717 [==============================] - 296s 413ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0813 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0732\n",
      "Epoch 11/20\n",
      "717/717 [==============================] - 298s 415ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0794 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0760\n",
      "Epoch 12/20\n",
      "717/717 [==============================] - 292s 408ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0777 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0723\n",
      "Epoch 13/20\n",
      "717/717 [==============================] - 294s 410ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0767 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0762\n",
      "Epoch 14/20\n",
      "560/717 [======================>.......] - ETA: 1:03 - loss: 0.0121 - mse: 0.0121 - mae: 0.0753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from keras.layers import concatenate\n",
    "workdir = \"../resnet_ht_models/emb_model_graph_4\"\n",
    "\n",
    "model_eval_dict = {}\n",
    "model_dict = {}\n",
    "training_epochs = 20\n",
    "model_ht_history = {}\n",
    "\n",
    "for i in hyper_param_dict:\n",
    "    if i <= 13: ### run the remaining models\n",
    "        continue\n",
    "    params_dict = hyper_param_dict[i]\n",
    "    learning_rate=params_dict[\"learning_rate\"] \n",
    "    batch_size=params_dict[\"batch_size\"] \n",
    "    opt_name=params_dict[\"optimizer\"]\n",
    "    \n",
    "    # hyper parameters\n",
    "    num_classes = 1\n",
    "    if opt_name == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    else: # sgd\n",
    "        optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    with K.tf.device('/GPU:0'): # model compile\n",
    "        # inputs = Input(shape=(train_X.shape[1],1),name='inputs')\n",
    "        \n",
    "        cell_input = Input(shape=(256,1),  name='cell_input') \n",
    "        drug_input = Input(shape=(2325,1), name='drug_input')\n",
    "        inputs = concatenate([cell_input, drug_input],axis=1) \n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "        x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    #     y = x\n",
    "        x = Activation('tanh')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(16, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "    #     x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(32, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "    #     x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv1D(64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    #     x = MaxPooling1D(pool_size=5)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    #     x = AveragePooling1D(pool_size=8)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(units=2048, name='dense1'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout1') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    #    x = Reshape((300,1))(x)\n",
    "\n",
    "    #    x = Conv1D(30, kernel_size=150, strides=1, activation = 'relu')(x)\n",
    "    #    x = MaxPooling1D(pool_size=2)(x)\n",
    "    #    x = BatchNormalization()(x)\n",
    "\n",
    "        x = Dense(units=1024, name='dense5'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Dropout(0.1, name='dropout5') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=512, name='dense6'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout6') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=1024, name='dense7'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout7') (x)\n",
    "        x = keras.layers.add([x,y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=512, name='dense8'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout8') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=256, name='dense9'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.1, name='dropout9') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Dense(units=128, name='dense10'  ) (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        y = x\n",
    "        x = Dropout(0.1, name='dropout10') (x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "        predictions = Dense(1, activation='linear', name='predictions', kernel_initializer='he_normal')(x)\n",
    "\n",
    "        # model = Model(inputs=inputs, outputs=predictions, name='Test_v2_DNN')\n",
    "        model = Model(inputs=[cell_input , drug_input], outputs=[predictions])\n",
    "        model.compile(loss=keras.losses.mean_squared_error,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['mse','mae'])\n",
    "        \n",
    "        # model training\n",
    "        StartTime8 = datetime.now()\n",
    "        print(\"StartTime :\", StartTime8)\n",
    "        with K.tf.device('/GPU:0'):\n",
    "            # model_train = model.fit(train_X, train_y, batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "            #                     validation_data=(val_X, val_y))\n",
    "            model_train = model.fit({'cell_input': train_cell_emb, 'drug_input': train_padel_features}, train_y, \n",
    "                                    batch_size=batch_size,epochs=training_epochs,verbose=1,\n",
    "                                    validation_data=({'cell_input': val_cell_emb, \n",
    "                                                      'drug_input': val_padel_features}\n",
    "                                                     , val_y))\n",
    "\n",
    "        EndTime8 = datetime.now()\n",
    "        print(\"EndTime :\", EndTime8)\n",
    "    model.save_weights(workdir+ f'/model_{i}_new.h5')\n",
    "    with open(workdir + f'/model_architecture_{i}_new.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "        \n",
    "    # evaluation\n",
    "    print(f\"Evaluating model {i}...\")\n",
    "    test_score = model.evaluate({'cell_input': test_cell_emb, 'drug_input': test_padel_features}, test_y, verbose=1)\n",
    "    model_ht_history[(learning_rate, batch_size)] = model\n",
    "    loss, mse, mae = test_score\n",
    "    print(\"loss=%.6f, mse=%.6f, mae=%.6f\"%(loss, mse, mae))\n",
    "    \n",
    "    model_dict[i] = model\n",
    "    model_eval_dict[i] = {\"loss\":loss, \"mse\":mse, \"mae\":mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe153eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mse = 10\n",
    "bst_model_id_lst = []\n",
    "for i in model_eval_dict:\n",
    "    if model_eval_dict[i]['mse'] < min_mse:\n",
    "        bst_model_id_lst = []\n",
    "        bst_model_id_lst.append(i)\n",
    "        min_mse = model_eval_dict[i]['mse']\n",
    "    elif model_eval_dict[i]['mse'] == min_mse:\n",
    "        bst_model_id_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5312190",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = bst_model_id_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68bfcec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ec365b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.014906061813235283,\n",
       " 'mse': 0.014906061813235283,\n",
       " 'mae': 0.0767875611782074}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6b9d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "182b8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 27s 38ms/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0759\n"
     ]
    }
   ],
   "source": [
    "test_eval = best_model.evaluate({'cell_input': test_cell_emb, 'drug_input': test_padel_features}, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50ba0c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 5e-05, 'batch_size': 128, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75861e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58de3429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 26s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'predicted_AUC_value')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_value = model.predict({'cell_input': test_cell_emb, 'drug_input': test_padel_features})\n",
    "plt.scatter(test_y,predicted_value,c='blue')\n",
    "plt.xlabel('test_AUC_value')\n",
    "plt.ylabel('predicted_AUC_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7efd6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(predicted_value)\n",
    "b = pd.DataFrame(test_y)\n",
    "c = pd.concat([a,b], axis=1)\n",
    "c.columns=[\"Predicted\",\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05a0b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rmse value is = 0.12807085961980627\n"
     ]
    }
   ],
   "source": [
    "rse = ((b[0]-a[0])**2).sum()\n",
    "mse = rse / len(b)\n",
    "print(\"Final rmse value is =\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e49904f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07730036887955459"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = (np.abs(b[0]-a[0])).sum()\n",
    "mae / len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ebbcd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016402145083756123"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7befe4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5123012358465762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_value = r2_score(b, a) \n",
    "print(r2_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61cf6abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>auc</th>\n",
       "      <th>pred_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.528562</td>\n",
       "      <td>0.700807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.930958</td>\n",
       "      <td>0.926843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.759249</td>\n",
       "      <td>0.863386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>PLX-4720</td>\n",
       "      <td>0.936510</td>\n",
       "      <td>0.956219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>ERK5-IN-1</td>\n",
       "      <td>0.823453</td>\n",
       "      <td>0.860413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22873</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>KIN001-266</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.754735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22874</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>LUMINESPIB</td>\n",
       "      <td>0.980529</td>\n",
       "      <td>0.982019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22875</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>NUTLIN-3A</td>\n",
       "      <td>0.960501</td>\n",
       "      <td>0.947060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22876</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SGC0946</td>\n",
       "      <td>0.970524</td>\n",
       "      <td>0.983547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22877</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>SL 0101-1</td>\n",
       "      <td>0.706073</td>\n",
       "      <td>0.725565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22878 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARXSPAN_ID   DRUG_NAME       auc  pred_auc\n",
       "0      ACH-000802   JW-7-24-1  0.528562  0.700807\n",
       "1      ACH-000802  KIN001-260  0.930958  0.926843\n",
       "2      ACH-000802   NSC-87877  0.759249  0.863386\n",
       "3      ACH-000802    PLX-4720  0.936510  0.956219\n",
       "4      ACH-000802   ERK5-IN-1  0.823453  0.860413\n",
       "...           ...         ...       ...       ...\n",
       "22873  ACH-000438  KIN001-266  0.975578  0.754735\n",
       "22874  ACH-000438  LUMINESPIB  0.980529  0.982019\n",
       "22875  ACH-000438   NUTLIN-3A  0.960501  0.947060\n",
       "22876  ACH-000438     SGC0946  0.970524  0.983547\n",
       "22877  ACH-000438   SL 0101-1  0.706073  0.725565\n",
       "\n",
       "[22878 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test = pd.read_csv('/data/yingfei/cancer_data/test_data.csv')\n",
    "\n",
    "full_test = full_test[['ARXSPAN_ID', 'DRUG_NAME']]\n",
    "eval_data = test_data[['ARXSPAN_ID', 'DRUG_NAME', 'auc']].copy()\n",
    "eval_data['pred_auc'] = predicted_value\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d587a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test['comb'] = full_test.ARXSPAN_ID + full_test.DRUG_NAME\n",
    "eval_data['comb'] = eval_data.ARXSPAN_ID + eval_data.DRUG_NAME\n",
    "eval_data = pd.merge(full_test, eval_data, on = ['ARXSPAN_ID', 'DRUG_NAME'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36784889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARXSPAN_ID</th>\n",
       "      <th>true_auc_arr</th>\n",
       "      <th>pred_auc_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000802</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-001496</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000267</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000508</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001106</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ACH-000953</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ACH-000561</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ACH-000819</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACH-000438</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ARXSPAN_ID true_auc_arr pred_auc_arr\n",
       "0   ACH-000802           []           []\n",
       "1   ACH-001496           []           []\n",
       "2   ACH-000267           []           []\n",
       "3   ACH-000508           []           []\n",
       "4   ACH-001106           []           []\n",
       "..         ...          ...          ...\n",
       "64  ACH-000953           []           []\n",
       "65  ACH-000561           []           []\n",
       "66  ACH-000819           []           []\n",
       "67  ACH-000873           []           []\n",
       "68  ACH-000438           []           []\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_arr = pd.DataFrame(eval_data.ARXSPAN_ID.unique(), columns = ['ARXSPAN_ID'])\n",
    "eval_data_arr['true_auc_arr'] = [[] for _ in range(len(eval_data_arr))]\n",
    "eval_data_arr['pred_auc_arr'] = [[] for _ in range(len(eval_data_arr))]\n",
    "eval_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "707c5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eval_data)):\n",
    "    cl_id = eval_data.loc[i, 'ARXSPAN_ID']\n",
    "    auc = eval_data.loc[i, 'auc']\n",
    "    pred_auc =  eval_data.loc[i, 'pred_auc']\n",
    "    if np.isnan(auc):\n",
    "        #eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'true_auc_arr'].values[0].append(1)\n",
    "        #eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'pred_auc_arr'].values[0].append(1)\n",
    "        continue\n",
    "    eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'true_auc_arr'].values[0].append(auc)\n",
    "    eval_data_arr.loc[eval_data_arr.ARXSPAN_ID == cl_id, 'pred_auc_arr'].values[0].append(pred_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e903b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = eval_data_arr.pred_auc_arr.apply(lambda x: np.array(x)).to_numpy()\n",
    "true_values = eval_data_arr.true_auc_arr.apply(lambda x: np.array(x)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a78e17f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932643113464056\n",
      "0.7790959138686008\n"
     ]
    }
   ],
   "source": [
    "### NDCG\n",
    "from sklearn.metrics import ndcg_score\n",
    "#ndcg_all = ndcg_score([p for p in pred_values],[t for t in true_values])\n",
    "#ndcg_10 = ndcg_score([p for p in pred_values],[t for t in true_values], k = 10)\n",
    "ndcg_all_values = []\n",
    "ndcg_10_values = []\n",
    "for i in range(len(pred_values)):\n",
    "    pred_value = eval_data_arr['pred_auc_arr'].apply(lambda x:list(map(lambda y:1-y, x)))[i]\n",
    "    true_value = eval_data_arr['true_auc_arr'].apply(lambda x:list(map(lambda y:1-y, x)))[i]\n",
    "    ndcg_all_values.append(ndcg_score([pred_value],[true_value]))\n",
    "    ndcg_10_values.append(ndcg_score([pred_value],[true_value], k = 10))\n",
    "    \n",
    "ndcg_all = np.mean(ndcg_all_values)\n",
    "ndcg_10 = np.mean(ndcg_10_values)\n",
    "\n",
    "print(ndcg_all)\n",
    "print(ndcg_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bbdac06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Recall@1', 0.3768), ('Recall@2', 0.3913), ('Recall@5', 0.4116), ('Recall@10', 0.4493)]\n"
     ]
    }
   ],
   "source": [
    "### Recall\n",
    "results = []\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    dict_test_cell_line_idx_perf = {}\n",
    "    for cur_cell_line_idx in range(len(pred_values)):\n",
    "        # step 1\n",
    "        # per the ground truth\n",
    "        gt_aucs = true_values[cur_cell_line_idx]\n",
    "        # find the top k drugs's idx\n",
    "        topk_drug_idx_gt = np.argsort(gt_aucs)[:top_k]\n",
    "        # step 2\n",
    "        # per the predicted scores\n",
    "        pred_scores = pred_values[cur_cell_line_idx]\n",
    "        assert gt_aucs.shape == pred_scores.shape\n",
    "        # find the top k drugs'idx (note: here its by pred scores)\n",
    "        topk_drug_idx_pred = np.argsort(pred_scores)[:top_k]\n",
    "        # step 3\n",
    "        # recall@k\n",
    "        cur_recall_at_k = len(\n",
    "            set(topk_drug_idx_pred).intersection(set(topk_drug_idx_gt))\n",
    "        ) / len(set(topk_drug_idx_gt))\n",
    "        dict_test_cell_line_idx_perf[cur_cell_line_idx] = cur_recall_at_k\n",
    "\n",
    "    avg_recall_at_k = np.mean(list(dict_test_cell_line_idx_perf.values()))\n",
    "    results.append((f\"Recall@{top_k}\", round(avg_recall_at_k, 4)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76a5e6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Auc@1', '0.2373 (GT: 0.1198)'), ('Auc@2', '0.3048 (GT: 0.157)'), ('Auc@5', '0.3751 (GT: 0.222)'), ('Auc@10', '0.4295 (GT: 0.2893)')]\n"
     ]
    }
   ],
   "source": [
    "### AUC\n",
    "results = []\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    dict_test_cell_line_topk_auc_sum_gt = {}\n",
    "    dict_test_cell_line_topk_auc_sum_pred = {}\n",
    "    for cur_cell_line_idx in range(len(pred_values)):\n",
    "        # step 1\n",
    "        # per the predicted scores\n",
    "        pred_scores = pred_values[cur_cell_line_idx]\n",
    "        # find the top k drugs'idx (note: here its by pred scores)\n",
    "        topk_drug_idx_pred = np.argsort(pred_scores)[:top_k]\n",
    "        # step 2\n",
    "        # per the ground truth\n",
    "        gt_aucs = true_values[cur_cell_line_idx]\n",
    "        # find the top k predicted drugs' (per ground truth) aucs\n",
    "        topk_drug_idx_gt = np.argsort(gt_aucs)[:top_k]\n",
    "        dict_test_cell_line_topk_auc_sum_gt[cur_cell_line_idx] = np.mean(\n",
    "            gt_aucs[topk_drug_idx_gt]\n",
    "        )\n",
    "        dict_test_cell_line_topk_auc_sum_pred[cur_cell_line_idx] = np.mean(\n",
    "            gt_aucs[topk_drug_idx_pred]\n",
    "        )\n",
    "\n",
    "    avg_auc_topk_gt = np.mean(\n",
    "        list(dict_test_cell_line_topk_auc_sum_gt.values())\n",
    "    )\n",
    "    avg_auc_topk_pred = np.mean(\n",
    "        list(dict_test_cell_line_topk_auc_sum_pred.values())\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        (\n",
    "            f\"Auc@{top_k}\",\n",
    "            f\"{round(avg_auc_topk_pred, 4)} (GT: {round(avg_auc_topk_gt, 4)})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83b218f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7325483720209628 0.7198399558385051\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "print(pearsonr(c.Predicted, c.Test)[0], spearmanr(c.Predicted, c.Test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147ff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drpreter_venv",
   "language": "python",
   "name": "drpreter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
